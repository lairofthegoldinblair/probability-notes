\chapter{Measure Theory}
Measure theory is concerned with the theory of integration.  Thinking
intuitively for a moment, we know that we want to compute
expressions of the form $\int_A f$ in which $A$ is a set and $f$ is a
real valued function on the set $A$.  If we take functions $f$ that
are equal to $1$ on the set $A$, then it is clear from our intuition
from elementary calculus that $\int_A 1$ should correspond the the
size of $A$ in some appropriate sense.  Therefore, even if we set out
to create a theory of integration we will get as a by product a theory
of set measure.  In fact, the development of the theory starts from
the notion of set measures and develops the theory of integration
using that.

Before setting out the definitions, it is worth mentioning that set
theory is a weird and wild territory.  Over the years, mathematicians
have come up with some truly astounding constructs with sets that defy
intuition. The first trivial example is to note the cardinality of $Z$
and $Z^2$ is the same.  A second much deeper example is the
Banach-Tarski Paradox which says in effect that there is a
decomposition of the unit ball in $\reals^3$ into a finite number of
pieces such that the pieces can be rearranged by only translations and
rotations into two copies of the unit ball.  We won't prove the
Banach-Tarski paradox here, but it suffices to say that it shows you
can't have all of the following in a definition of volume;
\begin{itemize}
\item[(i)]Translations are volume preserving.
\item[(ii)]Rotations are volume preserving.
\item[(iii)]All sets are measurable.
\end{itemize}

By now, the time honored approach to these matters is to give up on
the naive idea that all sets can be measured.  Thus the definition of a measure theory comprises a definition of
which sets are measurable, a means of measuring those sets and a
theory of integrating suitable functions using that measure.



\section{Measurable Spaces}
\begin{defn}A non-empty collection $\mathcal{A}$ of subsets of a set
  $\Omega$ is called a $\sigma$-algebra if given $A, A_1, A_2, \dots
  \in  \mathcal{A}$ we have
\begin{itemize}
\item[(i)]$A^c \in \mathcal{A}$
\item[(ii)]$\bigcup_n A_n \in \mathcal{A}$
\item[(iii)]$\bigcap_n A_n \in \mathcal{A}$
\end{itemize}
\end{defn}
Note that this definition makes a lot of sense.  Whatever our
definition of the class of measurable sets is, we want to be able to
perform meaningful constructions with those sets.  Thus we want the
set of allowable operations to be as large as possible.  On the other
hand, we know that we can't go beyond countable unions. For the
reals once one allows points to be measurable, allowing uncountable unions would
mean that every set is measurable and we already know we can't have that.
\begin{lem}Let $\sigma$-algebra $\mathcal{A}$ in $\Omega$, and $A_1,
  A_2, \dots \in \mathcal{A}$,
\begin{itemize}
\item[(i)] $\Omega \in \mathcal{A}$
\item[(ii)] $\emptyset \in \mathcal{A}$
\end{itemize}
\end{lem}
\begin{proof}
Since $\mathcal{A}$ is non empty, we can find $A \in \mathcal{A}$.
Thus $\Omega = A \bigcup A^c \in \mathcal{A}$.  Then taking
complements shows $\emptyset \in \mathcal{A}$.
\end{proof}
Note that in many accounts of measure theory, the result of the above lemma is assumed as part of
the definition of a $\sigma$-algebra.

\begin{lem}Given a class $\mathcal{C}$ of $\sigma$-algebras on
  $\Omega$, the intersection is also a $\sigma$-algebra.
\end{lem}
\begin{proof}
Because we have shown that every $\sigma$-algebra contains $\Omega$,
we know that the intersection is non-empty.  Now let $A, A_1, A_2, \dots$
be in every $\sigma$-algebra.  Clearly every $\sigma$-algebra in the
class contains $\bigcap_n A_n$, hence so does the intersection.
Similarly with $\bigcup_n A_n$ and $A^c$.
\end{proof}
Note that a union of $\sigma$-algebras is not necessarily a
$\sigma$-algebra.  However, a union of $\sigma$-algebras generates a
$\sigma$-algebra in an appropriate sense.
\begin{defn}Given a collection $\mathcal{C}$ of subsets of $\Omega$,
  we let $\sigma(\mathcal{C})$ be the smallest $\sigma$-algebra
  containing $\mathcal{C}$.
\end{defn}
Note that the definition makes sense since the set of all subsets of
$\Omega$ is a $\sigma$-algebra.  Therefore, the class of
$\sigma$-algbras containing $\mathcal{C}$ is non-empty and
$\sigma(\mathcal{C})$ is the intersection of of the class by the
previous lemma.

For metric spaces (and general topological spaces) there is an
important $\sigma$-algebra that is associated with the topology.
\begin{defn}Given a metric space $S$, the Borel $\sigma$-algebra
  $\borel{S}$ is the $\sigma$-algebra generated by the open sets on $S$.
\end{defn}

\begin{lem}\label{IntervalsGenerateBorel}The Borel $\sigma$-algebra of $\reals$ is generated by intervals
  of the form $(-\infty, x]$ for $x \in \rationals$.
\end{lem}
\begin{proof}Let $\mathcal{C}$ be the collection of all open
  intervals.
We know that the open sets of $\reals$ are countable
  unions of open intervals.  Therefore, the Borel $\sigma$-algebra is
  generated by the set of open intervals.  Now let $\mathcal{D}$ be
  the set of closed intervals of the form $(-\infty,x]$ for $x \in
  \rationals$.  Pick an open interval
  $(a,b)$ and pick a descreasing sequence or rationals $a_n \downarrow
  a$ and an increasing sequence of rationals $b_n \uparrow b$.  Then
  we have 
\begin{align*}(a,b) &= \bigcup_{n=1}^\infty (a_n,b_n] \\
&= \bigcup_{n=1}^\infty \left ( (-\infty,b_n] \cap (-\infty,a_n] \right )
\end{align*}
which shows that $\mathcal{C} \subset \sigma(\mathcal{D})$ hence 
$\sigma(\mathcal{C}) \subset \sigma(\mathcal{D})$.  However, since the
elements of $\mathcal{D}$ are closed sets and $\sigma$-algebras are
closed under set complement, we have $\mathcal{D} \subset
\sigma{\mathcal{C}}$ and therefore
\begin{align*}
\mathcal{B} = \sigma(\mathcal{C}) \subset \sigma(\mathcal{D}) \subset
\sigma(\mathcal{C}) = \mathcal{B}
\end{align*}
and we have $\sigma(\mathcal{D}) = \mathcal{B}$.
\end{proof}

Next we consider how $\sigma$-algebras behave in the presence of
functions.  Given a function $f:S \to T$ we have the induced map on
sets $f^{-1}: 2^T \to 2^S$ defined by 
\begin{align*}
f^{-1}(B) = \left \{x \in S; f(x) \in B \right \}
\end{align*}
\begin{lem}\label{SetOperationsUnderPullback}For $A, B,B_1,B_2,\dots
  \subset T$, then 
\begin{itemize}
\item[(i)] $f^{-1}(B^c) = \left[
    f^{-1}(B) \right ]^c$
\item[(ii)] $f^{-1} \bigcap_n B_n = \bigcap_n f^{-1}
  B_n$
\item[(iii)] $f^{-1} \bigcup_n B_n = \bigcup_n f^{-1}
  B_n$
\item[(iv)]$f^{-1}(B \setminus A) = f^{-1}(B) \setminus f^{-1}(A)$
\end{itemize}
\end{lem}
\begin{proof}
(i)\begin{align*}
f^{-1}(B^c) &= \left \{x \in S; f(x) \notin B \right \} \\
&= \left \{x \in S; f(x) \in B \right \}^c = \left[ f^{-1}(B) \right ]^c
\end{align*}
(ii)\begin{align*}
f^{-1} \bigcap_n B_n &= f^{-1} \left \{x \in T ; \forall n x \in B_n
\right \} \\
& = \left \{x \in S; \forall n f(x) \in B_n \right \} = \bigcap_n f^{-1}  B_n
\end{align*}
(iii)\begin{align*}
f^{-1} \bigcup_n B_n &= f^{-1} \left \{x \in T ; \exists n x \in B_n
\right \} \\
& = \left \{x \in S; \exists n f(x) \in B_n \right \} = \bigcup_n f^{-1}  B_n
\end{align*}

(iv) follows from (i) and (ii) by writing $B \setminus A = B \cap A^c$.
\end{proof}
\begin{lem}\label{SigmaAlgebraPullback}Given an arbitrary function $f$ between measurable spaces
  $(S,\mathcal{S})$ and $(T,\mathcal{T})$, then
\begin{itemize}
\item[(i)] $\mathcal{S}^\prime = f^{-1} \mathcal{T}$ is a
  $\sigma$-algebra on $S$.
\item[(ii)] $\mathcal{T}^\prime = \left \{A \subset T ; f^{-1}(A) \in
      \mathcal{S} \right \}$ is a $\sigma$-algebra on $T$.
\end{itemize}
The $\sigma$-algebra denoted $\mathcal{T}^\prime$ is often denoted
$f_* \mathcal{S}$.
\end{lem}
\begin{proof}
To show (i), let $A,A_1,A_2,\dots \in \mathcal{S}^\prime$.  Since
$\mathcal{S}^\prime = f^{-1}\mathcal{T}$, there exist $B,B_1,B_2,\dots
\in \mathcal{T}$ such that $A = f^{-1}(B)$ and $A_i = f^{-1}(B_i)$ for
$i=1,2,\dots$.  Now since $\mathcal{T}$ is a $\sigma$-algebra, we know
that $B^c$, $\bigcup_n B_n$ and $\bigcap_n B_n$ are all in
$\mathcal{T}$.  Now using the previous lemma,
\begin{align*}
A^c &= \left[f^{-1}(B)\right]^c &&= f^{-1}(B^c) \in
\mathcal{S}^\prime\\
\bigcap_n A_n &= \bigcap_n f^{-1}B_n &&= f^{-1} \bigcap_n B_n \in
\mathcal{S}^\prime \\
\bigcup_n A_n &= \bigcup_n f^{-1}B_n &&= f^{-1} \bigcup_n B_n \in
\mathcal{S}^\prime \\
\end{align*}
Now to see (ii), first note that $\mathcal{T}^\prime$ is non-empty
since $f^{-1} (\emptyset) = \emptyset \in \mathcal{S}$.  Next, pick $B,B_1,B_2,\dots \in \mathcal{T}^\prime$ so that
$f^{-1}B,f^{-1}B_1,f^{-1}B_2 \in \mathcal{S}$.  Again use the previous
lemma to see
\begin{align*}
f^{-1} B^c &= \left[f^{-1}(B)\right]^c \in
\mathcal{S}\\
f^{-1} \bigcap_n B_n &= \bigcap_n f^{-1}B_n \in
\mathcal{S} \\
f^{-1} \bigcup_n B_n &= \bigcup_n f^{-1}B_n \in
\mathcal{S} \\
\end{align*}
and this shows that $B^c,f^{-1} \bigcap_n B_n, f^{-1} \bigcap_n B_n
\in \mathcal{T}^\prime$.
\end{proof}

\begin{lem}\label{BijectivityOfInducedSetMap}Let $f : S \to T$ be a set function and $f^{-1} : 2^T \to
  2^S$ be the induced function on sets.
\begin{itemize}
\item[(i)]$f^{-1}$ is surjective if and only if $f$ is injective
\item[(ii)]$f^{-1}$ is injective if and only if $f$ is surjective
\item[(iii)]$f^{-1}$ is a bijection if and only if $f$ is a bijection
\end{itemize}
\end{lem}
\begin{proof}
Suppose $f$ is surjective and pick $A, B \subset T$ with $A \neq B$.
Then, possibly switching the names of $A$ and $B$, we have $t \in A
\setminus B$.  By surjectivity we know there exists an $s \in S$ such
that $f(s) = t$ and therefore $s \in f^{-1}(A) \setminus f^{-1}(B)$
showing $ f^{-1}(A) \neq f^{-1}(B)$.  Now if $f$ is not surjective
then there exists $t \in T$ such that there is no $s \in S$ with $f(s)
= t$.  In this case we see that $f^{-1}(T) = S = f^{-1}(T \setminus
\lbrace t \rbrace)$ showing $f^{-1}$ is not injective.

Suppose $f$ is injective and let $B \subset S$ and we claim $B =
f^{-1}(f(B))$.  Clearly $A \subset f^{-1}(f(B))$ and if they are not
equal then there exists $s \in S \setminus B$ such that $f(s) = f(b)$
for some $b \in B$ contradicting injectivity.  If $f$ is not injective
then there exists $s,t \in S$ with $s \neq t$ and $f(s) = f(t)$ and
clearly there can be no $A \subset T$ such that $f^{-1}(A) = \lbrace s \rbrace$.

The statement of (iii) is an immediate consequence of (i) and (ii).
\end{proof}

The definition given for $\sigma(\mathcal{C})$ for a set $\mathcal{C}
\subset 2^\Omega$ as the smallest $\sigma$-algebra containing
$\mathcal{C}$ may lack appeal because of the fact that it is
non-constructive.  It is possible to give a constructive definition of
$\sigma(\mathcal{C})$ by making a transfinite recursive definition.
The following makes use of the theory of ordinal numbers.
\begin{lem}Let $\mathcal{C} \subset 2^\Omega$, and let $\omega_1$ be
  the first uncountable ordinal and define for each countable ordinal
\begin{itemize}
\item[(i)]$\mathcal{C}_{\omega_0} = \mathcal{C}$
\item[(ii)]For a successor ordinal $\alpha$, $\mathcal{C}_\alpha$ is
  the set of countable unions of elements of $\mathcal{C}_{\alpha -
    1}$ and complements of such unions.
\item[(iii)]For a limit ordinal $\alpha$, define $\mathcal{C}_\alpha =
  \bigcup_{\beta < \alpha} \mathcal{C}_\beta$.
\end{itemize}
Then $\bigcup_{\alpha < \omega_1} \mathcal{C}_\alpha = \sigma(\mathcal{C})$.
\end{lem}
\begin{proof}
First we show $\bigcup_{\alpha < \omega_1} \mathcal{C}_\alpha \supset
\sigma(\mathcal{C})$.  Since we know that $\mathcal{C} \subset
\bigcup_{\alpha < \omega_1} \mathcal{C}_\alpha$, it suffices to show
that $\bigcup_{\alpha < \omega_1} \mathcal{C}_\alpha$ is a
$\sigma$-algebra.

It is explicit in the definition for successor
ordinals, that given any $A \in \mathcal{C}_\alpha$, we have $A^c \in  \mathcal{C}_{\alpha+1}$.

To show closure under set union, we suppose that we are
given $A_1, A_2, \dots$ where $A_i \in \mathcal{C}_{\alpha_i}$.  We now
use the fact that given a countable set of countable ordinals, there
is a countable ordinal that bounds them (TODO: Prove this somewhere or
find a good reference).  Thus we may pick a countable ordinal $\hat
\alpha$ such that $\alpha_i < \hat {\alpha}$ for every $i=1,2,\dots$.  Since
$\mathcal{C}_\alpha \subset \mathcal{C}_{\alpha+1}$, we know that $A_i
\in \mathcal{C}_{\hat \alpha}$ for all $i$.  Now simply apply the definition
of $\mathcal{C}_{\hat \alpha + 1}$ to see
$\bigcup_{i=1}^\infty A_i \in \mathcal{C}_{\hat \alpha + 1}$.  Having
proven closure under complement and countable union, use De
Morgan's Law to derive the countable intersection property and we are done.

Now we need to show that $\bigcup_{\alpha < \omega_1} \mathcal{C}_\alpha \subset
\sigma(\mathcal{C})$.  This is an easy transfinite induction on
$\alpha$ using the properties of the $\sigma$-algebra
$\sigma(\mathcal{C})$.
TODO: Write this out.
\end{proof}

\section{Measurable Functions}
We've seen that arbitrary set functions can be used to create
$\sigma$-algebras but when we consider functions between
measurable spaces the $\sigma$-algebras are given and it makes sense
to restrict our attention to a class of functions that are compatible
with those $\sigma$-algebras.
\begin{defn}A function $f : (S,\mathcal{S}) \to (T,\mathcal{T})$ is
  called measurable if for every $B \in \mathcal{T}$, we have
  $f^{-1}(B) \in \mathcal{S}$.  When we want to emphasize that the
  measurability is with repsect to particular $\sigma$-algebras we may
  say that $f$ is $\mathcal{S}/\mathcal{T}$-measurable.
\end{defn}
\begin{lem}\label{MeasurableByGeneratingSet}Suppose we are given a function $f : (S,\mathcal{S}) \to
  (T,\mathcal{T})$ and a class of subsets $\mathcal{C} \subset 2^T$
  such that $\sigma(\mathcal{C}) = \mathcal{T}$.  The $f$ is
  measurable if and only if $f^{-1} \mathcal{C} \subset \mathcal{S}$.
\end{lem}
\begin{proof}The only if direction is trivial.  So suppose $f^{-1}  \mathcal{C} \subset \mathcal{S}$.
Now consider $\mathcal{T}^\prime = \left \{ B \subset T; f^{-1} B \in
  S \right \}$.  By our assumption, we have $\mathcal{C} \subset
\mathcal{T}^\prime$.  Furthermore we know from
Lemma \ref{SigmaAlgebraPullback} that $\mathcal{T}^\prime$ is
a $\sigma$-algebra, thus $\sigma(\mathcal{C}) \subset
\mathcal{T}^\prime$ and this shows that $f$ is
$\mathcal{S}/\mathcal{T}$ measurable.
\end{proof}
\begin{lem}\label{CompositionOfMeasurable}Let $f:(S,\mathcal{S}) \to (T,\mathcal{T})$
  and $g:(T,\mathcal{T}) \to (U,\mathcal{U})$ be measurable.  Then $g
  \circ f :(S,\mathcal{S}) \to (U,\mathcal{U})$ is measurable.
\end{lem}
\begin{proof}This follows simply from the fact that $(g \circ
  f)^{-1}(B) = f^{-1}(g^{-1}(B))$ and the measurability of $f$ and $g$.
\end{proof}
Note, from this point forward, when we refer to $\reals$ as a
measurable space, it should be assumed that we are referring to
$\reals$ with the Borel $\sigma$-algebra.  Note that a function
$f:(\Omega, \mathcal{A}) \to \reals$ is measurable if and only if
$\left \{\omega \in \Omega ; f(\omega) \leq x \right \} \in \mathcal{A}$ for all $x \in \reals$ (in fact
it suffices to consider $x \in \rationals$).  It is also very common to consider
extensions of $\reals$ such as $\overline{\reals} = [-\infty,\infty]$
and $\overline{\reals}_+ = [0,\infty]$
obtained by appending points at infinity.  For these spaces we take the $\sigma$-algebra
generated by $\left \{\omega \in \Omega ; f(\omega) \leq x \right \}$
for $x \in \overline{\reals}$ respectively.  It can be shown that
there are natural topologies on each of these compactifications and
the $\sigma$-algebras defined are the Borel $\sigma$-algebras of these topologies.

We will often talk about the
convergence of sequences of measurable functions.  Unless we say
otherwise, it should be understood that this convergence is taken pointwise.
\begin{lem}\label{LimitsOfMeasurable}Let $f_1, f_2, \dots$ be measurable functions from
  $(\Omega, \mathcal{A})$ to $\overline{\reals}$.  Then $\sup_n f_n$,
  $\inf_n f_n$, $\limsup_n f_n$, $\liminf_n f_n$ are all measurable.
\end{lem}
\begin{proof}
To see measurability of $\sup_n f_n$ we suppose that $\omega \in
\Omega$ is such that $\sup_n f_n(\omega) \leq x$, then $x$ is an upper
bound we have $f_n(\omega) \leq x$ for all $n$.  On the other hand, if
we assume that $\omega \in \Omega$ is such that $f_n(\omega) \leq x$
for all $n$ then  $\sup_n f_n(\omega) \leq x$ so we have
\begin{align*}
\left \{\omega ; \sup_n f_n(\omega) \leq x \right \} = \bigcap_n \left
  \{\omega ; f_n(\omega) \leq x \right \} \in \mathcal{A}
\end{align*}
To see that $\inf_n f_n$ is measurable we use the identity $\inf_n f_n
= -\sup_n (-f_n)$.

We also have the definitions
\begin{align*}
\limsup_{n\to \infty} f_n = \inf_n \sup_{k \geq n} f_k \textrm{,} \liminf_{n\to \infty} f_n = \sup_n \inf_{k \geq n} f_k
\end{align*}
and the measurability of $\sup$ and $\inf$ already shown implies the
measurability of $\liminf$ and $\limsup$.
\end{proof}

From the measurability of limits of real valued functions we can also
generalize to measurability of limits in arbitrary metric spaces.
\begin{lem} \label{LimitsOfMeasurableMetricSpace}Let $(S,d)$ be a metric space and let
  $f_1, f_2, \dotsc$ be
  measurable functions  $(\Omega, \mathcal{A})$ to $(S,
  \mathcal{B}(S)$, then $\lim_{n \to \infty} f_n$ is measurable if it
  exists.
\end{lem}
\begin{proof}
Let $g : S \to \reals$ be an arbitrary continuous function.  Then $g$
is Borel measurable and therefore $g \circ f_n$ are Borel measurable
real valued functions.  Moreover by continuity of $g$ we know that
$\lim_{n \to \infty} g \circ f_n  = g \circ f$.  Therefore by Lemma
\ref{LimitsOfMeasurable} we can conclude that $g \circ f$ is Borel
measurable for all continuous $g : S \to \reals$.  

Now let $U \subset S$ be an open set and define $g_n(s) = n d(s,U^c)
\wedge 1$ so that $g_n$ are continuous functions such that $g_n
\uparrow \characteristic{U}$.  We know that $g_n \circ f$ are Borel
measurable hence if follows that $\characteristic{U} \circ f$ is Borel
measurable by another application of Lemma
\ref{LimitsOfMeasurable} which shows that $\lbrace f \in U \rbrace$ is
measurable.  Measurability of $f$ follows from the fact that open sets generate the Borel
$\sigma$-algebra and application of Lemma \ref{MeasurableByGeneratingSet}.
\end{proof}

We now introduce an extremely important class of measurable
functions.  Simple measurable functions will be used to approximate
arbitrary measurable functions and in particular, will serve as the
analogue of Riemann sums when we start to consider integration.

\begin{defn}Given a set $\Omega$ and a set $A
  \subset \Omega$, the \emph{indicator function} $\characteristic{A}$ is
  equal to $1$ on $A$ and $0$ on $A^c$.  A linear combination $c_1
  \characteristic{A_1} + \cdots + c_n \characteristic{A_n}$ is called
  a \emph{simple function}.
\end{defn}

\begin{lem}\label{SimpleFunctions}A function $f : \Omega \to \reals$ is simple if and only it
  takes a finite number of values.  A simple function is measurable if
  an only if $f^{-1}(c_j)$ is measurable for each of its distinct
  values $c_j \in \reals$.
\end{lem}
\begin{proof}
If $f = c_1  \characteristic{A_1} + \cdots + c_n \characteristic{A_n}$
is simple, then since indicator functions take only the value ${0,1}$
it is clear that $f$ can have at most $2^n$ values.

On the other hand, if $f : \Omega \to \reals$ only takes the finite
number of distinct values $c_1, \dots, c_n$ then clearly we may write 
$f = c_1  \characteristic{A_1} + \cdots + c_n \characteristic{A_n}$
where $A_j = f^{-1}(c_j)$.

As regards measurability, first notice that $\characteristic{A}$ is
measurable if and only if $A \in  \mathcal{A}$.  This follows from
that fact that there are only four possible preimages under
$\characteristic{A}$: $A, A^c, \Omega, \emptyset$ and each of these
preimages is the preimage of a measurable subset of $\reals$.

Similarly, if a simple function $f$ has the distinct values $c_1, \dots,
c_n$ (including $0$ if necessary) then clearly for $f$ to be
measurable it is necessary $f^{-1}(c_j)$ is measurable since points
are measurable in $\reals$.   On the hand, there are $2^n$ possible preimages under $f$ and they are all
constructed from unions of the preimages $f^{-1}(c_j)$ so if know that
$f^{-1}(c_j)$ are measurable then so is every $f^{-1}(A)$ for $A
\subset \reals$ (a stronger condition than measurability).
\end{proof}

Note that the representation of a simple function as a linear
combination of indicator functions is not unique.  However, we
have
just shown that a simple function is equally well characterized as a
function that takes a finite number of values.  The canonical
representation of a simple function is a representation such that the
$c_i$ are distinct and non-zero and the $A_i$ are pairwise disjoint; the canonical
representation is unique.
\begin{lem}\label{PointwiseApproximationBySimple}For any positive measurable function $f : (\Omega,
  \mathcal{A}) \to \overline{\reals}_+$ there exist a sequence of simple measurable
  functions $f_1, f_2, \dots$ such that $0 \leq f_n \uparrow f$.
\end{lem}
\begin{proof}
Define
\begin{align*}
f_n(\omega) = 
\begin{cases}k2^{-n} & \text{if $k2^{-n} \leq f(\omega) < (k+1)2^{-n}$
    and $0 \leq k \leq n2^n -1$.} \\
n & \text{if $f(\omega) \geq n$.}
\end{cases}
\end{align*}
Note that $f_n$ is simple since it has at most $2^n + 1$ values $0,
\frac{1}{2^n}, \dots, n$.  $f_n$ is measurable since
$f_n^{-1}(k2^{-n}) = f^{-1}[k2^{-n},(k+1)2^{-n})$ is measurable by measurability of $f$.  Similarly
with $f_n^{-1}(n) = f^{-1} [n,\infty)$ and Lemma \ref{SimpleFunctions}.
\end{proof}

As an application of approximation by simple functions, 
\begin{lem}\label{ArithmeticCombinationsOfMeasurableFunctions}
Let $f,g : (\Omega, \mathcal{A}) \to \reals$ be measurable functions
and let $a,b \in \reals$.  Then $af + bg$ and $fg$ are measurable and
$f/g$ is measurable when $g \neq 0$ on $\Omega$.
\end{lem}
\begin{proof}As $f$ and $g$ are measurable, we can apply the previous
  lemma to $f_\pm = \pm((\pm f) \wedge 0)$ and $g_{\pm} = \pm((\pm g) \wedge 0)$
  to get measurable simple functions $f_n$ and $g_n$ such that $\lim_{n \to
    \infty} f_n = f$ and $\lim_{n \to
    \infty} g_n = g$.  Basic properties of limits show that $\lim_{n
    \to \infty} (a f_n + b g_n) = a f + b g$, $\lim_{n \to \infty} f_n
  g_n = f g$ and $\lim_{n \to \infty} \frac{f_n}{  g_n} =
  \frac{f}{g}$.  Thus by Lemma \ref{LimitsOfMeasurable} we are done if
  we can show that each of $a f_n + b g_n$, $f_n g_n$ and
  $\frac{f_n}{g_n}$ is measurable.  In fact we will show that each of
  these is simple measurable.

It is easy to see that $a f_n + b g_n$ are also
  measurable simple as are $f_n g_n$.  Let $f_n$ take the values $c_1,
  \dots, c_s$ and let $g_n$ take the values $d_1, \dots, d_t$.  
Clearly the functions  $a f_n + b g_n$, $f_n g_n$ and
  $\frac{f_n}{g_n}$ are simple as each takes at most the values  $a c_i + b d_j$, $c_i d_j$ and
  $\frac{c_i}{d_j}$ for $i=1,\dots,s$ and $j=1,\dots, t$.  
Measurability follows from noting that each
  possible value of the linear combination is created from a finite
  set of combinations of the values of the $f_n$ and $g_n$; hence
  $(af_n + bg_n)^{-1}(c_j)$ is a finite union of intersections of the
  form $f_n^{-1}(x) \cap g_n^{-1}(y)$ where $x,y \in \reals$ are
  values of $f_n$ and $g_n$ respectively.
\end{proof}

\begin{defn}Given two measurable functions $f,g$ on the same measurable space
  $(\Omega, \mathcal{A})$, we say that $f$ is $g$-measurable if
  $\sigma(f) \subset \sigma(g)$.
\end{defn}

TODO: Where is the right place to introduce this concept?
While the basic results of measure theory can be formulated in terms
of general measurable spaces certain more advanced results require
topological assumptions that prevent the wildness of set theory from
taking over.  For the results of this nature in which we are
interested what is required is that the measure space look
sufficiently like the Borel algebra on the $\reals$.  Somewhat
surprisingly such a constraint isn't too severe (as we will show
later) and for the purposes of these notes (and following the lead
of Kallenberg) we will settle on the following definitions to capture
these restrictions.

\begin{defn}Two measure spaces $(S, \mathcal{S})$ and $(T,
  \mathcal{T})$ are said to be \emph{Borel isomorphic} if there exists
  a bijection $f : S \to T$ such that both $f$ and $f^{-1}$ are measurable.
\end{defn}

\begin{defn}A measurable space $(S, \mathcal{S})$ is said to be a
  \emph{Borel space} if it is Borel isomorphic to a Borel subset of $[0,1]$.
\end{defn}

The following lemma is extremely useful both conceptually and
practically.  In addition it's proof is a paradigmatic example of a
common measure theoretic argument and gives us a chance to show how
results may carry over from $\reals$ to general Borel spaces.
\begin{lem}\label{FunctionalRepresentation}Let $(S, \mathcal{S})$ be a
  Borel space and let $f : (\Omega, \mathcal{A}) \to S$ and $g :
  (\Omega, \mathcal{A}) \to (T,\mathcal{T})$ be measurable.  Then $f$
  is $g$-measurable if and only if there exists measurable $h :
  T  \to S$ such that $f = h \circ g$.
\end{lem}
\begin{proof}
For the if direction, assume $f = h \circ g$.  Then for $B \in
\mathcal{B}([0,1])$, we have $f^{-1}(B) = g^{-1}(h^{-1}(B))$.  Now we know
that $h^{-1}(B) \in \mathcal{T}$ and therefore, $f^{-1}(B) \in
\sigma(g)$.

For the only if direction, we first assume that $(S, \mathcal{S})
=([0,1], \mathcal{B}([0,1]))$.  
Assume $f$ is an indicator
function $\characteristic{A}$.  Our assumption of $g$-measurability
means that there exists $B \in \mathcal{T}$ such that $A =
g^{-1}(B)$.  If we define $h = \characteristic{B}$, then we have $f =
h \circ g$.  Now let us suppose that $f$ is a simple function and take
its canonical representation $f = c_1 \characteristic{A_1} + \cdots + c_n
\characteristic{A_n}$ with $A_i$ disjoint and $c_i$ distinct.  Since $f$ is
$g$-measurable, we know that there exist $B_i \in \mathcal{T}$ such
that $A_i = g^{-1}(B_i)$.  If we define $h=c_1 \characteristic{B_1} + \cdots + c_n
\characteristic{B_n}$, then $f = h \circ g$.

Now if we assume $f \geq 0$, then we know that we can find a sequence
of $g$-measurable simple functions such that $f_n \uparrow f$.  We
have shown that there are $h_n$ such that $f_n = h_n \circ g$.  Define
$h = \limsup_n h_n$ and then note $h$ is $g$-measurable and that 
\begin{align*}
h(g(\omega)) = \limsup_n h_n(g(\omega)) = \limsup_n f_n(\omega) =
\lim_{n \to \infty} f_n(\omega) = f(\omega)
\end{align*}
Lastly, for arbitrary $f$, we write $f = f_+ - f_{-}$ where $f_{\pm}
\geq 0$ and are both $g$-measurable (e.g. $f_{\pm} = (\pm f) \wedge 0$).
We find $h_{\pm}$ such that $f_{\pm} = h_{\pm} \circ g$ and define $h
= h_+ - h_{-}$.

Now let us assume that $S$ is a Borel subset of $[0,1]$ and note that
every measurable subset of $S$ is over the form $A \cap S$ for a Borel
subset $A \subset [0,1]$ and thus $f$ is also
$g$-measurable when considered as a function from $\Omega$ to $[0,1]$.  
By what we have just proven applied to
$f$, we get $\tilde{h} : T \to [0,1]$ such that $\tilde{h}
\circ g = f$.  Because of the latter identity, we know that
$\tilde{h}(g(\Omega)) \subset S$ however it is not necessarily the
case that $tilde{h}(T) \subset S$.  Since $S$ is a Borel subset of
$[0,1]$, we know that $\tilde{h}^{-1}(S)$ is $\mathcal{T}$-measurable
and therefore we can pick an arbitrary point $s_0 \in S$ and define
\begin{align*}
h(t) &= \begin{cases}
\tilde{h}(t) & \text{if $t \in \tilde{h}^{-1}(S)$} \\
s_0 & \text{otherwise}
\end{cases}
\end{align*}
and note that we now have $h : T \to S$ and $f = h \circ g$.

It remains to extend the argument to general Borel spaces $S$.  Assume
that $j : S \to A \subset [0,1]$ is a Borel isomorphism to a Borel
subset $A$.  We can define $\tilde{h}: T \to A$ such that $j \circ f =
h \circ g$ by the above argument.  Now let $h = j^{-1} \circ
\tilde{h}$ so we have $h : T \to S$ and $f = h \circ g$.
\end{proof}

The following definitions and lemma may seem merely technical, but in fact are
an important part of the most common methodology for proving measure
theoretic results.  
\begin{defn}A class $\mathcal{C}$ of subsets of a set $\Omega$ is called a $\lambda$-system if
\begin{itemize}
\item[(i)] $\Omega \in \mathcal{C} $.
\item[(ii)] for all $A,B \in \mathcal{C}$ if $A \subset B$, then
  $B \setminus A \in \mathcal{C}$.
\item[(iii)] for all $A_n \in
  \mathcal{C}$ if $A_1 \subset A_2 \subset \cdots$ and $A_n \uparrow A$, then $A \in \mathcal{C}$.
\end{itemize}
\end{defn}
\begin{defn}A class $\mathcal{C}$ of subsets of a set $\Omega$ is
  called a $\pi$-system if it is closed under finite intersections.
\end{defn}
The first observation is that the concepts of $\pi$-system and
$\lambda$-system factor the conditions for being a $\sigma$-algebra.
\begin{lem}\label{PiLambdaSigma}If a class $\mathcal{C} \subset 2^\Omega$ is both a
  $\pi$-system and a $\lambda$-system, then it is a $\sigma$-algebra.
\end{lem}
\begin{proof}
First we show closure under set complement.  Let $A \in \mathcal{C}$.
Then since $\Omega \in \mathcal{C}$, we know that $A^c = \Omega
\setminus A \in \mathcal{C}$.  Now note that having closure under set complement
together with closure under finite intersection gives closure under
finite union by De Morgan's law $\left \{ \bigcup_{i=1}^n A_i \right \} ^
c =  \bigcap_{i=1}^n A_i^c $.

Let $A_1, A_2, \dots \in \mathcal{C}$.  Next we show closure under
countable union.  Defining $B_n = \bigcup_{i=1}^n A_i$, we know that
$B_n \in \mathcal{C}$ and clearly $B_n \uparrow \bigcup_{i=1}^\infty
A_i$ and therefore $\bigcup_{i=1}^\infty A_i \in \mathcal{C}$.
Closure under countable intersections follows from closure under
countable unions and the infinite version of De Morgan's Law.
\end{proof}
\begin{thm}[$\pi$-$\lambda$ Theorem]\label{MonotoneClassTheorem}Suppose $\mathcal{C}$ is a $\pi$-system, $\mathcal{D}$ is a
  $\lambda$-system such that $\mathcal{C} \subset \mathcal{D}$.  Then
  $\sigma(\mathcal{C}) \subset \mathcal{D}$.
\end{thm}
\begin{proof}The first thing to note is that the intersection of a
  collection of $\lambda$-systems is also a $\lambda$-system and that
   $2^\Omega$ is a $\lambda$-system.
  Therefore, in a way entirely analogous to $\sigma$-algebras we may
  define the $\lambda$-system generated by a collection of sets as the
  intersection of all $\lambda$-systems containing the collection.

The theorem is proved for general $\mathcal{D}$ if we prove it for the
special case $\mathcal{D} = \lambda(\mathcal{C})$.  To see this
special case, by \ref{PiLambdaSigma} it suffices to show that
$\lambda(\mathcal{C})$ is a $\pi$-system.  A trivial induction
argument shows it suffices to show closure under pairwise
intersection:  for every $A,B \in \lambda(\mathcal{C})$ we have $A
\cap B \in \lambda(\mathcal{C})$.

By definition of $\pi$-algebra, we have closure when $A,B
\in \mathcal{C}$.  Now fix $C \in \mathcal{C}$ and let $\mathcal{A}_C
= \left \{A \subset \Omega ; A \cap C \in \lambda(\mathcal{C}) \right
\}$.  We claim that $\mathcal{A}_C$ is a $\lambda$-system.

To see that $\Omega \in \mathcal{A}_C$ is trivial: $C \cap \Omega
= C \in \mathcal{C} \subset \lambda(\mathcal{C})$.
Suppose $A \supset B$ where $A,B \in \mathcal{A}_C$, then $C
\cap (A \setminus B) = (C \cap A) \setminus (C \cap B) \in
\lambda(\mathcal{C})$.  Suppose $A_1 \subset A_2 \subset \cdots$ with
$A_i \in \mathcal{A}_C$.  $C \cap \bigcup_{i=1}^\infty A_i =
\bigcup_{i=1}^\infty C \cap A_i \in \lambda(\mathcal{C})$ by
distributivity of set intersection over set union and closure of $\lambda$-system under increasing unions.

Now that we know $\mathcal{A}_C$ is a $\lambda$-system containing
$\mathcal{C}$ we know that $\lambda(\mathcal{C}) \subset
\mathcal{A}_C$ and therefore $C \cap A \in \lambda(\mathcal{C})$ for
every $A \in \lambda(\mathcal{C})$ and $C \in \mathcal{C}$.

To finish up the proof, for every $C \in \lambda(\mathcal{C})$, let
$\mathcal{B}_C = \left \{ A \in \Omega ; A \cap C \in
  \lambda(\mathcal{C}) \right \}$.  We have just shown that
$\mathcal{C} \subset \mathcal{B}_C$ and an argument exactly analogous
to the one above shows that $\mathcal{B}_C$ is a $\lambda$-algebra and
therefore $\lambda(\mathcal{C}) \subset \mathcal{B}_C$ proving the result.
\end{proof}

Though we'll see many examples of this along the way, it is worth
making explicit how the Theorem \ref{MonotoneClassTheorem} is applied.
Suppose that one wishes to prove a property holds for a
$\sigma$-algebra $\mathcal{A}$ of sets.  A common sub-case is we'll be trying to show a
property holds for the indicator functions associated with those sets
(those being the most basic building blocks of measurable functions).
The $\pi$-$\lambda$ Theorem allows us to prove the property holds on
$\mathcal{A}$ by showing 
\begin{itemize}
\item[(i)] The collection of all sets satisfying the property is a $\lambda$-system
\item[(ii)] There is a $\pi$-system of sets $\mathcal{P}$ that
  satisfies the property and $\sigma(\mathcal{P}) = \mathcal{A}$.
\end{itemize}
A proof along these lines is referred to as a \emph{monotone class
  argument}.

\section{Measures and Integration}
Armed with a way of describing and transforming measurable sets it is
finally time to measure them.
\begin{defn}A \emph{measure} on a measurable space $(\Omega,
  \mathcal{A})$ is a function $\mu : \mathcal{A} \to
  \overline{\reals}_+$ satisfying
\begin{itemize}
\item[(i)] $\mu(\emptyset) = 0$
\item[(ii)] $\mu(\bigcup_{i=1}^\infty A_i) = \sum_{i=1}^\infty \mu(A_i)$
  for $A_1, A_2, \dots \in \mathcal{A}$ disjoint.
\end{itemize}
A triple $(\Omega, \mathcal{A}, \mu)$ is called a \emph{measure space}.
\end{defn}

An important special case of measure theory occurs when the underlying
space has unit measure.  Many of the concepts we have already
discussed have different names when discussing this special case.
\begin{defn}A \emph{probability space} is a measure space $(\Omega,
  \mathcal{A}, P)$ such that $P(\Omega) = 1$.  The measure $P$ is
  called the \emph{probability measure}.  Measurable sets $A \in
  \mathcal{A}$ are referred to as \emph{events}.  Given a measurable
  space $(S, \mathcal{S})$, a measurable function $\xi : \Omega \to S$
  is called a \emph{random element} in $S$.  For the special case in
  which $(S, \mathcal{S}) = (\reals, \mathcal{B}(\reals)$, we call a
  measurable $\xi : \Omega \to \reals$ a \emph{random variable}.
\end{defn}

\begin{lem}\label{ContinuityOfMeasure}Given a measure space $(\Omega, \mathcal{A}, \mu)$, and sets $A_1, A_2, \dots \in \mathcal{A}$.
\begin{itemize}
\item[(i)] If $A_i \uparrow A$ then $\mu A_i \uparrow \mu A$.
\item[(ii)] If $A_i \downarrow A$ and $\mu A_1 < \infty$ then $\mu A_i \downarrow \mu A$.
\end{itemize}
\end{lem}
\begin{proof}To show (i), define $B_1 = A_1$ and $B_i = A_i \setminus
  A_{i-1}$ for $i > 1$.  Clearly, $B_i$ are disjoint and it is equally
  clear that $\bigcup_{i=1}^n B_i = A_n$ and $\bigcup_{n=1} ^\infty
  B_n = A$.
Therefore
\begin{align*}
\mu A_n = \mu \bigcup_{i=1}^n B_i = \sum_{i=1}^n \mu B_i \uparrow
\sum_{i=1}^\infty \mu B_i = \mu \bigcup_{i=1}^\infty  B_i = \mu A
\end{align*}
where we have used finite and countable additivity of $\mu$ over the
$B_i$.

To see (ii), note that $A_1 \setminus A_n \uparrow A_1
\setminus A$ and then under the finiteness assumption $\mu A_1 <
\infty$, we see 
\begin{align*}
\mu (A_1 \setminus A_n) = \mu A_1 - \mu A_n \uparrow
\mu (A_1 \setminus A) = \mu A_1 - \mu A
\end{align*}
Subtract $\mu A_1$ from both sides multiply by $-1$ to get the result.
\end{proof}

\begin{lem}Given a measure space $(\Omega, \mathcal{A}, \mu)$, $\mu
  \left (\bigcup_{i=1}^\infty A_i \right ) \leq \sum_{i=1}^\infty \mu(A_i)$  for $A_1, A_2, \dots \in \mathcal{A}$.
\end{lem}
\begin{proof}First we prove finite subadditivity by an induction argument.  For $n=2$, we note that we may
  write disjoint unions
\begin{align*}
A &= (A \setminus B) \cup (A \cap B) \\
B  &= (B\setminus A) \cup (A \cap B) \\
A \cup B  &= (A\setminus B)  \cup (B\setminus A) \cup (A \cap B) \\
\end{align*}
By finite additivity of measure and positivity of measure, we see $\mu A \cup B = \mu A + \mu B
- \mu A \cap B \leq \mu A + \mu B$. 

For the induction step, assume $\mu \left (\bigcup_{i=1}^{n-1} A_i \right
) \leq \sum_{i=1}^{n-1} \mu(A_i)$, then use the case $n=2$ and
Lemma \ref{ContinuityOfMeasure} to see
\begin{align*}
\mu \left (\bigcup_{i=1}^{n} A_i \right) &= \mu \left
  (\bigcup_{i=1}^{n-1} A_i  \cup A_n\right) \\
&\leq \mu \left (\bigcup_{i=1}^{n-1} A_i \right ) + \mu A_n \\
&\leq \sum_{i=1}^{n-1} \mu(A_i) + \mu A_n = \sum_{i=1}^n \mu(A_i)
\end{align*}

To extend the result to infinite unions, define $B_n = \bigcup_{i=1}^n
A_i$ and note that $B_n \uparrow \bigcup_{i=1}^\infty
A_i$ and that by finite subadditivity, $\mu B_n \leq \sum_{i=1}^n \mu
A_i$.  Taking limits we see
\begin{align*}
\mu \bigcup_{i=1}^\infty A_i = \lim_{n \to \infty} \mu B_n \leq \lim_{n
  \to \infty} \sum_{i=1}^n \mu A_i = \sum_{i=1}^\infty \mu A_i
\end{align*}
\end{proof}

Next up is the definition of integral of a measurable function on a
measure space.  First we proceed by defining the integral for a simple functions.
\begin{defn}
Given a canonical representation of a simple function $f =
c_1 \characteristic{A_1} + \cdots + c_n \characteristic{A_n}$ we
define the integral of $f$ to be
\begin{align*}
\int f d\mu = \mu f = c_1 \mu A_1 + \cdots + c_n \mu A_n
\end{align*}
\end{defn}
Having the definition of the integral of a simple function in terms of
the canonical representation is inconvenient at times when one is
given a simple function that is not known to be in a canonical
representation.  It turns out that the formula above extends to any
representation of the simple function as a linear combination of
indicator functions.  To see that we proceed in steps.
\begin{lem}Given any representation of a simple function $f =
c_1 \characteristic{A_1} + \cdots + c_n \characteristic{A_n}$ with
$A_i$ pairwise disjoint,
\begin{align*}
\int f d\mu = c_1 \mu A_1 + \cdots + c_n \mu A_n
\end{align*}
\end{lem}
\begin{proof}We have to construct the canonical representation of
  $f$.  It is conceptually simple, but there is a bit of notation to
  deal with.
  Let $d_1, d_2, \dots, d_m$ be the distinct values of $c_1, \dots,
  c_n$.  Furthermore, for each $i=1,\dots,m$, let $B_{i,j}$ 
  $j=1,\dots,k_i$ be the set of $A_n$ for which $c_n = d_i$.  Then the
  canonical representation of $f$ is 
\begin{align*}
f = d_1 \characteristic{\bigcup_{j=1}^{k_1} B_{1,j}} + \cdots + d_m \characteristic{\bigcup_{j=1}^{k_m} B_{m,j}}
\end{align*}
and then 
\begin{align*}
\int f d \mu &= d_1 \mu \bigcup_{j=1}^{k_1} B_{1,j} + \cdots + d_m \mu
\bigcup_{j=1}^{k_m} B_{m,j} \\
&= d_1 \sum_{j=1}^{k_1} \mu B_{1,j} + \cdots + d_m 
\sum_{j=1}^{k_m} \mu B_{m,j} \\
&= c_1 \mu A_1 + \cdots + c_n \mu A_n
\end{align*}
\end{proof}
\begin{lem}\label{LinearityIntegralSimpleFunctions}Given two simple functions $f,g$, for all $a,b \in \reals$,
 \begin{align*}
\int \left (af + bg \right ) d \mu = a \int f d \mu + b \int g d \mu
\end{align*}
If $f \geq g$ $a.e.$ then we have
 \begin{align*}
\int f d \mu \geq \int g d \mu
\end{align*}
\end{lem}
\begin{proof}Take the canonical representation of both $f$ and $g$, $f
  = \sum_{i=1}^n c_i \characteristic{A_i}$ and $f
  = \sum_{i=1}^m d_i \characteristic{B_i}$.   Furthermore define $A_0 =
  \Omega \setminus \bigcup_{i=1}^n A_i$ and $B_0 =
  \Omega \setminus \bigcup_{i=1}^m B_i$.  Now consider all of the
  pairs $A_i \cap B_j$ and write 
\begin{align*}
f &= \sum_{i=0}^n \sum_{j=0}^m c_i
  \characteristic{A_i \cap B_j} \\
g &= \sum_{i=0}^n \sum_{j=0}^m d_j
  \characteristic{A_i \cap B_j}
\end{align*}
 where we have defined $c_0=d_0=0$.  Thus, we have the  representation 
\begin{align*}
af + bg = \sum_{i=0}^n \sum_{j=0}^m (ac_i + bd_j)   \characteristic{A_i \cap
  B_j}
\end{align*}
Since the $A_i  \cap B_j$ are pairwise disjoint, we can write
\begin{align*}
\int af+bg &= \int \sum_{i=0}^n \sum_{j=0}^m (ac_i + bd_j)   \characteristic{A_i \cap B_j} \\
&= \sum_{i=0}^n \sum_{j=0}^m (ac_i + bd_j)   \mu A_i \cap B_j \\
&= a \sum_{i=0}^n \sum_{j=0}^m c_i  \mu A_i \cap B_j + b \sum_{i=0}^n
\sum_{j=0}^m d_j  \mu A_i \cap B_j \\
&= a \int f + b \int g
\end{align*}

Using the same representation as above, we see that if $f \geq g$,
then since the $A_i \cap B_j$ are disjoint, we must have $c_i \geq
d_j$ whenever $A_i \cap B_j \neq \emptyset$.  This shows $\int f \geq
\int g$.
\end{proof}
\begin{cor}Given any representation of a simple function $f =
c_1 \characteristic{A_1} + \cdots + c_n \characteristic{A_n}$,
\begin{align*}
\int f  = c_1 \mu A_1 + \cdots + c_n \mu A_n
\end{align*} 
\end{cor}
The corollary above is used so often that we use it without mentioning
it and essentially treat it as the definition of the integral of a
simple function.

Having defined integrals of simple functions, we leverage the fact
that we can approximate positive measurable functions by increasing
sequences of simple functions to define the integral of a positive
measurable function.
\begin{defn}Given a measurable function $f : (\Omega, \mathcal{A},
  \mu) \to \overline{\reals}_+$, we define 
\begin{align*}\int f = \sup_{0 \leq g \leq f} \int g
\end{align*}
where the supremum is taken over positive simple functions $g$.
\end{defn}
Working with the supremum above is a bit inconvenient and it turns out
that it suffices to work with increasing sequences of positive simple
functions.  To see that we first need a lemma.
\begin{lem}Given a measurable function $f : (\Omega,
  \mathcal{A}, \mu) \to \overline{\reals}_+$, a sequence $0 \leq f_1, f_2, \dots$ of simple measurable
  functions such that $f_n \uparrow f$ and a simple measurable
  function $g$ such that $0 \leq g \leq f$, we have $\lim_{n \to \infty} \int f_n
  \, d\mu
  \geq \int g \, d\mu$.
\end{lem}
\begin{proof}Consider the case where $g = \characteristic{A}$ for $A
  \in \mathcal{A}$.  Pick $\epsilon > 0$, and define
\begin{align*}
A_n = \left \{ \omega \in A; f_n(\omega) \geq 1 - \epsilon \right \}
\end{align*}
Since $f_n$ is increasing, so is $A_n$.  Also it is simple to see that
$A_n \subset A$ since $f \geq f_n$ and $A \subset \bigcup_n A_n$ since
for each $\omega \in A$ convergence of $f_n(\omega) \uparrow
f(\omega)$ tells us that there is $N > 0$ such that for $n > N$, we
have $\abs{f_n(\omega) - f(\omega)} < \epsilon$, hence $A_n \uparrow
A$ and 
$\mu A_n \uparrow \mu A = \int g d \mu$.

Now the definition of $A_n$, the positivity of $f_n$ and the
positivity of integration tells us that
$\int f_n d \mu \geq (1 - \epsilon) \mu A_n$, so taking limits we see
\begin{align*}
\lim_{n \to \infty} \int f_n d \mu \geq (1 - \epsilon) \lim_{n \to
  \infty} \mu A_n = (1-\epsilon) \int g d \mu
\end{align*}
Now let $\epsilon \to 0$ to get the result.

To extend the result to arbitrary positive simple functions,  first consider $g
= c \characteristic{A}$ for $c > 0$.  Note that we can apply the
lemma to $\characteristic{A}$ and the functions $\frac{1}{c}f_n
\uparrow \frac{1}{c}f$, to see that $\lim_{n \to \infty}
\frac{1}{c}f_n \geq \mu A$ and multiply both sides by $c$.

Now consider a positive simple function in canonical form $g = c_1
\characteristic{A_1} + \cdots + c_m \characteristic{A_m}$.  Since $g$
is in the canonical form, $c_i > 0$ for $i=1, \dots, m$.  Also, $A_i \cap A_j = \emptyset$ for $i \neq j$
and therefore $g \characteristic{A_i}  = c_i \characteristic{A_i}$.
Now apply the lemma to each $g \characteristic{A_i} $ and the family
$f_n \characteristic{A_i}  \uparrow f \characteristic{A_i} $ and use
linearity of integral and limits.
\end{proof}
\begin{cor}Given a measurable positive function $f : (\Omega, \mathcal{A},
  \mu) \to \overline{\reals}_+$ and any sequence of positive simple functions $0 \leq f_1,
  f_2, \dots$ such that $f_n \uparrow f$, 
\begin{align*}
\int f d \mu = \lim_{n \to \infty} \int f_n d\mu
\end{align*}
\end{cor}
\begin{proof}As $f_n$ are positive simple functions with $f_n \leq f$
  we know each $\int f_n \leq \int f$ and therefore $\lim_{n \to \infty} \int f_n
  d\mu \leq \int f d \mu$.  

To see the other inequality, pick $\epsilon > 0$, and a positive
simple $0 \leq g \leq f$ such that $\int f d \mu - \epsilon \leq \int
g d \mu$.  Apply the above lemma and we see that $\int f d \mu - \epsilon \leq \int
g d \mu \leq \lim_{n \to \infty} \int f_n d \mu$.  Now let $\epsilon \to 0$ to see $\int f d \mu
\leq \int \lim_{n \to \infty} f_n d \mu$.
\end{proof}

\begin{lem}Given $f,g$ positive measurable and $a,b \geq 0$, 
\begin{align*}
\int \left ( a f + b g \right ) d \mu = a \int f d \mu + b \int g d \mu
\end{align*}
and if $f \geq g$,
\begin{align*}
\int f  d \mu \geq \int g d \mu
\end{align*}
\end{lem}
\begin{proof}Linearity follows by taking $0 \leq f_n \uparrow f$ and
  $0 \leq g_n \uparrow g$ and noting that $0 \leq a f_n + b g_n
  \uparrow a f + b g$.  Now apply linearity of integral of simple
  functions Lemma \ref{LinearityIntegralSimpleFunctions}.

Monotonicity follows immediately from noting that any simple $0 \leq h
\leq g$ also satisfies $0 \leq h \leq f$.
\end{proof}
Perhaps the most important basic theorems of measure theory are those
that describe how limits and integrals behave; in particular what
happens we exchange the order of limits and integrals.  There are three
commonly used variants and we are now ready to state and prove the
first.  Before we do that we illustrate three simple examples of the
things that can go wrong when we exchange the order of limits and
integrals.  All of these examples assume the existence of a measure
$\lambda$ on
$(\reals,\mathcal{B}(\reals))$ such that $\lambda([a,b]) = b -a$.  We
will prove later that such a measure exists (it is the \emph{Lebesgue
  measure} on $\reals$).
\begin{examp}[Escape to horizontal infinity]Consider the sequence of functions 
$f_n = \characteristic{[n,n+1]}$.  Note that $\lim_{n \to \infty}
\int f_n \, d \lambda = 1$ but $\int \lim_{n \to \infty}  f_n \, d
\lambda = 0$.
\end{examp}
\begin{examp}[Escape to vertical infinity]Consider the sequence of functions 
$f_n = n \characteristic{[0,\frac{1}{n}]}$.  Note that $\lim_{n \to \infty}
\int f_n \, d \lambda = 1$ but $\int \lim_{n \to \infty}  f_n \, d
\lambda = 0$.
\end{examp}
\begin{examp}[Escape to width infinity]Consider the sequence of functions 
$f_n = \frac{1}{n}\characteristic{[0,n-1]}$.  Note that $\lim_{n \to \infty}
\int f_n \, d \lambda = 1$ but $\int \lim_{n \to \infty}  f_n \, d
\lambda = 0$.
\end{examp}
 In all cases the integral of the limit is strictly less than the limit
of the integrals and in all cases some amount of \emph{mass} has
\emph{escaped to infinty}.  The limit theorems amount to proving the
fact that mass can only be lost when passing to the limit of a
sequence of measurable functions and establishing generally useful
hypotheses that prevent mass from escaping to infinity.

\begin{thm}\label{MCT}[Monotone Convergence Theorem]Given $f, f_1,
  f_2, \dots$ positive measurable functions from
  $(\Omega, \mathcal{A}, \mu)$ to $\overline{\reals}_+$ such that $0 \leq f_n \uparrow f$, we
  have $\int f_n d \mu \uparrow \int f d \mu$.
\end{thm}
\begin{proof}Choose an approximation of each $f_n$ by an increasing
  sequence of positive simple functions $g_{nk} \uparrow f_n$.  For
  each $n,k>0$, define $h_{nk} = g_{1k} \vee \cdots \vee g_{nk}$.
  Note that $h_{nk}$ is increasing in both of its subscripts.
  Furthermore, note that $h_{nk} \leq f_n$ because $g_{ik} \leq f_{i}
  \leq f_n$ for $i \leq n$ by the monotonicity of $f_n$.

We  claim that $h_{kk} \uparrow f$.  To see this, for every $n>0$,
  $h_{kk} \geq g_{nk}$ for $k \geq n$ and therefore
\begin{align*}
\lim_{k \to \infty} h_{kk} \geq \lim_{k \to \infty} g_{nk} = f_n
\end{align*}
By taking limits we get the inequality
\begin{align*}
\lim_{k \to \infty} h_{kk} \geq \lim_{n \to \infty} f_n = f
\end{align*}
We get the opposite inequality because $f_n$ increases to $f$, we know that for
every $k>0$, $h_{kk} \leq f_k \leq f$ and therefore $\lim_{k \to
  \infty} h_{kk} \leq f$.

We have an approximation of $0 \leq h_{kk} \uparrow f$ by simple
functions, now we can calculate the integral of $f$ using $h_{kk}$
\begin{align*}
\int f \, d\mu = \lim_{k \to \infty} \int h_{kk} \, d\mu \leq \lim_{k
  \to \infty} \int f_k \, d\mu \leq \int f \, d\mu
\end{align*}
where we have used the monotonicity of the integral in both
inequalities.  
\end{proof}
\begin{cor}\label{TonelliIntegralSum}[Tonelli's Theorem for Integrals
  and Sums]Given $f_1,
  f_2, \dots$ positive measurable functions from
  $(\Omega, \mathcal{A}, \mu)$ to $\overline{\reals}_+$, we
  have 
\begin{align*}
\int \sum_{n=1}^\infty f_n d \mu = \sum_{n=1}^\infty \int f_n \, d \mu
\end{align*}
\end{cor}
\begin{proof}Note that the sequence partial sums $\sum_{i=1}^n f_i$ is
  increasing in $n>0$.  Now use linearity of integral and apply the Montone Convergence Theorem.
\end{proof}

 In some cases, we may have a sequence of positive functions that are not known
to be increasing.  In those cases, limits may not even exists but we
still have a fundamental inequality
\begin{thm}\label{Fatou}[Fatou's Lemma]Given $f_1, f_2, \dots$
  positive measurable functions from
  $(\Omega, \mathcal{A}, \mu)$ to $\overline{\reals}_+$,
  then $\int \liminf_{n \to \infty} f_n d \mu \leq \liminf_{n \to
    \infty} \int f_n d \mu$.
\end{thm}
\begin{proof}The proof uses the Monotone Convergence Theorem.  To find
  an increasing sequence of positive measurable functions one needn't
  look further than the definition $\liminf_{n \to \infty} f_n =
  \lim_{n \to \infty} \inf_{k \geq n} f_k$.  Since $\inf_{k \geq n}
  f_k \uparrow \liminf_{n \to \infty} f_n$, we know by Monotone
  Convergence that $\lim_{n \to \infty} \int \inf_{k \geq n}
  f_k \, d \mu = \int \liminf_{n \to \infty} f_n \, d \mu$.  

However, we have the following calculation
\begin{align*}
\inf_{k \geq n} f_k &\leq f_k  & &\textrm{for all $k\geq n$ by
  definition of infimum} \\
\int \inf_{k \geq n} f_k \, d\mu &\leq \int f_k \,
d \mu & &\textrm{for all $k\geq n$ by
  monotonicity of integral} \\
\int \inf_{k \geq n} f_k \, d\mu &\leq \inf_{k \geq n} \int f_k \,
d \mu & &\textrm{by
  definition of infimum} \\
\lim_{n \to \infty} \int
\inf_{k \geq n} f_k \, d\mu &\leq \liminf_{n \to \infty} \int f_k \,
d \mu & &\textrm{taking limits and the
  definition of $\liminf$} \\
\int \liminf_{n \to \infty} f_n d \mu &= & & \textrm{by Monotone Convergence}
\end{align*}

In prose, by the  definition of the infimum $\inf_{k \geq n} f_k \leq f_k$ for every
  $k \geq n$, therefore monotonicity of the integral yields $\int
  \inf_{k \geq n} f_k d \mu \leq \int f_k d \mu$ for every
  $k \geq n$ and hence $\int
  \inf_{k \geq n} f_k d \mu \leq \inf_{k\geq n} \int f_k d \mu$.  Now
  take the limit as $n \to \infty$.
\end{proof}

Our last task is to eliminate the assumption of positivity in the
definition of the integral.  
\begin{defn}A measurable function $f$ on the measure space $(\Omega,
  \mathcal{A}, \mu)$ is \emph{integrable} if $\int \abs{f} \, d\mu <
  \infty$.  For any integrable $f$, we define $\int f \, d \mu = \int
  f_+ \, d\mu - \int f_{-} \, d \mu$.
\end{defn}

We've defined the integral of an integrable function in terms of a
canonical decomposition $f = f_+ - f_-$.  It is occasionally useful to
observe that any decomposition of an integrable function as a
difference of positive measurable functions can be used to calculate
the integral.
\begin{lem}Suppose we are given a measure space $(\Omega, \mathcal{A},
  \mu)$ and an integrable function $f : \Omega \to \reals$.  Suppose
  $f = f_1 -f_2$ where $f_i  : \Omega \to \reals$ are positive measurable
  with $\int f_i \, d \mu < \infty$. Then $\int f \, d\mu = \int f_1 \,
  d\mu - \int f_2 \, d\mu$.
\end{lem}
\begin{proof}Write $f = f_+ - f_-$ and note that $f_1 \geq f_+$ and
  $f_2 \geq f_-$.  For example either $f_+(\omega) = 0$ or
  $f_+(\omega) = f(\omega)$ and we know that $f_1(\omega) = f(\omega)
  + f_2(\omega) \geq f(\omega)$.  We also know that $f_1 - f_+ = f_2 -
  f_-$ and we can see that $\int (f_1 - f_+) \, d\mu = \int (f_2 - f_-) \, d\mu 
  < \infty$.  Therefore by
  linearity of integral
\begin{align*}
\int f \, d\mu &= \int f_+ \, d\mu - \int  f_- \, d\mu \\
&= \int f_+ \, d\mu + \int (f_1 - f_+) \, d\mu - \int (f_2 - f_-) \,
d\mu - \int  f_- \, d\mu \\
&= \int f_1 \, d\mu - \int  f_2 \, d\mu
\end{align*}
\end{proof}
Also linearity and monotonicity of integrals extend to the integrable
case.  Linearity of the integral subsumes the previous result.
\begin{lem}Suppose we are given a measure space $(\Omega, \mathcal{A},
  \mu)$ and integrable functions $f,g: \Omega \to \reals$.  The for
  $a,b \in \reals$ we have $\int (af + bg) \, d\mu = a\int f \, d\mu +
  b\int g \, d\mu$ and if $f \geq g$ then $\int f \, d\mu \geq \int g \, d\mu$.
\end{lem}
\begin{proof}
Write $f = f_+ - f_-$ and $g = g_+ - g_-$.  Define 
\begin{align*}
\hat{f}_\pm &= \begin{cases}
a f_\pm & \text{if $a  \geq 0$} \\
-a f_\mp & \text{if $a < 0$}
\end{cases}
\end{align*} 
It is easy to see that $\hat{f}_\pm \geq 0$,
$\int \hat{f}_\pm \, d\mu < \infty$,  $a f = \hat{f}_+ - \hat{f}_-$
and
\begin{align*}
\int af \, d\mu &= \int \hat{f}_+ \, d\mu - \int \hat{f}_- \, d\mu\\
&= \begin{cases}
\int a f_+ \, d\mu - \int af_- \, d\mu & \text{if $a \geq 0$} \\
\int -a f_- \, d\mu - \int -af_+ \, d\mu & \text{if $a < 0$} \\
\end{cases}\\
&= a \int f_+ \, d\mu - a \int f_- \, d\mu = a \int f\, d\mu
\end{align*}  
The same construction and
observations are true with $g$ and $\hat{g}_\pm$.
Then $a f + b g = (\hat{f}_+ + \hat{g}_+) - (\hat{f}_- + \hat{g}_-)$
and we have
\begin{align*}
\int (a f + b g) \, d\mu &= \int (\hat{f}_+ + \hat{g}_+) \, d\mu -
\int (\hat{f}_- + \hat{g}_-) \, d\mu \\
&= \int \hat{f}_+ \, d\mu - \int \hat{f}_- \, d\mu + \int \hat{g}_+ \, d\mu -
\int \hat{g}_- \, d\mu \\
&= a \int f \, d\mu + b \int g \, d\mu
\end{align*}

To see monotonicity, observe that $f \geq g$ if and only if $f_+ \geq
g_+$ and $f_- \leq g_-$.
\end{proof}

Lastly, it is occasionally necessary to deal with integrating
measurable functions that are either infinite on a set of measure zero
or undefined on a set of measure zero.  This is permissible by virtue
of the following Lemma.
\begin{defn}Let $(\Omega,  \mathcal{A}, \mu)$ be a measure space.  We
  say that a property hold \emph{almost everywhere} if the set where
  the property does not hold has measure zero.
\end{defn}
\begin{lem}\label{ZeroIntegralImpliesZeroFunction}Let $f \geq 0$ be a measurable function on $(\Omega,
  \mathcal{A}, \mu)$.  $\int f \, d\mu = 0$ if and only if $f = 0$
  almost everywhere.
\end{lem}
\begin{proof}Clearly this is true by definition for indicator
  functions.  It also is true by positivity and linearity of integral
  for simple functions.  For arbitrary $f\geq 0$, we take and
increasing  approximating sequence of simple functions $f_n \uparrow
f$ and note that $\int f \, d\mu = 0$ and monotonicity of integral
implies $\int f \, d\mu = 0$ for each $n$.  Therefore, $f_n = 0$ almost
everywhere for each $n$ and therefore $f_n = 0$ almost everywhere for
all $n$ by taking a countable union.  This implies $f = 0$ almost
everywhere. 
If on the other hand we assume that $f = 0$ almost
everywhere, then by the increasing nature of $f_n$, we see that $f_n
=0$ for all $n$ almost everywhere and therefore $\int f_n \, d\mu = 0$
for every $n$.  By Monotone Convergence we see that $\int f \, d\mu = 0$.
\end{proof}
Therefore, for the definition of integrability of $f$ can be extended
to allow $f$ to be redefined arbitrarily on a set of measure zero.
 
We have the following limit theorem for limits of integrable
functions.
\begin{thm}\label{DCT}[Dominated Convergence Theorem]Suppose we are given $f, f_1, f_2, \dots$ and $g,g_1,g_2,
  \dots$ measurable functions on $(\Omega,
  \mathcal{A}, \mu)$ such that $\abs{f_n} \leq g_n$, $\lim_{n \to
    \infty} f_n = f$, $\lim_{n \to
    \infty} g_n = g$ and $\lim_{n \to \infty} \int g_n \, d \mu  =
  \int g \, d \mu < \infty$.  Then $\lim_{n \to \infty} \int f_n \,
  d\mu = \int f \, d\mu$.
\end{thm}
\begin{proof}The trick here is to notice that by our assumption, $g_n
  \pm f_n \geq 0$ and we can apply Fatou's Lemma to both sequences.
  Doing so we get
\begin{align*}
\int g \, d\mu \pm \int f \, d\mu &= \int \lim_{n \to \infty} g_n \,
d\mu \pm \int \lim_{n \to \infty}  f_n \, d\mu \\
&=\int \liminf_{n \to \infty} g_n \,
d\mu \pm \int \liminf_{n \to \infty}  f_n \, d\mu \\
&=\int \liminf_{n \to \infty} \left (g_n  \pm  f_n \right ) \, d\mu \\
&\leq \liminf_{n \to \infty} \int \left (g_n  \pm  f_n \right ) \, d\mu \\
&= \liminf_{n \to \infty} \int g_n \, d\mu + \liminf_{n \to \infty} \int \pm  f_n  \, d\mu \\
&= \int g \, d\mu + \liminf_{n \to \infty} \int \pm  f_n  \, d\mu \\
\end{align*}
Now subtract $\int g \, d\mu$ from both sides of the equation and we
get two inequalities $\pm \int f \, d\mu \leq \liminf_{n \to \infty}
\int \pm  f_n  \, d\mu $.  It remains to put these two inequalities
together 
\begin{align*}
\limsup_{n \to \infty} \int f_n \, d\mu &= -\liminf_{n \to \infty}
\int -f_n \, d\mu \\
&\leq \int f \, d\mu \\
&\leq \liminf_{n \to \infty} \int f_n \, d\mu \\
\end{align*}
and the result is proved by the
obvious fact that $\liminf f_n \leq \limsup f_n$.
\end{proof}
Most applications of Dominated Convergence only use the special case in
which the sequence $g_n$ is constant.  We call out this special case
as a corollary of the general theorem.
\begin{cor}Suppose we are given $f, f_1, f_2, \dots$ and $g$ measurable functions on $(\Omega,
  \mathcal{A}, \mu)$ such that $\abs{f_n} \leq g$, $\lim_{n \to
    \infty} f_n = f$ and $\int g \, d \mu < \infty$.  Then $\lim_{n \to \infty} \int f_n \,
  d\mu = \int f \, d\mu$.
\end{cor}
\begin{proof}Let $g_n = g$ for all $n>0$ and use Theorem \ref{DCT}.
\end{proof}

\begin{lem}\label{PushforwardMeasure}Suppose we are given a measure space $(\Omega, \mathcal{A},
  \mu)$, a measurable space $(S, \mathcal{S})$ and measurable
  function $f : \Omega \to S$.  The function $\pushforward{f}{\mu} (A) =
  \mu(f^{-1}(A))$ defines a measure on $(S, \mathcal{S})$.  The
  measure $\pushforward{f}{\mu}$ is called the \emph{push forward} of
  $\mu$ by $f$.
\end{lem}
\begin{proof}Clearly, $\pushforward{f}{\mu} (\emptyset) = \mu(\emptyset) =
  0$.  
If we are given disjoint $A_1, A_2, \dots$ then by and the fact that $\mu$ is a measure,
we know 
\begin{align*}
\pushforward{f}{\mu} \left (\bigcup_{i=1}^\infty A_i \right ) & =
\mu \left (\bigcup_{i=1}^\infty f^{-1}(A_i) \right ) & & \text{by Lemma
\ref{SetOperationsUnderPullback}} \\
& = \sum_{i=1}^\infty \mu (f^{-1}(A_i)) & & \text{by countable
  additivity of measure}\\
&=  \sum_{i=1}^\infty \pushforward{f}{\mu} (A_i) & & \text{by
  definition of push forward}
\end{align*}
\end{proof}

\begin{defn}For a probability space $(\Omega, \mathcal{A}, P)$, a
  measurable space $(S, \mathcal{S})$ and a
  random element $\xi : \Omega \to S$, the measure $\pushforward{\xi}{P}$ is
  called the \emph{distribution} or \emph{law} of $\xi$.  We often
  write $\mathcal{L}(\xi)$ for the law of $\xi$.
\end{defn}
\begin{lem}[Change of Variables]\label{ChangeOfVariables}Suppose we are given a measure space $(\Omega, \mathcal{A},
  \mu)$, a measurable space $(S, \mathcal{S})$, and measurable
  functions $f : \Omega \to S$ and $g : S \to \reals$, then 
\begin{align*}
\int (g \circ f) \, d \mu = \int g \, d (\pushforward{f}{\mu})
\end{align*}
Whenever either side of the equality exists, the other does and they
are equal.
\end{lem}
\begin{proof}
To begin with we assume that $g = \characteristic{A}$ for $A \in
\mathcal{S}$.  The first simple claim is that $\characteristic{A}
\circ f = \characteristic{f^{-1}(A)}$.  This is seen by unfolding
definitions for an $\omega \in \Omega$:
\begin{align*}
(\characteristic{A} \circ f)(\omega) &= \characteristic{A} (f(\omega)) \\
&= \begin{cases}
1 &\text{if $f(\omega) \in A$}\\
0 &\text{if $f(\omega) \notin A$}
\end{cases}\\
&= \begin{cases}
1 &\text{if $\omega \in f^{-1}(A)$}\\
0 &\text{if $\omega \notin f^{-1}(A)$}
\end{cases}\\
&= \characteristic{f^{-1}(A)}(\omega)
\end{align*}
Using this fact the result of the theorem follows for
$\characteristic{A}$ by another simple calculation
\begin{align*}
\int \characteristic{A} \, d (\pushforward{f}{\mu}) &= (\pushforward{f}{\mu})(A)
\\
&= \mu(f^{-1}(A)) \\
&= \int \characteristic{f^{-1}(A)} \, d\mu \\
&= \int (\characteristic{A} \circ f) \, d\mu
\end{align*}

Next we assume that $g = c_1 \characteristic{A_1} + \cdots + c_n
\characteristic{A_n}$ is a simple function. As a general property of
the linearity of composition of functions we can see that 
\begin{align*}
g \circ f
&= c_1 (\characteristic{A_1} \circ f) + \cdots + c_n (\characteristic{A_n} \circ f)
\end{align*}
Coupling this with the result for indicator functions and linearity of
integral we get
\begin{align*}
\int g \, d (\pushforward{f}{\mu}) &= \sum_{i=1}^n c_i \int \characteristic{A_i} \, d (\pushforward{f}{\mu})
\\
&= \sum_{i=1}^n c_i \int (\characteristic{A_i} \circ f) \, d \mu \\
&=  \int \sum_{i=1}^n c_i (\characteristic{A_i} \circ f) \, d \mu \\
&= \int (g \circ f) \, d\mu
\end{align*}

Next we suppose that $g$ is a positive measurable function.  We know
that we can find an increasing sequence of positive simple functions
$g_n \uparrow g$.  Note that $g \circ f$ is positive measurable, $g_n
\circ f$ is positive simple and $g_n \circ f \uparrow g \circ f$.  Now
can use the result proven for simple functions and Monotone
Convergence 
\begin{align*}
\int g \, d(\pushforward{f}{\mu}) &= \lim_{n \to \infty} \int g_n
\, d(\pushforward{f}{\mu}) & &\text{ by Monotone Convergence} \\
&= \lim_{n \to \infty} \int (g_n \circ f)
\, d\mu & &\text{ by result for simple functions} \\
&=\int (g \circ f)
\, d\mu & &\text{ by Monotone Convergence} \\
\end{align*}

The last step is to consider an integrable $g$.  Write it as $g = g_+
- g_-$ for $g_\pm$ positive and use linearity of the integral and the
result just proven for positive functions.
\end{proof}

\begin{defn}Suppose we are given a measure space $(\Omega, \mathcal{A},
  \mu)$ and a positive measurable function $f : \Omega \to \reals_+$.
  We define the measure $f \cdot \mu$ by the formula
\begin{align*}
(f \cdot \mu)(A) = \int \characteristic{A} \cdot f \, d \mu = \int_A f
\, d\mu
\end{align*}
If $\nu$ is a measure of the above form, then we say that $f$ is a
$\mu$\emph{-density} of $\nu$.
\end{defn}
\begin{lem}\label{ChainRuleDensity}Suppose we are given a measure space $(\Omega, \mathcal{A},
  \mu)$, a positive measurable function $f : \Omega \to \reals_+$ and
  and measurable function $g : \Omega \to \reals$, then 
\begin{align*}
\int f g \, d \mu = \int g \, d (f \cdot \mu)
\end{align*}
Whenever either side of the equality exists, the other does and they
are equal.
\end{lem}
\begin{proof}First assume that $g=\characteristic{A}$ is an indicator
  function.  The result is just the definition of the measure $f \cdot
  \mu$:
\begin{align*}
\int \characteristic{A} \, d(f \cdot \mu) = (f \cdot \mu)(A) = \int \characteristic{A}
\cdot f \, d\mu
\end{align*}
Next assume that $g = \sum_{i=1}^n c_i \characteristic{A_i}$ is a
simple function.  Then we can simply apply linearity of the integral
\begin{align*}
\int g \, d(f \cdot \mu) &=\sum_{i=1}^n c_i \int \characteristic{A_i}
\, d(f \cdot \mu)\\
 &=\sum_{i=1}^n c_i \int \characteristic{A_i}\cdot f
\, d\mu  \\
 &=\int g\cdot f
\, d\mu  \\
\end{align*}
For a positive measurable $g$ we pick an increasing approximation by simple
functions $g_n \uparrow g$.  We note that for positive $f$ we have 
 $g_n \cdot f$ positive (not necessarily simple) with $g_n \cdot f \uparrow g \cdot f$.  Thus,
\begin{align*}
\int g \, d(f \cdot \mu) &= \lim_{n \to \infty} \int g_n \, d(f \cdot
\mu) & &\text{definition of integral}\\
&= \lim_{n \to \infty} \int g_n \cdot f \, d \mu & &\text{by result for
  simple functions}\\
&= \int g \cdot f \, d \mu & &\text{by Monotone Convergence}\\
\end{align*}
The last step is to pick an integrable $g = g_+ - g_-$ and use
linearity of integral.  Note also that in this case the two integrals
in question are defined for exactly the same $g$.
\end{proof}

\subsection{Standard Machinery}
We've put together a collection of definitions and tools for
talking about integration and proving theorems about integration.
What is probably not clear at this point is that there are some very
useful patterns for how these defintitions, lemmas and theorems are
used.  One such pattern is so commonplace that I have heard it called
the \emph{standard machinery}.  
Suppose one wants to show a result about general measurable
functions.  A proof of the result using the standard machinery proceeds by 
\begin{itemize}
\item[(i)]Demonstrating the result for indicator functions.
\item[(ii)]Arguing by linearity that the result holds for simple functions.
\item[(iii)]Showing the result holds for non-negative measurable
  functions by approximating by an increasing limit of simple
  functions and using the Monotone Convergence Theorem.
\item[(iv)]Showing the result for arbitrary functions by expressing an
  arbitrary measurable function as a difference of non-negative
  measurable functions.
\end{itemize}
The proof of Lemma \ref{ChangeOfVariables} and Lemma
\ref{ChainRuleDensity} are examples of proofs
using the standard machinery.  It is a good idea to get very
comfortable with such arguments as it is quite common in many texts to
leave any such proof as an exercise for the reader.  An important refinement of the standard machinery involves using a
monotone class argument with the $\pi$-$\lambda$ Theorem to demonstrate the result for all indicator
functions.  Recall that to do that, one shows that the collection of
sets whose indicator functions satisfy the theorem is a
$\lambda$-system and to then prove the result a $\pi$-system of sets
such that the $\pi$-system generates the $\sigma$-algebra of the
measurable space.
\section{Products of Measurable Spaces}

Given a collection of measurable spaces there is a standard
construction that makes the cartesian product of the spaces into a
measurable space.
\begin{defn}Suppose we are given an index set $T$ and for each $t \in
  T$ we have a measurable space $(\Omega_t, \mathcal{A}_t)$.  The
  \emph{product} $\sigma$\emph{-algebra} $\bigotimes_t \mathcal{A}_t$ on the cartesian product
  $\prod_t \Omega_t$ is the $\sigma$-algebra
  generated by all one dimensional \emph{cylinder sets} $A_t \times
  \prod_{s \neq t} \Omega_s$ for $A_t \in \mathcal{A}_t$.
\end{defn}

TODO: Show that this is the smallest $\sigma$-algebra that make the
projections measurable

TODO: Show that the countable product of Borel $\sigma$-algebras is the Borel
$\sigma$-algebra with respect to the product topology in the separable
case.  Note that the non-separable case is more subtle and in fact
turns out to be important (especially in statistics)!

\begin{prop}\label{BorelProductSigmaAlgebrasOnProductSpaces}Let $S_1, S_2, \dotsc$ be topological spaces then
  $\mathcal{B}(S_1) \otimes \mathcal{B}(S_2) \otimes \dotsb \subset
  \mathcal{B}(S_1 \times S_2 \times \dotsb)$.  If every $S_n$ is
  second countable then $\mathcal{B}(S_1) \otimes \mathcal{B}(S_2) \otimes \dotsb =
  \mathcal{B}(S_1 \times S_2 \times \dotsb)$.
\end{prop}
\begin{proof}
$\mathcal{B}(S_1) \otimes \mathcal{B}(S_2) \otimes \dotsb$ is the
$\sigma$-algebra generated by cylinder sets $A_n \times \prod_{m \neq
  n} S_m$ for $A_n \in \mathcal{B}(S_n)$ so it suffices to show that
such cylinder sets are in $\mathcal{B}(S_1 \times S_2 \times
\dotsb)$.  This is clearly true for the case of $A_n$ open since in
this case we have a cylinder set for the product topology.  On the
other hand the set of all $A_n \subset S_n$ for which $A_n \times \prod_{m \neq
  n} S_m \in \mathcal{B}(S_1 \times S_2 \times \dotsb)$ is easily seen
to be a $\lambda$-system so we may apply the $\pi$-$\lambda$ Theorem
\ref{MonotoneClassTheorem}.

On the other hand, assume that each $S_n$ is second countable.  It
follows that $S_1 \times S_2 \times \dotsb$ is second countable and
therefore every open set is a countable union 

TODO: Finish...  I think there is a result that $\mathcal{B}(S \times
S) = \mathcal{B}(S) \otimes \mathcal{B}(S)$ implies that $S$ is second
countable (check Van der Vaart and Wellner).
\end{proof}

The following is an important scenario that we shall often encounter.
Suppose we have a measurable space $(\Omega, \mathcal{A})$ and a
collection of measurable functions $f_t : \Omega \to (S_t,
\mathcal{S}_t)$.  From a purely set-theoretic point of view this
specification of functions is in fact
equivalent to the specification of a single function $f : \Omega \to
\prod_t S_t$ (i.e. if we let $\pi_s : \prod_t S_t \to S_s$ be the
projections then we define $\pi_s(f(\omega)) = f_s(\omega)$).  

\begin{lem}Given a collection of measurable functions $f_t : \Omega
  \to S_t$ and the equivalent function $f : \Omega \to \prod_t S_t$ we
  have $\sigma(\bigwedge_t \sigma(f_t)) = \sigma(f)$.
\end{lem}
\begin{proof}
To see that $\sigma(\bigwedge_t \sigma(f_t)) \subset \sigma(f)$ it
suffices to show that $\sigma(f_t) \subset \sigma(f)$ for all $t \in
T$.  This follows since for any $A_t \in \mathcal{S}_t$, we have
$f_t^{-1}(A) = f^{-1}(A \times  \prod_{s \neq t} \Omega_s)$.  This
fact also shows that $\sigma(f) \subset \sigma(\bigwedge_t
\sigma(f_t))$ since the cylinder sets $A \times  \prod_{s \neq t}
\Omega_s$ generate $\otimes_t \mathcal{S}_t$ by Lemma \ref{MeasurableByGeneratingSet}.
\end{proof}

TODO: Show that the collection $(f_{t_1}, \dotsc, f_{t_n}) \in A$ is a
$\pi$-system (which is clearly generating by the previous Lemma).  Use
this fact in Lemma \ref{ProcessLawsAndFDDs} and Theorem \ref{ExistenceMarkovProcess}.

\section{Null Sets and Completions of Measures}
\begin{lem}Let $f \geq 0$ be a measurable function then $\int f \,
  d\mu$ = 0 if and only if $f = 0$ $\mu$-almost everywhere.
\end{lem}
\begin{proof}
First suppose that $f$ is simple with canonical representation $f = c_1
\characteristic{A_1} + \dotsb +  c_n
\characteristic{A_n}$ where $c_i > 0$.  Then $\int f \, d\mu = c_1
\mu(A_1) + \dotsb +  c_n
\mu(A_n)$ and it follows the positivity of the $c_i$ that $\int f \, d\mu =0$ if and only if
$\mu(A_1) = \dotsb = \mu(A_n)$.

Now for a general non-negative measurable $f$ we can find simple $0
\leq f_n \uparrow f$ such that $\int f \, d\mu = \lim_{n \to \infty}
\int f_n \, d\mu$.  If $\int f\, d\mu = 0$ then by monotonicity of
integral and the result for simple functions we know that $f_n \neq 0$
almost everywhere.  Taking the countable union of sets of measure zero we know
that $f_n \neq 0$ for all $n$ on a set of measure zero and therefore
taking limits we conclude $f \neq 0$ on a set of measure zero.
Conversely if $f \neq 0$ on a set of measure zero then since $f_n$ is
an increasing sequence if follows that each $f_n \neq 0$ on a set of
measure zero and applying the result for simple functions $\int f_n \,
d\mu =0$ for all $n$.  Taking the limits of the integrals we see that
$\int f \, d\mu =0$.
\end{proof}

\begin{lem}Let $(\Omega, \mathcal{A}, \mu)$ be a measure space, let
  $\mathcal{F}$ be a sub $\sigma$-algebra of $\mathcal{A}$ and let
  $\mathcal{F}^{\mu}$ be the $\mu$-completion of $\mathcal{F}$.  The
  for every $A \in \mathcal{F}^{\mu}$ there exist $A_-, A_+ \in
  \mathcal{F}$ such that $A_- \subset A \subset A_+$ and $\mu(A_-) = \mu(A_+)$.
\end{lem}
\begin{proof}
TODO
\end{proof}

\section{Outer Measures and Lebesgue Measure on the Real Line}
To construct Lebesgue measure on the real line, one proceeds by
demonstrating that one may construct a measure by first constructing a more
primitive object called an outer measure and then proving that outer
measure become measures when restricted to an appropriate collection
of sets.  Having redefined the problem as the construction of outer
measure, one constructs outer measure on real line in a hands on way.

Much of this process that has broader applicability than just the real line,  therefore we state and prove the results
in the more general case.
TODO: Come up with some intuition about outer measure (more
specifically Caratheodory's characterizaiton of sets measurable with
respect to an outer measure; it says in some sense that a measurable
set and its complement have aren't \emph{too} entangled with one another).
\begin{defn}Given a set $\Omega$, an \emph{outer measure} is a
positive  function $\mu : 2^\Omega \to \overline{\reals}_+$ satisfying
\begin{itemize}
\item[(i)] $\mu(\emptyset) = 0$
\item[(ii)] If $A \subset B$, then $\mu(A) \leq \mu(B)$
\item[(iii)] Given $A_1, A_2, \dots \subset \Omega$, then $\mu \left
    (\bigcup_{i=1}^\infty A_i \right ) \leq \sum_{i=1}^\infty \mu(A_i)$.
\end{itemize}
\end{defn}

\begin{defn}Given a set $\Omega$ with outer measure $\mu$, we say a
  set $A \subset \Omega$ is $\mu$\emph{-measurable} if for every $B
  \subset \Omega$,
\begin{align*}
\mu(B) = \mu(A \cap B) + \mu(A^c \cap B)
\end{align*}
\end{defn}

\begin{rem}For every $A,B \subset \Omega$, we have from finite
  subadditivity of outer measure
\begin{align*}
\mu(B) = \mu((A \cap B) \cup (A^c \cap B)) \leq \mu(A \cap B) + \mu(A^c \cap B)
\end{align*}
and therefore to show $\mu$-measurability we only need to show the
reverse inequality.
\end{rem}

\begin{lem}\label{CaratheodoryRestriction}Given a set $\Omega$ with an outer measure $\mu$, let
$\mathcal{A}$ be the collection of $\mu$-measurable sets.  Then
$\mathcal{A}$ is a $\sigma$-algebra and the
  restriction of $\mu$ to $\mathcal{A}$ is a measure.
\end{lem}
\begin{proof}We first note that $A \in \mathcal{A}$ if and only if $A^c
  \in \mathcal{A}$ since the defining condition of $\mathcal{A}$ is
  symmetric in $A$ and $A^c$.

Next we show $\emptyset \in \mathcal{A}$.  To see this,
  take $B \subset \Omega$,
\begin{align*}
\mu(B) &= \mu(\emptyset) + \mu(B) & &\text{since $\mu(\emptyset) = 0$}
\\
& = \mu(\emptyset \cap B) + \mu(B \cap \Omega)
\end{align*}

Next we show that $\mathcal{A}$ is closed under finite intersection.
Pick $A, B \in \mathcal{A}$ and $E \subset \Omega$ and calculate
\begin{align*}
\mu(E) &= \mu(E \cap A) + \mu(E \cap A^c) & &\text{since $A \in
  \mathcal{A}$} \\
&= \mu(E \cap A \cap B) + \mu(E \cap A \cap B^c) +\mu(E \cap A^c) & &\text{since $B \in
  \mathcal{A}$} \\
&\geq \mu(E \cap (A \cap B)) + \mu(E \cap A \cap B^c \cup E \cap A^c)
& & \text{by subadditivity} \\
&\geq \mu(E \cap (A \cap B)) + \mu(E \cap (A \cap B)^c)
& & \text{by monotonicity of $\mu$} \\
\end{align*}
and we have noted that it suffices to show this inequality to show $A
\cap B \in \mathcal{A}$.  Now by De Morgan's Law we conclude that
$\mathcal{A}$ is closed under finite union.

Now we turn to consider the behavior of $\mu$ and show that $\mu$ is
finitely and countably additive over disjoint unions; in fact we show
a bit more.
We let $A,B \in \mathcal{A}$ and let $E \subset \Omega$
be disjoint.
\begin{align*}
\mu(E \cap (A \cup B)) &= \mu(E \cap (A \cup B) \cap A) + \mu(E \cap
(A \cup B) \cap A^c) & & \text{since $A \in \mathcal{A}$} \\
&= \mu(E \cap A) + \mu(E \cap B) & &\text{by set algebra}
\end{align*}
It is easy to see that one can do induction to extend the above result
to all finite disjoint unions.
Now let $A_1, A_2, \dots \in \mathcal{A}$ and $E \subset \Omega$.
Define $U_n = \bigcup_{i=1}^n A_i$ and $U = \bigcup_{i=1}^\infty A_i$.
\begin{align*}
\mu(E \cap U) &\geq \mu(E \cap U_n) & & \text{by monotonicity} \\
&= \sum_{i=1}^n \mu(E \cap A_i) & &\text{by finite additivity and
  disjointness of $A_i$}
\end{align*}
Now take the limit we have $\mu(E \cap U) \geq \sum_{i=1}^\infty \mu(E
\cap A_i)$.  Applying subadditivity of $\mu$ we get the opposite
inequality and we have shown 
\begin{align*}
\mu(E \cap \bigcup_{i=1}^\infty A_i) = \sum_{i=1}^\infty \mu(E
\cap A_i)
\end{align*}
In particular, we can take $E=\Omega$ to show that $\mu$ is countably
additive over disjoint unions.

Having shown how to calculate $\mu$ over countable disjoint unions, we
can show that $U \in \mathcal{A}$. For every $n > 0$,
\begin{align*}
\mu(E) &= \mu(E \cap U_n) + \mu(E \cap U_n^c) \\
&\geq \sum_{i=1}^n \mu(E \cap A_i) + \mu(E \cap U) & & \text{by
  subadditivity and monotonicity} \\
\end{align*}
Take the limit and use the previous claim to see
\begin{align*}
\mu(E) &\geq \sum_{i=1}^\infty \mu(E \cap A_i) + \mu(E \cap U) \\
&= \mu(E \cap U) + \mu(E \cap U^c)
 \end{align*}
thereby showing $U \in \mathcal{A}$.

The last thing to show is that a countable union of elements of
$\mathcal{A}$ are in $\mathcal{A}$.  This follows from what we have
shown about countable
disjoint unions since we have already proven this for complements, finite unions
and intersections and therefore for any $A_1,A_2, \dots$ we can define
$B_n = A_n \setminus \bigcup_{i=1}^{n-1} A_i$ so that
$\bigcup_{i=1}^\infty A_i =\bigcup_{i=1}^\infty B_i$ with the $B_i$ disjoint.
\end{proof}

To define \emph{Lebesgue measure} on $\reals$ we will leverage the
construction above and first define an outer measure by approximating
by intervals.  Given an interval $I \subset \reals$, let $\abs{I}$ be
length of $I$.
\begin{thm}\label{LebesgueMeasure}[Lebesgue Measure]There exists a
  unique measure $\lambda$ on $(\reals, \mathcal{B}(\reals)$ such that
  $\lambda(I) = \abs{I}$ for all intervals $I \subset \reals$.
\end{thm}
Before we begin the proof of the theorem we need first construct an
outer measure.
\begin{lem}\label{LebesgueOuterMeasure}[Lebesgue Outer Measure]Define the function $\lambda : 2^\reals \to \reals$ defined by 
\begin{align*}
\lambda(A) &= \inf_{\{I_k\}} \sum_k \abs{I_k} 
\end{align*}
where the infimum ranges over countable covers of $A$ by intervals.
Then $\lambda$ is
an outer measure.  In addition, $\lambda(I) = \abs{I}$ for every
interval $I \subset \reals$.
\end{lem}
\begin{proof}It is clear that $\lambda$ is positive and $\lambda(\emptyset) = 0$.  It is also
  clear that $\lambda$ is increasing since for any $A \subset B
  \subset \reals$ any cover of $B$ is also a cover of $A$.  

To see subadditivity, take $A_1, A_2, \dots \subset \reals$.  Pick
$\epsilon > 0$ and then for each $A_n$ we take a countable cover by intervals
$I_{n1}, I_{n2}, \dots$ such that $\lambda(A_n) \geq \sum_{k=1}^\infty
\abs{I_{nk}} - \frac{\epsilon}{2^n}$.  Then, the collection of
intervals $I_{nk}$ for $n,k > 0$ is an countable cover of
$\bigcup_{i=1}^\infty A_i$ and therefore
\begin{align*}
\lambda \left (\bigcup_{i=1}^\infty A_i \right ) &\leq
\sum_{n=1}^\infty \sum_{k=1}^\infty \abs{I_{nk}} \\
&\leq \sum_{n=1}^\infty \left ( \lambda(A_n) + \frac{\epsilon}{2^n}
\right )\\
&= \sum_{n=1}^\infty \lambda(A_n) + \epsilon
\end{align*}
Now let $\epsilon \to 0$ and we have proven subadditivity.

To prove that $\lambda(I) = \abs{I}$, we first consider intervals of
the form $I = [a,b]$ with $a < b$.  The family of intervals $(a -
\epsilon, b+\epsilon)$ for $\epsilon > 0$ shows that $\lambda{I} \leq
\abs{I}$ so we only need to show the opposite inequality.
Suppose we are given a countable cover by open intervals $I_1, I_2,
\dots$.  We need to show that $\abs{I} \leq \sum_{k=1}^\infty \abs{I_k}$.
By the Heine-Borel Theorem (Theorem \ref{HeineBorel}), there
is a finite subcover $I_1, \dots, I_n$ and it suffices to show
that $\abs{I} \leq \sum_{k=1}^n \abs{I_k}$ for the finite subcover.

For finite covers we
can proceed by induction.  To begin, consider a cover by a single
interval.  For any $J \supset I$ we know that
$\abs{J} \geq \abs{I}$.

For the induction step, assume that $\inf_{\{I_k\}} \sum_{k=1}^n
\abs{I_k} = \abs{I}$ where the infimum is over covers by $n$
intervals.  Take a cover of $I$ by $n+1$ intervals $I_1, \dots,
I_{n+1}$.  There exists an $I_k$ such that $b \in I_k$.  If we write
$I_k = (a_k,b_k)$, then the rest of the $I_j$ form a cover of
$[a,a_k]$.
\begin{align*}
\abs{I} &= (b-a_k) + (a_k - a) \\
&\leq \abs{I_k} + \sum_{m \neq k} \abs{I_m} & &\text{by induction
  hypothesis applied to $[a,a_k]$} \\
&=\sum_m \abs{I_m}
\end{align*}
It remains to eliminate the restriction to bounded closed intervals.
Clearly every cover of 
$[a,b]$ by open intervals is a cover of $(a,b)$.  On the other hand, every countable cover of $(a,b)$ can be extended to a countable cover of $[a,b]$ by adding
at most two arbitrarily small intervals of the form
$(a-\epsilon,a+\epsilon)$ and $(b-\epsilon,b+\epsilon)$.  An
\emph{epsilon of room} argument shows that $\lambda (a,b) = \lambda
[a,b]$.  Monotonicity of $\lambda$ shows the same is true for half
open intervals.


TODO: Show that outer measure of infinite intervals is infinite.
\end{proof}

\begin{defn}A subset $A \subset \reals$ is \emph{Lebesgue measurable}
  if $A$ is $\lambda$-measurable with respect to the Lebesgue outer measure.
\end{defn}

\begin{lem}\label{BorelsAreLebesgueMeasurable}Every Borel measurable $A \subset \reals$ is also Lebesgue measurable.
\end{lem}
\begin{proof}Since we know that the collection of Lebesgue measurable
  sets is a $\sigma$-algebra, and we know that the Borel algebra on
  $\reals$ is generated by intervals of the form $(-\infty, x]$, it
  suffices to show that each such interval is Lebesgue measurable.

Take an interval $I=(-\infty, x]$, a set $E \subset \reals$ and
$\epsilon > 0$.  Pick a countable covering $I_1, I_2, \dots$ of $E$ by
open intervals so that
$\lambda(E) + \epsilon \geq \sum_{k=1}^\infty \abs{I_k} $.
\begin{align*}
\lambda(E) + \epsilon &\geq \sum_{k=1}^\infty \abs{I_k} \\
&=\sum_{k=1}^\infty \abs{I_k \cap I}  + \sum_{k=1}^\infty \abs{I_k \cap I^c} \\
&=\sum_{k=1}^\infty \lambda(I_k \cap I) + \sum_{k=1}^\infty
\lambda(I_k \cap I^c) \\
&\geq \lambda \left ( \bigcup_{k=1}^\infty I_k \cap I \right )
+\lambda \left ( \bigcup_{k=1}^\infty I_k \cap I^c \right ) &
&\text{by subadditivity} \\
&\geq \lambda(E \cap I) + \lambda(E \cap I^c)
\end{align*}
where the last line holds because $I_k \cap I$ is a countable cover of
$E \cap I$ and similarly for $E \cap I^c$.  Now let $\epsilon \to 0$
to get the result.

TODO: Actually $I_k \cap I$ are half open intervals.  The proof needs
to be extended 
to handle this fact.  Presumably an $\frac{\epsilon}{2^n}$ argument
works here.  Note most definitions of Lebesgue outer measure do not
restrict to open covers (then you have to pay the cost of the
$\frac{\epsilon}{2^n}$ argument to apply Heine Borel).
\end{proof}

\begin{lem}[Uniqueness of measure]\label{UniquenessOfMeasure}Let $(\Omega, \mathcal{A}, \mu)$ be a measure space with
  $\mu$ a finite measure.  Suppose $\nu$ is a finite
  measure on
  $(\Omega, \mathcal{A})$ such that there is a $\pi$-system
  $\mathcal{C}$ such that $\sigma(\mathcal{C})=\mathcal{A}$, $\Omega \in \mathcal{C}$ and for all $A \in
  \mathcal{C}$ we have $\mu(A) = \nu(A)$, then $\mu=\nu$.

If we assume that $\mu$ a $\sigma$-finite measure and $\nu$ is a 
$\sigma$-finite measure such that there exists a partition $\Omega =
\Omega_1 \cup \Omega_2 \cup \cdots$ with $\mu(\Omega_n) =
\nu(\Omega_n) < \infty$, the result holds as well.
\end{lem}
\begin{proof}
First we assume that $\mu$ (and then by hypothesis $\nu$) is finite.
We apply a monotone class
argument.  Consider the collection $\mathcal{D}$ of $A \in
\mathcal{A}$ such that $\mu(A) = \nu(A)$.  We claim that
this collection is a $\lambda$-system.  Since we have assumed
$\mu(\Omega) = \nu(\Omega)$ we have that $\Omega \in \mathcal{D}$.  Now suppose $A
\subset B \in \mathcal{D}$.  By additivity of measure and finiteness
of $\mu$ and $\nu$,
\begin{align*}
\mu(B \setminus A) = \mu(B) - \mu(A) = \nu(B) -\nu(A) =
\nu(B \setminus A)
\end{align*}
Now we assume $A_1 \subset A_2 \subset \cdots \in \mathcal{D}$.  By
continuity of measure (Lemma \ref{ContinuityOfMeasure}) 
\begin{align*}
\mu \left ( \bigcup_i A_i \right ) = \lim_{n \to \infty} \mu(A_i) = \lim_{n \to \infty} \nu(A_i) =
\nu \left ( \bigcup_i A_i \right )
\end{align*}
Application of the $\pi$-$\lambda$ Theorem (Theorem
\ref{MonotoneClassTheorem}) together with the fact that
$\sigma(\mathcal{C}) = \mathcal{A}$ shows that equality holds on all
of $\mathcal{A}$.

Now we handle to the $\sigma$-finite case.  We a partition
$\Omega=\Omega_1 \cup \Omega_2 \cup \cdots$ such that $\mu(\Omega_n) =
\nu(\Omega_n) < \infty$ for all $n$.  Denote $\mu_n$ and
$\nu_n$ the restriction of $\mu$ and $\nu$ to the set $\Omega_n$.  We
note that $\mu_n$ and $\nu_n$ each satisfy the hypothesis of the lemma
for the finite measure case (e.g. $\mu_n(A) = \mu(\Omega_n \cap A)$).  Therefore
we can conclude that $\mu_n = \nu_n$ on all of $\mathcal{A}$ for all
$n$.  For any
$A \in \mathcal{A}$ define $A_n = \cup_{k=1}^n \Omega_k \cap A$ note
that 
\begin{align*}
\mu (A_n) = \sum_{k=1}^n \mu_k(A) = \sum_{k=1}^n \nu_k(A)  = \nu(A_n)
\end{align*}
and $A_1 \subset A_2 \subset \cdots $ with $\cup_{n=1}^\infty A_n =
A$.  Now apply continuity of measure (Lemma \ref{ContinuityOfMeasure}) to see that $\mu(A)=\nu(A)$.
\end{proof}

TODO: Do we need to assume that there is a partition with
$\mu(\Omega_n) = \nu(\Omega_n)$ or can it be derived from the fact
that $\sigma(\mathcal{C}) = \mathcal{A}$.  Is suspect it can be
derived but the applications we have in mind it is trivial to generate
the partition by hand.

 Now we are ready to prove the existence and uniqueness of Lebesgue
measure (Theorem \ref{LebesgueMeasure}).

\begin{proof}The existence of Lebesgue measure clearly follows from
  Lemma \ref{CaratheodoryRestriction} applied to the outer measure
  constructed in Lemma \ref{LebesgueOuterMeasure}.  The fact that the
  $\sigma$-algebra of the restriction contains the Borel sets follows
  from Lemma \ref{BorelsAreLebesgueMeasurable}.

It remains to show uniqueness.  Now clearly the collection of intervals is closed under finite
intersections hence is a $\pi$-system that generates
$\mathcal{B}(\reals)$.  Furthermore, $\reals =
\cup_{n=-\infty}^\infty (n, n+1]$ so we may apply Lemma
\ref{UniquenessOfMeasure} to get uniqueness.
\end{proof}

\begin{defn}A measure space $(\Omega, \mathcal{A}, \mu)$ is
  \emph{$\sigma$-finite} if there exists a countable partition $\Omega
  = \Omega_1 \cup \Omega_2 \cup \cdots$ such that $\mu(\Omega_i) < \infty$.
\end{defn}

\subsection{Abstract Version of Caratheodory Extension}
The construction of Lebesgue measure we have given actually has a
broad generalization which we present here.

\begin{defn}A non-empty collection $\mathcal{A}_0$ of subsets of a set
  $\Omega$ is called a \emph{Boolean  algebra} if given any $A, B
  \in \mathcal{A}_0$ we have
\begin{itemize}
\item[(i)]$A^c \in \mathcal{A}_0$
\item[(ii)]$A \cup B \in \mathcal{A}_0$
\item[(iii)]$A \cap B \in \mathcal{A}_0$
\end{itemize}
\end{defn}

Note that it is trivial induction argument to extend the closure
properties to arbitrary finite unions and intersections.

\begin{defn}A \emph{pre-measure} on a Boolean algebra $(\Omega, \mathcal{A}_0)$ is
  a function $\mu_0 : \mathcal{A}_0 \to \overline{\reals}_+$ such that 
\begin{itemize}
\item[(i)]$\mu_0(\emptyset) = 0$
\item[(ii)]For any $A_1, A_2, \dotsc \in \mathcal{A}_0$ such that the
  $A_n$ are disjoint and 
  $\cup_{n=1}^\infty A_n \in \mathcal{A}_0$, we have
  $\mu_0(\cup_{n=1}^\infty A_n) = \sum_{n=1}^\infty \mu_0(A_n)$.
\end{itemize}
\end{defn}

\begin{lem}A pre-measure is finitely additive and montonic.  That is to say given
  any disjoint $A_1, \dotsc, A_n \in \mathcal{A}_0$ we have
  $\mu_0(\cup_{i=1}^n A_i) = \sum_{i=1}^n \mu_0(A_i)$ and given $A
  \subset B$ with $A, B \in \mathcal{A}_0$, we have $\mu_0(A) \leq \mu_0(B)$.
\end{lem}
\begin{proof}
Finite additivity follows by extending the finite sequence to an infinite sequence by appending
copies of the emptyset and using the fact that $\mu_0(\emptyset)=0$.  Monotonicity follows from finite additivity by writing $B = A \cup
B\setminus A$ so that $\mu_0(B) = \mu_0(A) + \mu_0(B\setminus A) \geq \mu_0(A)$.
\end{proof}

Our goal is to show that any pre-measure on a Boolean algebra
$\mathcal{A}_0$ may be
extended to a measure on a $\sigma$-algebra containing
$\mathcal{A}_0$.  We proceed in four steps
\begin{itemize}
\item[1)] Define an outer measure $\mu^*$ from $\mu_0$
\item[2)] Show that all sets in $\mathcal{A}_0$ are $\mu^*$-measurable.
\item[3)] Show that for all sets $A \in \mathcal{A}_0$, $\mu^*(A) = \mu_0(A)$.
\item[4)] Use the Caratheodory restriction to create a
  $\sigma$-algebra and measure.
\end{itemize}

\begin{lem}\label{PremeasureToOuterMeasure}Given a pre-measure $\mu_0$ on a Boolean algebra $(\Omega,
  \mathcal{A}_0)$ then the set function $\mu^* : 2^\Omega \to
  \overline{\reals}_+$ defined by
\begin{align*}
\mu^*(A) &= \inf \lbrace \sum_{n=1}^\infty \mu_0(A_n) \mid A \subset
\cup_{n=1}^\infty A_n \text { and } A_n \in \mathcal{A}_0 \text{ for
  all $n$} \rbrace
\end{align*}
is an outer measure.
\end{lem}
\begin{proof}
Because $\mu_0(\emptyset)$ and $\emptyset \subset \emptyset$ we see
that $\mu^*(\emptyset) = 0$.

Suppose we are given $A \subset B$.  Then if we have a cover $B
\subset \cup_{n=1}^\infty B_n$ where $B_n \in \mathcal{A}_0$, then
this is also a cover of $A$.  Therefore $\mu^*(A)$ is an infimum over
a larger collection of covers than that used in calculating $\mu^*(B)$
hence $\mu^*(A) \leq \mu^*(B)$ (we could actually pick an $\epsilon$
and an approximating cover as below then let $\epsilon \to 0$).

Now to show subadditivity.  Let $A_1, A_2, \dotsc$ be a sequence of
arbitrary subsets of $\Omega$.  If any $\mu^*(A_n) = \infty$ then we
automatically know $\mu^*(\cup_{n=1}^\infty A_n) \leq \sum_{n=1}^\infty \mu^*(A_n)$, so we
may assume that all $\mu^*(A_n) < \infty$.  Let $\epsilon > 0$ be
given and for each $n$ we pick $B_{1n}, B_{2n}, \dotsc$ such that $A_n
\subset \cup_{m=1}^\infty B_{mn}$ and $\sum_{m=1}^\infty \mu_0(B_{mn})
\leq \mu^*(A_n) + \frac{\epsilon}{2^n}$.  Now, we also have that
$\cup_{n=1}^\infty A_n
\subset  \cup_{n=1}^\infty \cup_{m=1}^\infty B_{mn}$ and therefore we
know that $\mu^*(\cup_{n=1}^\infty A_n) \leq \sum_{n=1}^\infty \sum_{m=1}^\infty
\mu_0(B_{mn}) \leq \sum_{n=1}^\infty \mu^*(A_n) + \epsilon$.  Since
$\epsilon$ was arbitrary, we have $\mu^*(\cup_{n=1}^\infty A_n) \leq \sum_{n=1}^\infty
\mu^*(A_n)$ so subadditivity is proven.
\end{proof}

\begin{lem}\label{PremeasureBooleanAlgebraOuterMeasurable}Given a pre-measure $\mu_0$ on a Boolean algebra $(\Omega,
  \mathcal{A}_0)$ and the outer measure $\mu^*$ constructed in Lemma
  \ref{PremeasureToOuterMeasure}, if $A \in \mathcal{A}_0$ then $A$ is
  $\mu^*$-measurable.
\end{lem}
\begin{proof}
Let $A \in \mathcal{A}_0$ and $B \subset \Omega$ and we have to show
$\mu^*(B) \geq \mu^*(A \cap B) + \mu^*(A^c \cap B)$. 
Pick $B_1, B_2, \dotsc$ such that $B_n \in \mathcal{A}_0$ for all $n$
and $\sum_{n=1}^\infty \mu_0(B_n) \leq \mu^*(B) + \epsilon$.  By
finite additivity of $\mu_0$ and the fact that $A, B_n \in \mathcal{A}_0$,
we can write $\mu_0 (B_n) = \mu_0(A \cap B_n) + \mu_0(A^c \cap B_n)$
and therefore $\sum_{n=1}^\infty \mu_0(A \cap B_n) + \sum_{n=1}^\infty
\mu_0(A^c \cap B_n) \leq \mu^*(B) + \epsilon$.  On the other hand, we
know that $A \cap B \subset \cup_{n=1}^\infty A \cap B_n$ so $\mu^*(A
\cap B) \leq \sum_{n=1}^\infty \mu_0( A \cap B_n)$ and similarly with
$A^c$.  Therefore $\mu^*(A \cap B) + \mu^*(A^c \cap B)\leq \mu^*(B) + \epsilon$.
Take the limit as $\epsilon$ goes to zero and we are done.
\end{proof}

\begin{lem}\label{PremeasureOuterMeasureEqual}Given a pre-measure $\mu_0$ on a Boolean algebra $(\Omega,
  \mathcal{A}_0)$ and the outer measure $\mu^*$ constructed in Lemma
  \ref{PremeasureToOuterMeasure}, if $A \in \mathcal{A}_0$ then $\mu^*(A)=\mu_0(A)$.
\end{lem}
\begin{proof}
Suppose we are given $A \in \mathcal{A}_0$.  Since $A$ is a singleton
cover of itself, we know that $\mu^*(A) \leq \mu_0(A)$.  It remains to
show $\mu_0(A) \leq \mu^*(A)$.  If $\mu^*(A) =\infty$ then this is
trivally true so we may assume $\mu^*(A) < \infty$.  Let $\epsilon
>0$ be given and pick $A_1, A_2, \dotsc \in \mathcal{A}_0$ such that
$A \subset \cup_{n=1}^\infty A_n$ and 
$\sum_{n=1}^\infty \mu_0(A_n) \leq \mu^*(A) + \epsilon$.  Our goal now
is to shrink each of the $A_n$ so that we wind up with a partition of
$A$.  Then we will be able to apply the countable additivity of pre-measures.

First, we convert the cover by $A_n$ into a disjoint cover of $A$.  Let
$B_1 = A_1$ and then define $B_n = A_n \setminus (A_1 \cup \cdots \cup
A_{n-1})$ for $n>1$.
By construction, the $B_n$ are disjoint and $\cup_{i=1}^n B_i =
\cup_{i=1}^n A_i$.  Furthermore $B_n \subset A_n$ so by monotonicity
of $\mu_0$ we have $\mu_0(B_n) \leq \mu_0(A_n)$.  Now have $A \subset
\cup_{n=1}^\infty B_n$ with $B_n$ disjoint, $B_n \in \mathcal{A}_0$
for all $n$  and $\sum_{n=1}^\infty
\mu_0(B_n) \leq \mu^*(A) + \epsilon$.  

Lastly we convert the disjoint cover $B_n$ into a partitioning of $A$.  
Consider $C_n = B_n \cap A$.  We still have $C_n \in
\mathcal{A}_0$, $C_n$ disjoint and montonicity implies $\sum_{n=1}^\infty
\mu_0(C_n) \leq \mu^*(A) + \epsilon$.  But now we have
$\cup_{n=1}^\infty C_n = A \in \mathcal{A}_0$ so we may apply
countable additivity of premeasure to conclude $\mu_0(A) = \sum_{n=1}^\infty
\mu_0(C_n) \leq \mu^*(A) + \epsilon$.  Once again, $\epsilon$ was
arbitrary so let it go to zero and we are done.
\end{proof}


TODO: construction that takes us from a semiring to a Boolean algebra.
It is often convenient to start a construction of a measure with a
collection of sets that is so small that it doesn't even form a
Boolean algebra.  For example when constructing Lebesgue measure on
$\reals$ we were really motivated by a desire that the measure of an
interval $(a,b]$ should be $b-a$, yet the set of such intervals on
$\reals$ is not a Boolean algebra.
\begin{defn}A set $\mathcal{D} \subset 2^\Omega$ is called a
  \emph{semiring} if 
\begin{itemize}
\item[(i)]$\emptyset \in \mathcal{D}$
\item[(ii)]if $A, B \in \mathcal{D}$ then $A \cap B \in \mathcal{D}$
\item[(iii)]if $A, B \in \mathcal{D}$ then there exist disjoint $C_1,
  \dotsc, C_n \in \mathcal{D}$ such that $A \setminus B = \cup_{j=1}^n
  C_j$
\end{itemize}
\end{defn}

\begin{examp}The set of intervals $(a,b]$ with $a \leq b$ is a
  semiring.  To be excruciatingly explicit we have the formulae
\begin{align*}
(a,b] \cap (c,d] &= (a\vee c, (b \wedge d) \vee a \vee c]
\intertext{and}
(a,b] \setminus (c,d] &= (a \wedge c, (a \vee c) \wedge b \wedge d]
\cup a \vee c \vee (b \wedge d), c \vee d]
\end{align*}
\end{examp}

TODO: Other constructions of semirings (e.g. products)

\begin{defn}A set $\mathcal{R} \subset 2^\Omega$ is called a
  \emph{ring} if 
\begin{itemize}
\item[(i)]$\emptyset \in \mathcal{R}$
\item[(ii)]if $A, B \in \mathcal{R}$ then $A \cup B \in \mathcal{R}$
\item[(iii)]if $A, B \in \mathcal{R}$ then $A \setminus B \in \mathcal{R}$
\end{itemize}
\end{defn}

\begin{lem}\label{RingFromSemiring}If $\mathcal{D}$ is a semiring then $\mathcal{R} = \lbrace
  \cup_{j=1}^n C_j \mid C_j \in \mathcal{D} \text{ and the $C_j$ are
    disjoint} \rbrace$ is a ring.  Furthermore it is the smallest ring
  containing $\mathcal{D}$.
\end{lem}
\begin{proof}
The fact that $\emptyset \in \mathcal{R}$ is immediate.  Suppose we
are given $\cup_{i=1}^n A_i$ and $\cup_{j=1}^m B_j$ in
$\mathcal{R}$. Then we have
\begin{align}
\left ( \cup_{i=1}^n A_i \right ) \cap \left ( \cup_{j=1}^m B_j \right
) &= \cup_{i=1}^n \cup_{j=1}^m A_i \cap B_j
\end{align}
which is in $\mathcal{R}$ because each $A_i \cap B_j \in \mathcal{D}$
and they are disjoint by the disjointness since each of $A_i$ and
$B_j$ is a disjoint set of sets.  

We also have 
\begin{align}
\left ( \cup_{i=1}^n A_i \right ) \setminus \left ( \cup_{j=1}^m B_j \right
) &=\left ( \cup_{i=1}^n A_i \right ) \cap \left ( \cup_{j=1}^m B_j \right
)^c \\
&=\cup_{i=1}^n \cap_{j=1}^m A_i \cap B_j^c \\
&=\cup_{i=1}^n \cap_{j=1}^m A_i \setminus B_j
\end{align}
and we know that each $A_i \setminus B_j \in \mathcal{D}$ and we know
that $\mathcal{D}$ is closed under finite intersections thus
$\cap_{j=1}^m A_i \setminus B_j \in \mathcal{D}$.  Furthermore by
disjointness of $A_i$ we have that $\cap_{j=1}^m A_i \setminus B_j$
are disjoint and therefore we have shown that $\left ( \cup_{i=1}^n A_i \right ) \setminus \left ( \cup_{j=1}^m B_j \right
) \in \mathcal{R}$.

To see that $\mathcal{R}$ is the smallest ring containing
$\mathcal{D}$ note simply that it is a ring and any ring containing
$\mathcal{D}$ must contain all of the finite disjoint unions of
elements in $\mathcal{D}$.
\end{proof}

\begin{examp}\label{RingOfDisjointUnionHalfOpenIntervals}The set of disjoint unions of intervals $(a,b]$ with $a \leq b$ is a
  ring.  This follows from the general result Lemma
  \ref{RingFromSemiring} but later on we shall have some use for the
  explicit formula
\begin{align*}
&(a,b] \cup (c,d] \\
&= (a \wedge c, (a \vee c) \wedge b \wedge d] \cup (a \vee c, (b
\wedge d) \vee a \vee c]
\cup a \vee c \vee (b \wedge d), c \vee d]
\end{align*}
which decomposes a union of half open intervals into a disjoint union
of half open intervals.
\end{examp}
 
To connect up the concept of rings with that of Boolean algebras we
have the following result.
\begin{lem}Let $\mathcal{R}$ be a ring and define $\mathcal{R}^c =
  \lbrace A^c \mid A \in \mathcal{R}\rbrace$.  Then $\mathcal{A} =
  \mathcal{R} \cup \mathcal{R}^c$ is a Boolean algebra and is the
  Boolean algebra generated by $\mathcal{R}$.  If $\mathcal{R}$ is a
  $\sigma$-ring then $\mathcal{R} \cup \mathcal{R}^c$ is the
  $\sigma$-algebra generated by $\mathcal{R}$.
\end{lem}
\begin{proof}Since Boolean algebras are closed under set complement it
  suffices to show that $\mathcal{A} = \mathcal{R} \cup \mathcal{R}^c$ is a Boolean
  algebra (respectively $\sigma$-algebra).  Closure under set
  complement is immediate from construction.  Closure under set
  intersection follows from handling the three possible cases
\begin{itemize}
\item[(i)]if $A, B \in \mathcal{R}$ then $A\cap B \in \mathcal{R}
  \subset \mathcal{A}$ since $\mathcal{R}$ is a ring.
\item[(ii)]if $A \in \mathcal{R}$ and $B \in \mathcal{R}^c$ then
  $A\cap B = A \cap (B^c)^c = A \setminus B^c \in \mathcal{R}
  \subset \mathcal{A}$ since $B^c \in \mathcal{R}$ and $\mathcal{R}$ is a ring.
\item[(iii)]if $A, B \in \mathcal{R}^c$ then $A \cap B = (A^c \cup
  B^c)^c \in \mathcal{R}^c
  \subset \mathcal{A}$ since $A^c, B^c \in \mathcal{R}$ and $\mathcal{R}$ is a ring.
\end{itemize}
Closure under finite set union follows as usual from De Morgan's Law.

Now if $\mathcal{R}$ is a $\sigma$-ring then 

TODO: Finish
\end{proof}

We have the following result for $\sigma$-rings that is analagous to
Lemma \ref{SigmaAlgebraPullback} proven for $\sigma$-algebras.
\begin{lem}\label{SigmaRingPullback}Given an arbitrary set function $f
  : S \to T$ and $\sigma$-rings $\mathcal{S}$ and $\mathcal{T}$ on
  $S$ and $T$ respectively 
\begin{itemize}
\item[(i)] $\mathcal{S}^\prime = f^{-1} \mathcal{T}$ is a
  $\sigma$-ring on $S$.
\item[(ii)] $\mathcal{T}^\prime = \left \{A \subset T ; f^{-1}(A) \in
      \mathcal{S} \right \}$ is a $\sigma$-ring on $T$.
\end{itemize}
\end{lem}
\begin{proof}
The proof of Lemma \ref{SigmaAlgebraPullback} shows closure under
countable union and intersection.  From these two facts, closure under
set difference follows by writing $B \setminus A = B \cap A^c$.
\end{proof}
 TODO: We have proven abstract Caratheodory construction in the
language of Boolean algebras; fill in a gap that shows that a
countably additive function on a ring actually defines a premeasure as
defined above.

\begin{lem}Let $\mu$ be an additive function on a semiring $\mathcal{D}$.  Let
  $\mu(\cup_{i=1}^n A_i) = \sum_{i=1}^n \mu(A_i)$ for any disjoint
  $A_1, \dotsc, A_n \in \mathcal{D}$.  Then $\mu$ is well defined and
  finitely additive on
  the ring $\mathcal{R}$ generated by $\mathcal{D}$.  If $\mu$ is
  countably additive on $\mathcal{D}$ then $\mu$ is countably additive
  on $\mathcal{R}$ and extends to a measure on $\sigma$-algebra
  generated by $\mathcal{D}$.
\end{lem}
\begin{proof}
\end{proof}

\subsection{Product Measures and Fubini's Theorem}

Prior to showing how to construct product measures, we need a
technical lemma.
\begin{lem}[Measurability of Sections]\label{MeasurableSections}Let $(S, \mathcal{S}, \mu)$ be a measure space with $\mu$ a
  $\sigma$-finite measure, let $(T, \mathcal{T})$ be a measurable
  space and $f : S \times T \to \reals_+$ be a positive $\mathcal{S} \otimes \mathcal{T} $-measurable
  function.  Then
\begin{itemize}
\item[(i)]$f(s,t)$ is an $\mathcal{S}$-measurable function of $s \in
  S$ for every fixed $t \in T$.
\item[(ii)] $\int f(s,t) \,  d \mu(s)$ is $\mathcal{T}$-measurable for
  as a function of $t \in T$.
\end{itemize}
\end{lem}
\begin{proof}
To see (i) and (ii),  let us first assume that $\mu$ is a bounded measure.  The proof uses
the standard machinery.  First assume that $f(s,t)
= \characteristic{B \times C}$ for $B \in \mathcal{S}$ and $C \in
\mathcal{T}$. Then note that for fixed $t \in T$, $f(s,t) = \characteristic{B}$ if $t
\in C$ and $f(s,t) = 0$ otherwise; in both cases we see that $f$ is
$\mathcal{S}$-measurable.  Also we calculate, $\int \characteristic{B
  \times C} (s,t) \,  d \mu(s) = \characteristic{C} (t)\int
\characteristic{B} (s) \,  d \mu(s) = \mu(B) \characteristic{C} (t) $
which clearly $\mathcal{T}$-measurable since $\mu(B) < \infty$.

Observe that the set of sets $B \times C$ is a $\pi$-system.  Let
\begin{align*}
\mathcal{H} = \lbrace A \in \mathcal{S} \otimes \mathcal{T} \mid
\characteristic{A}(s,t) \text{ is $\mathcal{S}$-measurable for every
  fixed $t \in T$ and $\int \characteristic{A}(s,t) \, d\mu(s)$ is $\mathcal{T}$-measurable } \rbrace
\end{align*}
and we claim that $\mathcal{H}$ is a $\lambda$-system.  Clearly $S
\times T \in \mathcal{H}$ from what we have already shown.  Suppose
next that $A \subset B$ are both in $\mathcal{H}$.  Note that
$\characteristic{B \setminus A} = \characteristic{B} -
\characteristic{A}$ so each section is a difference of
$\mathcal{S}$-measurable functions hence $\mathcal{S}$-measurable.
Similarly, 
\begin{align*}
\int \characteristic{B \setminus A} (s,t) \, d\mu(s) &= \int
\characteristic{B} (s,t) \, d\mu(s) - \int
\characteristic{A} (s,t) \, d\mu(s) 
\end{align*}
is a difference of $\mathcal{T}$-measurable function hence
$\mathcal{T}$-measurable.

Lastly, suppose that $A_1 \subset A_2 \subset \cdots \in
\mathcal{H}$.  Then $\characteristic{A_i} \uparrow \characteristic{\bigcup A_i}$ and this statement is true when considering each
function as a function on $S \times T$ but also for every
section with fixed $t \in T$.  Hence every section is a increasing limit of $\mathcal{S}$-measurable
functions and therefore $\mathcal{S}$-measurable.  Also we can apply
Montone Convergence Theorem to see that 
\begin{align*}
\int \characteristic{\bigcup A_i}(s,t) \, d\mu(s) = \lim_{n \to
  \infty} \int \characteristic{A_i}(s,t) \, d\mu(s)
\end{align*}
which shows $\mathcal{T}$-measurability.
Now the
$\pi$-$\lambda$ Theorem shows that $\mathcal{H} =  \mathcal{S} \otimes
\mathcal{T}$ and we have the result for all indicators.  

Next, linearity of taking sections and integrals shows that all simple functions
also satisfy the theorem.  Lastly for a general positive $f(s,t)$ we
take an increasing sequence of simple functions $f_n \uparrow f$.
Again, the limit is taken pointwise so every section of $f$ is the
limit of the sections of $f_n$ each of which has been shown
$\mathcal{S}$-measurable.  As the limit of $\mathcal{S}$-measurable
functions, we see that every section $f$ is also
$\mathcal{S}$-measurable.  Since for a fixed $t \in T$, $f_n(s,t)$ is
increasing as a function of $s$ alone we apply the Monotone
Convergence Theorem to see that
\begin{align*}
\int f(s,t) \, d\mu(s) = \lim_{n \to \infty} \int f_n(s,t) \, d\mu(s)
\end{align*}
which shows $\mathcal{T}$-measurability of $\int f(s,t) \, d\mu(s)$
since it is a limit of $\mathcal{T}$-measurable functions.

Now let $\mu$ be a $\sigma$-finite measure on $S$.  Then there is a
disjoint partition $S_1, S_2, \dots$ of $S$ such that $\mu S_n <
\infty$.  Thus, $\mu_n (A) = \mu(A \cap S_n)$ defines a bounded
measure and we know from Lemma \ref{ChainRuleDensity} that for any
measurable $g$, $\int g \, d\mu_n = \int g
\characteristic{S_n} \, d\mu$.
Putting these observations together,
\begin{align*}
\int f(s,t) \,  d \mu(s) &= \int f(s,t) \sum_{n=1}^\infty
\characteristic{S_n}(s) \,  d \mu(s) & & \text{since $S_n$ is a partition
  of $S$} \\
&= \sum_{n=1}^\infty \int f(s,t) 
\characteristic{S_n}(s) \,  d \mu(s) & & \text{by Corollary 
  \ref{TonelliIntegralSum} } \\
&= \sum_{n=1}^\infty \int f(s,t) \,  d \mu_n(s) 
\end{align*}
Since each $\mu_n$ is bounded, we have proven that each $\int f(s,t) \,  d \mu_n(s) $ is
$\mathcal{T}$-measurable hence the same is true for the partial sums
by linearity and then the infinite sum by taking a limit.
\end{proof}

TODO: Come up with an example of a non-measurable function for which all sections are measurable.

\begin{thm}[Fubini-Tonelli Theorem]\label{Fubini}Let $(S, \mathcal{S}, \mu)$
  and $(T, \mathcal{T}, \nu)$ be two $\sigma$-finite measure spaces.
  There exists a unique measure $\mu \otimes \nu$ on $(S \times T,
  \mathcal{S} \otimes \mathcal{T})$ satisfying 
\begin{align*}
(\mu \otimes \nu)(B \times C) &= \mu B \cdot \nu C & &\text{ for all
  $B \in \mathcal{S}$, $C \in \mathcal{T}$.}
\end{align*}
In addition if $f : S \times T \to \reals_+$ is a positive measurable
function then 
\begin{align*}
\int f(s,t) \,  d (\mu \otimes \nu) = \int \left [ \int f(s,t) \, d
\nu(t) \right ] d \mu(s)  = \int \left [ \int f(s,t) \, d \mu(s)
\right ] d\nu(t)
\end{align*}
This last sequence of equalities also holds if $f : S \times T \to \reals$
is measurable and integrable with respect to $\mu \otimes \nu$.
\end{thm}
\begin{proof}Note that the class of sets of the form $A \times B$ for
  $A \in \mathcal{S}$ and $B \in \mathcal{T}$ is clearly a
  $\pi$-system and generates $\mathcal{S} \otimes \mathcal{T}$ by
  definition of the product $\sigma$-algebra.  Furthermore by
  $\sigma$-finiteness of both $\mu$ and $\nu$ we can construct a
  disjoint partition $S \times T = \cup_i \cup_j S_i \times T_j$ with
  $\mu(S_i)\nu(T_j) < \infty$.  Therefore we can apply Lemma
  \ref{UniquenessOfMeasure} to see that the property $(\mu \otimes
  \nu)(A \times B) = \mu(A) \nu(B)$ uniquely determines $\mu \otimes
  \nu$.

To show existence of such a measure, define 
\begin{align*}
(\mu \otimes \nu)(A) = \int \left [\int \characteristic{A}(s,t) \, d
  \nu(t) \right ] d \mu(s)
\end{align*}
The fact that the iterated integrals are well defined follows from
Lemma \ref{MeasurableSections}.  
To see that it is a measure, first
note that it is simple to see $(\mu \otimes \nu)(\emptyset) = 0$.

To prove countable additivity, suppose we are given disjoint $A_1,
A_2, \dots \in \mathcal{S}
\otimes \mathcal{T}$.  By disjointness, we know
$\characteristic{\bigcup_{i=1}^\infty A_i} = \sum_{i=1}^\infty \characteristic{A_i}$.
Now because indicator functions and the inner integrals are positive, we can interchange
integrals and sums twice (Corollary \ref{TonelliIntegralSum}) and get
\begin{align*}
(\mu \otimes \nu)(\bigcup_{i=1}^\infty A_i) &= \int \left [ \int
\characteristic{\bigcup_{i=1}^\infty A_i}(s,t) \, d \nu(t) \right ] d \mu(s)\\
&= \int \left [ \int \sum_{i=1}^\infty \characteristic{A_i}(s,t) \, d
  \nu(t) \right ]  d \mu(s)\\
&= \sum_{i=1}^\infty \int \left [ \int \characteristic{A_i}(s,t) \, d
  \nu(t) \right ] d \mu(s)\\
\end{align*}

It is also clear that for $A = B \times C$ with $B \in \mathcal{S}$
and $C \in \mathcal{T}$, 
\begin{align*}
(\mu \otimes \nu)(B \times C) &= \int \left [ \int \characteristic{B}(s)
\characteristic{C}(t) \, d\nu(t) \right ] d \mu(s)\\
&= \int \characteristic{B}(s) \, d \mu(s) \cdot \int 
\characteristic{C}(t) \, d\nu(t) \\
&= \mu B \cdot \nu C
\end{align*}
Therefore we have proven the existence of the product measure.

The argument proving existence of the product measure applies equally well if we reverse the order
of $\mu$ and $\nu$ and shows that 
\begin{align*}
(\mu \otimes \nu)(B \times C) = \int \left [ \int \characteristic{B
    \times C}(s,t) \, d
\nu(t) \right ] d \mu(s) = \int \left [ \int \characteristic{B \times C}(s,t)
\, d \mu(s) \right ] d \nu(t)
\end{align*}
which proves that the integrals are equal for indicator functions of
sets of the form $B \times C$ and therefore for all indicator
functions by the montone class argument we used at the beginning of
the proof.  At this point, the
standard machinery can be deployed.  Linearity of integrals easily
shows that the equality extends to simple functions.  Lastly suppose
we have a positive measurable function $f(s,t) : S \times T \to
\overline{R}_+$ with a sequence of positive simple functions
$f_n(s,t) \uparrow f(s,t)$.  By the Monotone Convergence Theorem and
monotonicity of integral we know that 
\begin{align*}
0 &\leq \int f_n(s,t) \, d\mu(s) \uparrow \int f(s,t) \, d\mu(s) \\
0 &\leq \int f_n(s,t) \, d\nu(t) \uparrow \int f(s,t) \, d\nu(t) \\
\end{align*}
and therefore we have
\begin{align*}
\int f(s,t) \,  d (\mu \otimes \nu) 
&= \lim_{n \to \infty} \int
 f_n(s,t) \,  d (\mu \otimes \nu)  & & \text{by definition of integral
   of $f$}\\
&= \lim_{n \to \infty} \int \left [
\int f_n(s,t) \,  d \mu(s) \right ] d\nu(t) & &\text{by Tonelli
for simple functions}\\
&= \int \left [
\int f(s,t) \,  d \mu(s) \right ] d\nu(t) & &\text{by Monotone Convergence
   on $\int f_n \, d \mu(s)$}\\
\end{align*}

It is worth pointing out explicitly that even if $f(s,t)$ is never
equal to infinity, the integrals may be equal to infinity on all of
$S$ or $T$ and it is critical that we have phrased the theory of
integration for positive functions in terms of functions with values
in $\overline{\reals}_+$.

TODO: Clean up the following argument; it has all right details but is
more than a bit ragged.  Particularly annoying is that this is the
first time we've talked about defining integrals for signed functions
that take infinite values on a set of measure zero.

Now assume that $f$ is integrable with respect to $\mu \otimes \nu$: 
$\int \abs{f(s,t)} \,  d (\mu \otimes \nu) < \infty$.  We
write $f = f_+ - f_-$ and note that $\int f_\pm(s,t) \,  d (\mu
\otimes \nu) < \infty$ and use Tonelli's Theorem just proven to see
that 
\begin{align*}
\int f_\pm(s,t) \,  d (\mu \otimes \nu) &= \int \left [ \int f_\pm(s,t) \, d
\nu(t) \right ] d \mu(s)  = \int \left [ \int f_\pm(s,t) \, d \mu(s)
\right ] d\nu(t) < \infty
\end{align*}
The finiteness of the iterated integrals implies that the integrands
are almost surely finite and therefore we see that each section 
$\int f_\pm \, d\mu(s)$ and $\int f_\pm \, d\nu(t)$ is almost surely
finite.  The trick is that being almost surely finite isn't good
enough when trying to calculate the iterated integrals of $f$ and we
might run into the awkward situation in which there is a $t \in T$
such that \emph{both} $\int f_+ \, d\mu(s)$ and $\int f_+ \, d\mu(s)$
are infinite.  However define
$N_S = \{ s \in S \mid \int \abs{f} \, d\nu(t) = \infty \}$ and $N_T =
\{ t \in T \mid \int \abs{f} \, d\mu(s) = \infty \}$.  We have noted
that $N_S$ is a $\mu$-null set and that $N_T$ is a $\nu$-null set
hence $N_S \times N_T$ is a $(\mu \otimes \nu)$-null set.  We modify
$f$ so that it is zero on $N_S \times N_T$ by defining 
$\tilde{f}(s,t) = (1 - \characteristic{N_S \times N_T}) f(s,t)$.  Note
the following 
\begin{align*}
\int \tilde{f} d(\mu\otimes \nu) &= \int f d(\mu\otimes \nu) \\
\int \tilde{f} d\mu(s) &= \begin{cases}
\int f d\mu(s) & \text{if $t \notin N_T$} \\ 
0 & \text{if $t \in N_T$} \\ 
\end{cases} \\
\int \tilde{f} d\nu(t) &= \begin{cases}
\int f d\nu(t) & \text{if $s \notin N_S$} \\ 
0 & \text{if $s \in N_S$} \\ 
\end{cases}
\end{align*}
Now we can write $\tilde{f} = \tilde{f}_+ - \tilde{f}_-$ and apply
Tonelli's Theorem to see
\begin{align*}
\int \tilde{f} d(\mu\otimes \nu) &= \int \tilde{f}_+ d(\mu\otimes \nu)
- \int \tilde{f}_- d(\mu\otimes \nu) \\
&= \int \left [ \int \tilde{f}_+ d\mu(s)\right ] d \nu(t) - \int \left
  [ \int \tilde{f}_- d\mu(s)\right ] d \nu(t) \\
&= \int \left [  \int \tilde{f}_+ d\mu(s) - \int \tilde{f}_-
d\mu(s) \right ] d \nu(t) \\
&= \int \left [ \int \tilde{f} d\mu(s)\right ] d \nu(t) \\
\end{align*}

But we know $\int \left [ \int \tilde{f} d\mu(s)\right ] d \nu(t) =
\int \left [ \int f d\mu(s)\right ] d \nu(t)$ so we get the result for
$f$ as well.
\end{proof}

TODO: Royden has some exercises that demonstrate how each of these
hypotheses is necessary (e.g. Counterexample to Fubini for
non-integrable f).  Incorporate them.
\begin{examp}Define the measure space $(\naturals, 2^\naturals,
  \mu)$ where $\mu(A) = \card{A}$.  $\mu$ is called the \emph{counting
    measure}.  
Consider the function 
\begin{align*}
f(s,t) &= \begin{cases}
2 - 2^{-s+1} & \text{if $s=t$}\\
-2 + 2^{-s+1} & \text{if $s = t + 1$} \\
0 & \text{otherwise}
\end{cases}
\end{align*}
on $(\naturals \times \naturals, 2^{\naturals \times \naturals}, \mu
\otimes \mu)$.  Since $\mu \otimes \mu$ is the counting measure on
$\naturals \times \naturals$ it is easy to see that 
\begin{align*}
\int \abs{f(s,t)} \, d ( \mu \otimes \mu) &= \sum_{s=1}^\infty
\sum_{t=1}^\infty \abs{f(s,t)} = \infty
\end{align*}
so $f$ is not integrable.  However in this case both of the iterated
integrals are defined.
For fixed $t$, 
\begin{align*}
\int f(s,t) \, d\mu(s) &=
\sum_{s=1}^\infty f(s,t) = 2^{-t} - 2^{-t+1} = -2^{-t}
\end{align*}
hence 
\begin{align*}
\int \left [ \int f(s,t) \, d\mu(s) \right ] d \mu(t) &=
\sum_{t=1}^\infty -2^{-t} = -1
\end{align*}

For fixed $s$, 
\begin{align*}
\int f(s,t) \, d\mu(s) &=
\sum_{t=1}^\infty f(s,t) = \begin{cases}
1 & \text {if $s=1$}\\
0 & \text {otherwise}
\end{cases}
\end{align*}
and therefore 
\begin{align*}
\int \left [ \int f(s,t) \, d\mu(t) \right ] d \mu(s) &= 1
\end{align*}
This example shows that the positivity of $f$ is a necessary condition
in Tonelli's Theorem and that the assumption of integrability is
necessary in Fubini's Theorem.
\end{examp}


TODO
Outer measures, Caratheodory construction, Lesbegue Measure (existence
and uniqueness), Product Measures and Fubini's Theorem, Radon-Nikodym Theorem and
Fundamental Theorem of Calculus, Differential Change of Variables for
Lebesgue Measure on $\reals^n$ (useful for calculations involving
probability densities).

\begin{lem}[Translation Invariance of Lebesgue Measure]\label{LesbegueTranslationInvariance} Suppose $\mu$ is a measure on $\reals^n$ which is
  translation invariant and for which $\mu([0,1]^n) = 1$, then $\mu =
  \lambda^n$.
\end{lem}
\begin{proof}Suppose we are given a translation invariant measure
  $\mu$ such that $\mu([0,1]^n) = 1$.  By writing boxes as a
  union of cubes and using finite
  and countable additivity together with translation invariance it is
  easy to see that
  for any box $\mathcal{I}_1 \times \cdots \times \mathcal{I}_n$ where
  each $\mathcal{I}_k$ has rational endpoints that we have 
\begin{align*}
\mu\left (\mathcal{I}_1 \times \cdots \times
    \mathcal{I}_n \right ) &= \abs{\mathcal{I}_1} \cdots
  \abs{\mathcal{I}_n} \\
 &= \lambda^n \left (\mathcal{I}_1 \times \cdots \times
    \mathcal{I}_n \right )
\end{align*}
Now fix $\mathcal{I}_2, \dots ,\mathcal{I}_n$ and consider $\nu(A) = \frac{1}{ \abs{\mathcal{I}_2} \cdots  \abs{\mathcal{I}_n}}\mu \left
  (A \times \mathcal{I}_2 \times \cdots \times
    \mathcal{I}_n \right ) $ as a function of $A \in
  \mathcal{B}(\reals)$.  It is easy to see that this is a Borel
  measure and we have already seen that $\nu(\mathcal{I}) =
  \abs{\mathcal{I}}$ for all rational intervals (hence all intervals
    by countable additivity).  Therefore $\nu = \lambda$ is Lebesgue
    measure on $\mathcal{B}(\reals)$ and we have for every $B_1 \in
    \mathcal{B}(\reals)$,
\begin{align*}
\mu\left (B_1 \times \mathcal{I}_2 \times\cdots \times
    \mathcal{I}_n \right ) 
 &= \lambda^n \left (B_1 \times \mathcal{I}_2 \times \cdots \times
    \mathcal{I}_n \right )
\end{align*}
Now iterate the argument $2, \cdots, n$ fixing all but the $i^{th}$
argument to extend to all cylinder sets $B_1 \times \cdots \times B_n$
and we apply the uniqueness of product measures.

Now it remains to show that $\lambda^d$ is indeed translation
invariant.
TODO
\end{proof}
\begin{cor}\label{LesbegueRotationInvariance} Lebesgue measure $\lambda^n$ on $\reals^n$ is invariant
  under orthogonal transformations.
\end{cor}
\begin{proof}Suppose we are given an orthogonal transformation $P$.
  We claim that the measure $\lambda^n_P(A) = \lambda^a(P A)$ is
  translation invariant.   To see this, assume we are given $h \in
  \reals^n$ and note that 
\begin{align*}
\lambda^n_P(A + h) &= \lambda^n(P A + Ph)  & &\text{linearity of $P$} \\
&= \lambda^n(PA) & &\text{translation invariance of $\lambda^n$} \\
&= \lambda^n_P(A) & &\text{definition of $\lambda^n_P$}
\end{align*}
Therefore we know that $\lambda^n_P = c \lambda^n$ for some constant
$c>0$.  Take the unit ball $B^n \subset \reals^n$ and notice that $P
B^n = B^n$ to see that in fact $c = 1$.
\end{proof}
\begin{cor}\label{LesbegueLinearChangeOfVariables}[Linear Change of Variables]For an arbitrary linear transformation $T : \reals^n \to
  \reals^n$, $\lambda^n(T A) = \abs{\det{T}} \lambda^n(A)$ for all
  measurable $A$.
\end{cor}
\begin{proof}Note that by the Singular Value Decompostion, we can
  write $T = U D V$ with $U,V$ orthogonal.  By the rotation invariance
  of $\lambda^n$, we are reduced to the case of a diagonal matrix.  In
  that case, the result is easy.
TODO write down the easy stuff too!
\end{proof}
\section{Radon-Nikodym Theorem and Differentiation}
We have seen the construction of measures by integration of a
density.  A productive line of inquiry is to ask if one can
characterize measures that arise through this construction and those
that cannot arise through this construction.  As it
turns out an precise answer may be given for $\sigma$-finite measures;
this is the content of the Radon-Nikodym Theorem.  If one restricts
attention to $\reals$ and considers the Fundamental Theorem of
Calculus for Riemann integrals
\begin{align*}
\frac{d}{dx} \int_0^x f(y) \, dy = f(x)
\end{align*}
one can surmise that there is a connection between the considerations
of the Radon-Nikodym Theorem and the theory of differentiation of
integrals.  This is indeed the case and we will prove the extension of
the Fundamental Theorem of Calculus to Lebesgue integrals using the
Radon-Nikodym Theorem.  Note that it is probably more traditional to
explore the theory of differention of functions of a real variable
without using the more abstract Radon-Nikodym Theorem but if one
intends to cover both one can save some time by proceeding in the way
we have chosen (stolen unabashedly from Kallenberg).

The first step is to develop a couple of tools that may be used to
compare two measures.  The trick is that if one takes the difference
of two measure, one does not get a measure.  However there is a clever
observation that helps to repair the defect.  
\begin{defn}A \emph{ bounded signed measure} on a measurable space $(\Omega,
  \mathcal{A})$ is a bounded function $\nu : \mathcal{A} \to
  \reals$ such that $\nu(\emptyset) = 0$ and for every disjoint $A_1, A_2, \dots \in
  \mathcal{A}$ such that $\sum_{n=1}^\infty \abs{\nu (A_n)}  < \infty$, we have $\nu(\bigcup_{n=1}^\infty A_n ) =
  \sum_{n=1}^\infty \nu (A_n)$ 
\end{defn}
Note that a bounded signed measure is finitely additive (just take infinitely many copies of the empty set use countable additivity).
It is important to note that a bounded signed measure is continuous in
the same way that an ordinary measure is.
\begin{prop}\label{ContinuityOfSignedMeasure}Let $\nu$ be a bounded
  signed measure on the measurable space $(\Omega,  \mathcal{A})$.
If $A, A_1, A_2, \dotsc \in \mathcal{A}$, $\sum_{n=1}^\infty \abs{\nu(A_n \setminus A_{n-1})} < \infty$ and $A_n \uparrow A$ then $\nu(A) = \lim_{n \to \infty} \nu(A_n)$. If $A, A_1, A_2, \dotsc \in \mathcal{A}$, $\sum_{n=1}^\infty \abs{\nu(A_n \setminus A_{n+1})} < \infty$ and $A_n \downarrow A$ then $\nu(A) = \lim_{n \to \infty} \nu(A_n)$.
\end{prop}
\begin{proof}
Continuity follows from the same proof as Lemma \ref{ContinuityOfMeasure}.  Defining $B_1 = A_1$ and $B_n = A_n \setminus A_{n-1}$ for $n > 1$ we see that $B_n$ are disjoint, $A_n = \cup_{j=1}^n B_j$ and $A = \cup_{j=1}^\infty B_j$.  By assumption, $\sum_{j=1}^\infty \abs{\nu(B_j)} < \infty$ and therefore we may apply countable and finite additivity to see
\begin{align*}
\nu(A) = \sum_{j=1}^\infty \nu(B_j) = \lim_{n \to \infty} \sum_{j=1}^n \nu(B_j) = \lim_{n \to \infty} \nu(A_n)
\end{align*}
To see continuity under decreasing sequences of sets 
\begin{align*}
\nu(A_1) - \nu(\cap_{j=1}^\infty A_j) &= \nu(A_1 \setminus \cap_{j=1}^\infty A_j) = \nu(\cup_{j=1}^\infty A_j \setminus A_{j+1}) \\
&= \sum_{j=1}^\infty\nu(A_j \setminus A_{j+1}) = \lim_{n \to \infty} \sum_{j=1}^n\nu(A_j \setminus A_{j+1}) 
\end{align*}
\end{proof}

Equally important to note is that monotonicity and subadditivity fail for signed measures.
\begin{examp}Let $\Omega = \lbrace 1,2,3 \rbrace$ and define $\nu(1) = \nu(2) = 1$ and $\nu(3) = -1$ then $0=\nu(\lbrace 1,3 \rbrace) < \nu(\lbrace 1 \rbrace)=1$ and $1 = \nu(\lbrace 1,3 \rbrace \cup \lbrace 2,3 \rbrace) > \nu(\lbrace 1,3 \rbrace) +  \nu(\lbrace 2,3 \rbrace) = 0$.
\end{examp}

\begin{defn}Two measures $\mu$ and $\nu$ on a measurable space $(\Omega,
  \mathcal{A})$ are said to be \emph{mutually singular} if there
  exists $A \in \mathcal{A}$ such that $\mu A = 0$ and $\nu A^c = 0$.
  We often write $\mu \perp \nu$.
\end{defn}
\begin{examp}Lebesgue measure and any Dirac measure on $\reals$ are
  mutually singular.
\end{examp}
\begin{examp}Let $f,g$ be positive measurable functions on $\reals$
  such that $\int f \wedge g \, d\lambda= 0$.  Then $f \cdot \lambda$ and $g
  \cdot \lambda$ are mutually singular.
\end{examp}
\begin{defn}Given two measures $\mu$ and $\nu$ on a measurable space $(\Omega,
  \mathcal{A})$ we say that $\nu$ is \emph{absolutely continuous} with
  respect to $\mu$ if for every $A \in \mathcal{A}$ such that $\mu A =
  0 $ we also have $\nu A = 0$.
  We often write $\nu \ll \mu$.
\end{defn}
\begin{examp}Let $f$ be a positive measurable function on the measure
  space $(\Omega,
  \mathcal{A}, \mu)$, then $f \cdot \mu$ is absolutely continuous with
  respect to $\mu$.  We shall soon see that this is the only way to
  construct absolutely continuous measures.
\end{examp}
\begin{thm}\label{HahnDecomposition}[Hahn Decomposition]Given a
  bounded signed measure $\nu$ on a measurable space $(\Omega,
  \mathcal{A})$ there are unique bounded mutually singular positive
  measures $\nu_+$ and $\nu_-$ such that $\nu = \nu_+ - \nu_-$.
\end{thm}
\begin{proof}Let $c=\sup_{A \in \mathcal{A}} \nu(A)$.  The first claim
  is that there is a $A_+ \in \mathcal{A}$ such that $\nu A_+ = c$.
By continuity of measure Proposition \ref{ContinuityOfSignedMeasure} we expect to
be able to show this by taking a limit over sets with $\nu(A)$ getting arbitrarily close to $c$.  
Reflecting for a moment one realizes there are two reasons that a set $A$ may have measure less than 
$c$.  The first reason is that the set may be missing some positive mass that can be added and the second
reason is that the set may have some negative mass that can be subtracted; of course these two reasons are not 
mutually exclusive.  In the first case taking a union of sets improves the approximation in the second case taking an 
intersection improves the approximation therefore we expect our limiting process to involve both unions and intersections.

A trick is that signed measures are not subadditive hence taking a union does not always increase measure. 
The first thing we need is a simple bound on the damage that
taking a union can do to approximations to the supremum.
\begin{clm}Suppose we  are given $A,A^\prime \in \mathcal{A}$ such that $\nu A \geq c -
  \epsilon$ and $\nu A^\prime \geq c - \epsilon^\prime$ then $\nu(A \cup A^\prime) \geq c - \epsilon - \epsilon^\prime$.
 If $B \subset A \setminus A^\prime$ then $-\epsilon \leq \nu(B) \leq \epsilon + \epsilon^\prime$.
\end{clm}
To see the first part of the claim,
\begin{align*}
\nu (A \cup A^\prime) &= \nu (A \setminus (A \cap A^\prime)) + \nu (A^\prime  \setminus (A \cap A^\prime)) + \nu (A \cap A^\prime) \\
&=\nu (A) + \nu (A^\prime) - \nu (A \cap A^\prime) \\
&\geq \nu A + \nu A^\prime - c & &\text{by bound on $\nu$} \\
&\geq c - \epsilon - \epsilon^\prime & &\text{by bounds on $A,A^\prime$}
\end{align*}
For the second part of the claim, the lower bound actually holds for any subset of $A$; if $B \subset A$ then
$\nu(B) + \nu(A\setminus B) = \nu(A) \geq c - \epsilon$ by $\nu(A \setminus B) \leq c$ hence
$\nu(B) \geq -\epsilon$ follows.  For the upper bound, if $B \subset A \setminus A^\prime$ then by finite additivity
and the two lower bounds already established,
\begin{align*}
\nu(B) &= \nu(A \cup A^\prime) - \nu(A^\prime) - \nu(A \setminus A^\prime \setminus B) \\
&\leq c - (c - \epsilon^\prime) - (-\epsilon) = \epsilon + \epsilon^\prime
\end{align*}

Now approximate the supremum by taking $A_1, A_2, \dots \in \mathcal{A}$ such that $\nu
  A_n \geq c - 2^{-n}$.  By the first part of the above claim and a simple induction we have
$\nu(\cup_{j=n+1}^m A_j) \geq c - \sum_{j=n+1}^m 2^{-j}$ for all $n < m$.  Note that
\begin{align*}
\cup_{j=n+1}^{m+1} A_j \setminus \cup_{j=n+1}^{m} A_j &= A_{m+1} \setminus \cup_{j=n+1}^{m} A_j \subset A_{m+1} \setminus A_m
\end{align*}
and therefore by the second part of the prior claim, $\abs{\nu(\cup_{j=n+1}^{m+1} A_j \setminus \cup_{j=n+1}^{m} A_j)} \leq 2^{-m-1} + 2^{-m} < 2^{-m+1}$
so that we may apply continuity of measure (Proposition \ref{ContinuityOfSignedMeasure}) to conclude
\begin{align*}
\nu \bigcup_{i=n+1}^\infty A_i &= \lim_{m \to \infty} \nu \bigcup_{i=n+1}^m A_i
\geq \lim_{m \to \infty} c - \sum_{i=n+1}^m 2^{-i} = c - 2^{-n}
\end{align*}
Let $A_+ = \bigcap_{n=1}^\infty \bigcup_{i=n+1}^\infty A_i$ and by the same argument as above we have
\begin{align*}
\bigcup_{i=n}^\infty A_i \setminus \bigcup_{i=n+1}^\infty A_i \subset A_n \setminus A_{n+1}
\end{align*}
and therefore 
\begin{align*}
\sum_{n=1}^\infty \abs{ \nu \bigcup_{i=n}^\infty A_i \setminus \bigcup_{i=n+1}^\infty A_i} &\leq \sum_{n=1}^\infty 2^{-n+1} < \infty
\end{align*}
and we may apply Proposition \ref{ContinuityOfSignedMeasure} to conclude
\begin{align*} \nu A_+ = \lim_{n \to \infty} \nu
  \bigcup_{i=n+1}^\infty A_i \geq c
\end{align*}
By the definition of $c$ we see that $\nu A_+ = c$.  Now define $A_- =
A_+^c$ and define the restrictions 
\begin{align*}
\nu_+ B &= \nu (A_+ \cap B ) \\
\nu_- B &= -\nu ( A_- \cap B )
\end{align*}

\begin{clm}$\nu_\pm$ are both measures.
\end{clm}
We prove this for $\nu_+$, this will imply that $\nu_-$ is also a measure by considering $-\nu$.  Since $\nu(A_+) = \sup_{A \in \mathcal{A}} \nu(A)$ it follows that $\nu_+(B) \geq 0$ for all $B$; if not then $\nu(A_+ \setminus B) = \nu(A_+) - \nu(A_+ \cap B) > \nu(A_+)$ which is a contradiction.  Let $B_1, B_2, \dotsc \in \mathcal{A}$ be disjoint then $\sum_{j=1}^n \nu(A_+ \cap B_j) \leq \nu(A_+)$ and is an increasing sequence thus $\sum_{j=1}^\infty \abs{\nu(A_+ \cap B_j)} = \sum_{j=1}^\infty \nu(A_+ \cap B_j)$ exists and is finite.  There since $\nu$ is a bounded signed measure
\begin{align*}
\sum_{j=1}^\infty \nu_+(B_j) &= \sum_{j=1}^\infty \nu(A_+ \cap B_j) = \nu(A_+ \cap \cup_{j=1}^\infty  B_j) = \nu_+(\cup_{j=1}^\infty  B_j)
\end{align*}
and the claim follows.  

Since $\nu_+(A_+^c) = \nu(\emptyset) = 0$ and $\nu_-(A_+) = -\nu ( \emptyset ) = 0$ it follows that $\nu_+$ and $\nu_-$ are mutually singular.  Furthermore by finite additivity we know that $\nu(B) = \nu(B \cap A_+) + \nu(B \cap A_-) = \nu_+(B) - \nu_-(B)$.

If $\nu = \mu_+ - \mu_-$ with $\mu_\pm$ bounded mutually singular measures then pick $B$ such that $\mu_+(B^c) = 0$ and $\mu_-(B) = 0$ then we have
\begin{align*}
\nu_+(A_+) &= \nu(A_+) = \mu_+(A_+ \cap B) - \mu_-(A_+ \cap B^c)
\end{align*}
from which it follows that $\mu_-(A_+ \cap B^c)=0$ since otherwise 
\begin{align*}
\mu_+(A_+ \cap B) = \nu(A_+ \cap B) > \nu(A_+) = \sup_{A \in \mathcal{A}} \nu(A)
\end{align*}
therefore $\mu_-(A_+) = \mu_-(A_+ \cap B) + \mu_-(A_+\cap B^c) = 0$.  By a similar argument we conclude that $\mu_+(A_-) = 0$ thus we may assume that $B=A_+$ and it follows that $\mu_\pm = \nu \mid_{A_\pm} = \nu_\pm$.
\end{proof}

\begin{thm}[Radon-Nikodym Theorem]\label{RadonNikodym}Let $\mu, \nu$
  be $\sigma$-finite measures on the measurable space $(\Omega,
  \mathcal{A})$.  There exist unique measures $\nu_a \ll \mu$ and
  $\nu_s \perp \mu$ such that $\nu = \nu_a + \nu_s$.  Furthermore,
  there is a unique positive measurable $f : \Omega \to \reals$ such
  that $\nu_a = f \cdot \mu$.
\end{thm}
\begin{proof}TODO
\end{proof}

In addition to the product measure construction we have just seen
there is another important construction for $\reals$.
\begin{defn}A measure $\mu$ on $(\reals, \mathcal{B}(\reals))$ is called
  \emph{locally finite} if $\mu(I) < \infty$ for every finite interval
  $I \subset \reals$.
\end{defn}
\begin{lem}[Lebesgue-Stieltjes
  Measure]\label{LebesgueStieltjesMeasure}There is a 1-1
  correspondence between locally finite measures on $(\reals,\mathcal{B}(\reals))$ and
  nondecreasing right continuous functions $F : \reals \to \reals$ such that $F(0)=0$ given by 
\begin{align*}
\mu((a,b]) = F(b) - F(a)
\end{align*}
\end{lem}
\begin{proof}
Suppose we are given a locally finite measure $\mu$ on
$(\reals,\mathcal{B}(\reals))$.  Define
\begin{align*}
F(x) = \begin{cases}
\mu (0,x] & \text{if $x > 0$}\\
-\mu (x, 0] & \text{if $x < 0$}\\
0 & \text{if $x=0$}
\end{cases}
\end{align*}
Local finiteness of $\mu$ implies that $F$ is well defined.
Monotonicity of $\mu$ implies that $F$ is nondecreasing.  Continuity
of measure implies that $F$ is right continuous.  Clearly, 
\begin{align*}
\mu (a,b] = F(b) - F(a)
\end{align*} and furthermore $F$ is the unique function that satisfies
this property.

On the other hand, given an $F$ that is nondecreasing, right
continuous and satisfies $F(0) = 0$ we define a generalized inverse by 
\begin{align*}
G(y) = \inf \lbrace x \in \reals \mid F(x) \geq y \rbrace = \sup
\lbrace x \in \reals \mid F(x) < y \rbrace
\end{align*}
Note that if $y < w$ then $\lbrace x \in \reals \mid F(x) \geq w
\rbrace \subset \lbrace x \in \reals \mid F(x) \geq y \rbrace$ which
shows that $G$ is a nondecreasing function.  The fact that $G$ is
nondecreasing implies that $G^{-1} (-\infty, y] = (-\infty, x]$ for
some $x \in \reals$ and therefore $G$ is a measurable function.  
Furthermore, 
\begin{align*}
G(F(x)) &= \inf\lbrace s \in \reals \mid F(s) \geq F(x)
\rbrace \leq x
\end{align*}
and on the other hand since 
\begin{align*}
G(y) &= \inf\lbrace x \in \reals \mid F(x) \geq y
\rbrace 
\end{align*}
we can find a sequence $x_n \downarrow G(y)$ such that $F(x_n) \geq y$
and therefore by right continuity of $F$ we now that $F(G(y)) =
\lim_{n\to\infty} F(x_n) \geq y$.

Together these two facts show that 
$G(y) \leq c$ if and only if $y \leq F(c)$.  In one direction suppose
$y \leq F(c)$, then applying $G$ to both sides and using the
nondecreasing nature of $G$, we get $G(y) \leq G(F(c)) \leq c$.  In
the other direction, we assume $G(y) \leq c$ and apply $F$ to both
sides and to see
\begin{align*}
F(c) \geq F(G(y)) \geq y
\end{align*}
It follows that we also have the contrapositive assertion $c < G(y)$ if and only if $F(c) < y$.

Now we can finish the proof by 
defining $\mu = (\pushforward{G}{\lambda})$ where $\lambda$ is Lebesgue
measure on $\reals$.  We observe that this is an inverse to the
construction of $F$ given above.  
\begin{align*}
\mu (a,b] &= \lambda \left ( \lbrace y \in \reals \mid a < G(y)  \leq b
  \rbrace \right ) \\
&= \lambda (F(a), F(b)] = F(b) - F(a)
\end{align*}

Uniqueness of measure $\mu$ with this property follows by Lemma
\ref{UniquenessOfMeasure} as local finiteness obviously implies
$\sigma$-finiteness on $\reals$.
\end{proof}

Note the choice of the normalizing condition $F(0) = 0$ is somewhat
arbitrary albeit a natural choice when considering arbitrary locally
finite measures on $\reals$.  We will see later that for finite
measures, and probability
measures in particular, it is more useful to pick a different
normalization $\lim_{x \to -\infty} F(x) = 0$.

By the description of all measures on $\reals$ as
Lebesgue-Stieltjes measures, we have set the stage for the
translation of results about measures into results about
nondecreasing, right continuous functions.  In particular, if we apply
the Radon-Nikodym Theorem to we see that any such $F$ may be written
as $F = F_a + F_s$ which represent the absolutely continuous and
singular parts of the decomposition respectively.  If one unwinds the
defining property of $F_a$ from the Lebesgue-Stieltjes integral, one
sees
 that in the absolutely continuous case, $F_a(x) = \int_0^x f \,
 d\lambda$ for an appropriate density $f$.

\begin{thm}[Fundamental Theorem Of Calculus]\label{FundamentalTheoremOfCalculus}Let any nondecreasing, right continuous function $F(x) = \int_0^x
  f \, d\lambda + F_s(x)$ is differentiable a.e. with derivative $F^\prime = f$.
\end{thm}
\begin{proof}
TODO
\end{proof}

\begin{cor}[Integration By Parts]\label{IntegrationByParts}Suppose $f$
  and $g$ are absolutely continuous functions.  Then 
\begin{align*}
\int_a^b f^\prime g d\lambda
  = f(b)g(b) - f(a)g(a) - \int_a^b f g^\prime d \lambda
\end{align*}
\end{cor}
\begin{lem}\label{IntervalSelection}Let $\mathcal{I}$ be an arbitrary
  collection of open intervals of $\reals$.  Let $G = \bigcup_{I \in
    \mathcal{I}} I$ and suppose that $\lambda G < \infty$.  Then there
  exists disjoint $I_1, \dots, I_n$ such that $\sum_{i=1}^n \abs{I_i}
  \geq \frac{\lambda G}{4}$.
\end{lem}
\begin{proof}TODO
\end{proof}
\begin{lem}\label{DifferentiationOnNullSets}Let $\mu$ be a locally finite measure on $(\reals, \mathcal{B}(\reals))$
  and let $F(x) = \mu (0,x]$.  Let $A \in \mathcal{B}$ be a set with
  $\mu A = 0$, then $F^\prime = 0$ almost everywhere $\lambda$ on $A$.
\end{lem}
\begin{proof}The intuition behind the proof is that the derivative
  $F^\prime(x)$ represents the ratio of $\mu$-measure and
  $\lambda$-measure for arbitrarily small intervals around $x \in
  \reals$.  For $x \in A$, we expect the $\mu$-measure and therefore
  the derivative to be $0$.  Since $A$ may not contain any honest
  intervals, there is some finesse required to make the intuition rigorous.

First pick $\delta > 0$ and and open set $G_\delta \supset A$ such that $\mu
G_\delta < \delta$.  

TODO: Prove that such $G_\delta$ exists; this is a fact for arbitrary
Borel $\sigma$-algebras.

For each $\epsilon > 0$, let 
\begin{align*}
A_\epsilon &= \{ x \in A \mid \limsup_{h \to 0} \frac{F(x + h) - F(x -
  h)}{h} > \epsilon \} \\
\end{align*}
so that for $x \in A_\epsilon$ there exist arbitrarily small $h > 0$
such that 
\begin{align*}
\mu(x-h,x+h] &=F(x + h) - F(x -  h) > \epsilon h =
\frac{1}{2}\epsilon \lambda(x-h,x+h]
\end{align*}
Note that $A_\epsilon$ is measurable since 
\begin{align*}
\limsup_{h \to 0}  \frac{F(x + h) - F(x -
  h)}{h} &= \limsup_{n \to \infty} n \left(F(x + 1/n) - F(x -
  1/n)\right)
\end{align*} 
is measurable (Lemma \ref{LimitsOfMeasurable}).

By openness of $G_\delta$ and by the above remarks, for any $x \in A_\epsilon$ we can pick $h > 0$ small enough so that
$I_x = (x - h, x+h] \subset G_\delta$ and $2\mu(I_x)/\epsilon > \lambda(I_x)$.  Since $A_\epsilon \subset
\bigcup_{x \in A_\epsilon} I_x$, by the previous Lemma
\ref{IntervalSelection} we pick a finite disjoint set $I_{x_1}, \dots,
I_{x_n}$ and note that
\begin{align*}
\lambda A_\epsilon &\leq \lambda 
\bigcup_{x \in A_\epsilon} I_x \leq 4 \sum_{k=1}^n \abs{I_{x_k}} \leq
4 \sum_{k=1}^n \frac{2\mu I_{x_k}}{ \epsilon} = \frac{8}{\epsilon} \mu
\bigcup_{k=1}^n I_{x_k} \leq \frac{8\delta}{\epsilon}
\end{align*}
Now $\delta > 0$ was arbitrary so we see that $\lambda A_\epsilon =
0$.  Since $\epsilon > 0$ was arbitrary and since the set of points in
$A$ where $F^\prime \neq
0$ is a countable union of $A_\epsilon$ (e.g. take $\bigcup_n
A_{\frac{1}{n}}$)  we see that $F^\prime(x) = 0$
almost everywhere on $A$.
\end{proof}

\subsection{Functions of Bounded Variation}
Recall that we have define $x_+ = x \vee 0$ and $x_- = \abs{x} -
x_+ = -(x \wedge 0)$.  Given a real valued function $F$ on $[a,b]$ we consider a partition $a=x_0
< x_1 < \dotsb < x_n=b$ and define 
\begin{align*}
p &= \sum_{j=1}^n (F(x_j) - F(x_{j-1}))_+ \\
n &= \sum_{j=1}^n (F(x_j) - F(x_{j-1}))_- \\
v &= \sum_{j=1}^n \abs{F(x_j) - F(x_{j-1})}\\
\end{align*}
and note that $p+n = v$ and $p - n = F(b) - F(a)$.  We define the
\emph{positive}, \emph{negative} and \emph{total variation} of $F$ on
$[a,b]$ to be the supremum of the above over all partitions of
$[a,b]$:
\begin{align*}
P_a^b(F) &= \sup_{\substack{n \geq 1 \\ a=x_0 < x_1 < \dotsb x_n=b}} \sum_{j=1}^n (F(x_j) - F(x_{j-1}))_+ \\
N_a^b(F) &= \sup_{\substack{n \geq 1 \\ a=x_0 < x_1 < \dotsb x_n=b}} \sum_{j=1}^n (F(x_j) - F(x_{j-1}))_- \\
TV_a^b(F) &= \sup_{\substack{n \geq 1 \\ a=x_0 < x_1 < \dotsb x_n=b}} \sum_{j=1}^n \abs{F(x_j) - F(x_{j-1})}\\
\end{align*}


\begin{lem}\label{ElementaryVariationInequalities}For any function $F$ defined on $[a,b]$ we have 
\begin{align*}
P_a^b(F) \vee N_a^b(F) &\leq TV_a^b(F) \\
\intertext{and}
TV_a^b(F) &\leq P_a^b(F) + N_a^b(F)
\end{align*}
\end{lem}
\begin{proof}
For any partition $a=x_0 < x_1 < \dotsb < x_n=b$ we noted above $p + n
\leq v$ and therefore $p \leq v$ which implies by taking the supremum on
the right $p \leq TV_a^b(F)$ and then by taking the supremum on the
left $P_a^b(F) \leq TV_a^b(F)$.  The argument to show $N_a^b(F) \leq
TV_a^b(F)$ is identical.  Similarly from $v = p + n$, we can take two
different suprema on the right to see that $v \leq P_a^b(F) +
N_a^b(F)$ and then taking the supremum on the left we get $TV_a^b(F)
\leq P_a^b(F) \leq TV_a^b(F)$.
\end{proof}

\begin{defn}We say that  function $F$ defined on $[a,b]$ has
  \emph{bounded variation} on $[a,b]$ if $TV_a^b(F) < \infty$.
\end{defn}

\begin{lem}\label{TotalVariationAsSumOfPositiveAndNegativeVariation}If $F$ has bounded variation on $[a,b]$ then 
\begin{align*}
TV_a^b(F) &= P_a^b(F) + N_a^b(F) \\
\intertext{and}
F(b) - F(a) &=  P_a^b(F) - N_a^b(F) 
\end{align*}
\end{lem}
\begin{proof}
From \ref{ElementaryVariationInequalities}, we know that $F$ being of
bounded variation implies that both the positive and negative
variation are finite.  Now with a fixed $a=x_0 < x_1 < \dotsb < x_n=b$
we had $p  = n + F(b) - F(a)$, so taking supremum on the right we get
$p  \leq N_a^b(F) + F(b) - F(a)$
and the taking suspremum on the left we get $P_a^b(F)  \leq N_a^b(F) +
F(b) - F(a)$.  As noted the negative variation is finite and therefore
we conclude $P_a^b(F)  - N_a^b(F) \leq
F(b) - F(a)$. Similarly we get from applying the same steps to $n = p
+ F(a) - F(b)$
that $N_a^b(F) \leq P_a^b(F) + F(a) - F(b)$ which gives us $F(b) -F(a)
\leq P_a^b(F)  - N_a^b(F)$ and therefore we conclude that $F(b) -F(a)
= P_a^b(F)  - N_a^b(F)$.

Now arguing from $p + n = v$ and taking the supremum on the right we
have using $F(b) - F(a) = p -n$,
\begin{align*}
TV_a^b(F) \geq p+n = 2p + F(a) - F(b) = 2p + N_a^b(F) - P_a^b(F)
\end{align*}
which upon taking another supremum gives
\begin{align*}
TV_a^b(F) \geq 2P_a^b(F) + N_a^b(F) - P_a^b(F) = P_a^b(F) + N_a^b(F)
\end{align*}

Note a more hands on way of proving the this result is to note
that we have a triangle inequality $(x+y)_+ leq x_+ + y_+$ and therefore
if we are given a partition $a=x_0 < x_1 < \dotsb < x_n=b$ and
refine the partition by adding a new point then to create a new
partition $a=\tilde{x}_0 < \tilde{x}_1 < \dotsb < \tilde{x}_n=b$ then
we have
\begin{align*}
\sum_{j=1}^n (F(x_j) - F(x_{j-1}))_+ &\leq \sum_{j=1}^{n+1} (F(\tilde{x}_j) - F(\tilde{x}_{j-1}))_+
\end{align*}
and similarly with the negative variation.  Now let $\epsilon > 0$ be
chosen and find partitions $a=x_0 < x_1 < \dotsb < x_n=b$ such that 
\begin{align*}
P_a^b(F) - \epsilon/2 &< \sum_{j=1}^n (F(x_j) - F(x_{j-1}))_+  \leq P_a^b(F) 
\end{align*}
and $a=y_0 < y_1 < \dotsb < y_m=b$ such that
\begin{align*}
N_a^b(F) - \epsilon/2 &< \sum_{j=1}^m (F(y_j) - F(y_{j-1}))_+  \leq N_a^b(F) 
\end{align*}
By the above argument, both inequalities continue to hold if we take
the common refinement of both partitions so we may in fact assume that
$n=m$ and $x_j=y_j$ for $j=0, \dotsc, n$.  Therefore by adding we get
\begin{align*}
P_a^b(F)  + N_a^b(F) - \epsilon &< \sum_{j=1}^n  (F(x_j) -
F(x_{j-1}))_+ +  (F(x_j) - F(x_{j-1}))_- \\
&= \sum_{j=1}^n  \abs{F(x_j) - 
F(x_{j-1})} \leq TV_a^b(F)
\end{align*}
and the result follows by taking the limit as $\epsilon$ goes to $0$.
\end{proof}

\begin{thm}\label{BoundedVariationAsDifferenceOfMonotone}A function on $[a,b]$ is of bounded variation if an only if
  it is the difference of to non-decreasing functions.
\end{thm}
\begin{proof}
First we show that a function of bounded variation is a difference of
monotone functions.  Consider a point $a \leq x \leq b$ and note that since every partition
of $[a,x]$ can be extended to a partiton of $[a,b]$ we have $P_a^x(F)
\leq P_a^b(F) \leq TV_a^b(F) < \infty$ and similarly with $N_a^x(F)$.
The same argument for any pair $a \leq x \leq y \leq b$ shows that
$P_a^x(F) \leq P_a^y(F)$ and similarly $N_a^x(F) \leq N_a^y(F)$.
Therefore $P_a^x(F)$ and $N_a^x(F)$ are both non-decreasing functions
and applying Lemma
\ref{TotalVariationAsSumOfPositiveAndNegativeVariation} on the
interval $[a,x]$ we get $F(x) = P_a^x(F) - N_a^x(F) - F(a)$.  Since
$N_a^x(F) - F(a)$ is also a non-decreasing function we are done with
this direction.

Now if $F(x) = G(x) - H(x)$ with both $G$ and $H$ monotone then for
any partition $a=x_0 < x_1 < \dotsb < x_n=b$ we have
\begin{align*}
\sum_{j=1}^n \abs{F(x_j) - F(x_{j-1})} &= \sum_{j=1}^n \abs{G(x_j) -
  G(x_{j-1}) - H(x_j) + H(x_{j-1})} \\
&\leq \sum_{j=1}^n (G(x_j) -
  G(x_{j-1})) + \sum_{j=1}^n( H(x_{j-1}) + H(x_{j})) = G(b) - G(a) +
  H(a) - H(b)
\end{align*}
\end{proof}

\begin{lem}\label{AdditivityOfTotalVariation}Let $f$ be a function of
  bounded variation on $[a,b]$, then for every $a < x < b$, $TV_a^x(f)
  + TV_x^b(f) = TV_a^b(f)$.
\end{lem}
\begin{proof}Pick partitions $a=x_0 < \dotsb < x_n=x$ of $[a,x]$ and $x=y_0 <
  \dotsb < y_m=b$ of $[x,b]$ and note that $a=x_0 < \dotsb < x_n=y_0 < y_1 < \dotsb <
  y_m=b$ is a partition of $[a,b]$.  Therefore
\begin{align*}
\sum_{j=1}^n \abs{f(x_j) - f(x_{j-1})} + \sum_{j=1}^m \abs{f(y_j) -
  f(y_{j-1})} &\leq TV_a^b(f)
\end{align*}
which upon taking suprema over partitions of $[a,x]$ and $[x,b]$ shows
$TV_a^x(f) + TV_x^b(f) \leq TV_a^b(f)$.  

On the other hand, let $a=x_0 < \dotsb < x_n=b$ be a partition of
$[a,b]$.  First assume that there exists an $0 < m < n$ such that $x_m
= x$.  It then follows that $a=x_0 < \dotsb < x_m=x$ is a partition of
$[a,x]$ and $x = x_m < \dotsb < x_n=b$ is a partition of $[x,b]$ and
therefore
\begin{align*}
\sum_{j=1}^n \abs{f(x_j) - f(x_{j-1})} &= \sum_{j=1}^m \abs{f(x_j) -
  f(x_{j-1})} + \sum_{j=m+1}^n \abs{f(x_j) - f(x_{j-1})} \leq
TV_a^x(f)  + TV_x^b(f)
\end{align*}
On the other hand, if $x$ is not a member of the partition then we may
add it and by the triangle inequality that can only increase the
variation of the partition so the inequality still holds.  Thus we may
take the supremum over all partitions of $[a,b]$ and we get $TV_a^b(f)
\leq TV_a^x(f)  + TV_x^b(f)$ and the result is proven.
\end{proof}

\begin{lem}\label{ContinuityOfTotalVariation}Let $f$ be a left
  continuous function with bounded variation on $[a,b]$, then
  $TV_a^x(f)$ is a left continuous function of $x$.  Similarly if $f$
  is right continuous (resp. continuous) then  $TV_a^x(f)$ is a right
  continuous (resp. continuous).
\end{lem}
\begin{proof}
We first suppose that $f$ is left continuous and show that $TV_a^x(f)$
is left continuous at $x$.  Pick $\epsilon > 0$ and select a partion
$a=x_0 < x_1 < \dotsb < x_n=x$ such that $\sum_{j=1}^n \abs{f(x_j) -
  f(x_{j-1})} > TV_a^x(f) - \epsilon/2$.  By left continuity of $f$ at $x$
we can pick a $\delta>0$ such that $\abs{f(x) - f(y)} < \epsilon/2$
for all $x-\delta < y < x$. Without loss of generality we may also
assume that $\delta < x - x_{n-1}$.  For any such $y$ we
define a new partition by adding the point $y$ to the existing
partition $x_0, \dotsc, x_n$; precisely define 
\begin{align*}
\tilde{x}_j &= \begin{cases}
x_j & \text{for $j=0, \dotsc, n-1$} \\
y & \text{for $j=n$} \\
x & \text{for $j=n+1$}
\end{cases}
\end{align*}
and note that by the triangle inequality, 
\begin{align*}
TV_a^x(f) - \epsilon/2 &< \sum_{j=1}^n \abs{f(x_j) -
  f(x_{j-1})} \leq \sum_{j=1}^{n+1} \abs{f(\tilde{x}_j) -
  f(\tilde{x}_{j-1})} \leq TV_a^x(f)
\end{align*}
If restrict our attention to the partition $a = \tilde{x}_0 < \dotsb <
\tilde{x}_n = y$, by monotonicity of total variation and the choice of $y$ we have
\begin{align*}
TV_a^x(f) &\geq TV_a^y(f) \geq \sum_{j=1}^{n} \abs{f(\tilde{x}_j) -
  f(\tilde{x}_{j-1})} \\
&> TV_a^x(f) - \epsilon/2 - \abs{f(x) - f(y)} > TV_a^x(f) - \epsilon
\end{align*}
which shows left continuity of $TV_a^x(f)$.

One could prove the case of right continuous $f$ by an analogous
argument that shows $TV_x^b(f)$ is a right continuous function of $x$
and then observing $TV_a^x(f) = TV_a^b(f) - TV_x^b(f)$ Lemma
\ref{AdditivityOfTotalVariation} (do this as an exercise!).  Here we take a slightly different
approach and derive the case of right continuity from the case of left
continuity.  Given $f$ a function on $[a,b]$, define the function
$\tilde{f}(x) = f(b+a-x)$ on $[a,b]$.  Note that $f$ is right
continuous if and only if $\tilde{f}$ is left continuous.  Note also
that the transformation $x \mapsto b+a-x$ is a bijection of $[a,y]$
and $[b+a-y,b]$ for every $a \leq y \leq b$
and therefore is a bijection of partitions of $[a,y]$ and $[b+a-y,b]$
for every such $y$.  From this it follows that $TV_a^y(f) =
TV_{b+a-y}^b(\tilde{f})$ for every $a \leq y \leq b$.  In particular
taking $y=b$,
$f$ is of bounded variation on $[a,b]$ if and only if $\tilde{f}$ is.
Stitching all of these observations together, if $f$ is right
continuous, then $\tilde{f}$ is left continuous and therefore by the
first part of the Lemma and Lemma \ref{AdditivityOfTotalVariation} we
know that $TV_{y}^b(\tilde{f}) = TV_a^b(\tilde{f}) -
TV_a^{y} (\tilde{f})$ is a left continuous function of $y$.  From this
it follows that $TV_a^y(f) = TV_{b+a-y}^b(\tilde{f})$ is a right
continuous function of $y$.

The case of $f$ continuous follows immediately as a function is
continuous if and only if it is both right continuous and left continuous.
\end{proof}

As an exercise, one should show that continuity of a function not only
implies the continuity of the total variation but also the positive
and negative variations (all we needed positivity and the triangle
inequality of the absolute value; properties that are shared by the
positive and negative part functions).  (TODO: Can we instead derive the
positive and negative variation cases from right continuity of total
variation and $f$?)
If we assume that we are given a right continuous function $f$ of bounded
variation, then by Lemma \ref{ContinuityOfTotalVariation} we know that
positive and negative variations are right continuous and therefore by
Theorem \ref{BoundedVariationAsDifferenceOfMonotone} we see that $f$
is a difference of monotone right continuous functions.  By the
construction of Lebesgue-Stieltjes measures this allows us to
associate locally finite (signed) measures to $f$.  

TODO: Define all of the measures involved and observe that $dF = dF_+ - dF_-$
is the Jordon decompostiion of the signed measure $dF$ and that $dTV_a^s(F)$ is the
absolute value of the signed measure $dF$.

\begin{lem}\label{AbsoluteValueOfStieltjes}Let $F$ be a function of bounded variation of $[a,b]$ and
  let $g$ be a measurable function then $\abs{ \int g \, dF} \leq \int
  \abs{g} \abs{dF}$.
\end{lem}
\begin{proof}
This is just a computation using the definitions and the triangle inequality
\begin{align*}
\abs{\int g \, dF} &= \abs{\int g \, dF_+ - \int g \, dF_-} \leq
\abs{\int g \, dF_+}  + \abs{ \int g \, dF_-} \\
&\leq\int \abs{ g} \,
dF_++ \int \abs{ g} \, dF_- = \int \abs{g} \, \abs{dF}
\end{align*}
\end{proof}

In addition to functions of bounded variation providing signed
measures via the construction of Stieltjes measures integrals also
provide a source of functions of bounded variation.

\begin{defn}A function $F$ is \emph{absolutely continuous} on an
  interval $[a,b]$ if for every $\epsilon > 0$ there exists $\delta>0$
  such that for every $n > 0$ and every set of disjoint intervals $(a_j, b_j] \subset
  (a,b]$ for $j=1, \dotsc, n$ with $\sum_{j=1}^n (b_j-a_j) < \delta$
  we have $\sum_{j=1}^n \abs{F(b_j)-F(a_j)} < \epsilon$.
\end{defn}

\begin{lem}\label{AbsoluteContinuityImpliesContinuousBoundedVariation}If $F$ is absolutely continuous on $[a,b]$ then $F$ is
 uniformly continuous on $[a,b]$ and has bounded variation on $[a,b]$.
\end{lem}
\begin{proof}
The fact that $F$ is uniformly continuous is immediate by considering a single
subinterval of $[a,b]$.  Seeing that $F$ has bounded variation is
conceptually simple but notationally a little ugly.  The idea is simply
that any sufficiently fine partition of $[a,b]$ can be decomposed into
a union of subpartitions of a subinterval of length less than any
desired $\delta$; this is enough to bound the total variation. To see
the details, pick
$N > 0$ so that  $\sum_{j=1}^n (b_j-a_j) < (b-a)/N$ implies
$\sum_{j=1}^n \abs{F(b_j)-F(a_j)} < 1$.  First assume that we have a
partition $a=x_0 < x_1 < \dotsb < x_n=b$ such that for each $k=0,
\dotsc, N$ there is an $n_k$ with $x_{n_k} = (b-a)*k/N$. Then we
have $\sum_{j=n_{k-1}+1}^{n_k} (x_j - x_{j-1}) < \delta$ for
each $k$ and therefore
\begin{align*}
\sum_{j=1}^n \abs{F(b_j)-F(a_j)} &= \sum_{k=1}^{(b-a)/N}\sum_{j=n_{k-1}+1}^{n_k}
\abs{F(b_j)-F(a_j)} < (b-a) /N < \infty
\end{align*}
The assumption that $x_{n_k} = (b-a)*k/N$ can be arranged for by refining
an arbitrary partition and noting that the total variation can only increase by
doing so.
\end{proof}

To construct a general construction of absolutely continuous functions
from Stieltjes measures we first prove the
following fact about integrals on general measurable spaces.

\begin{lem}\label{LimitOfIntegralAsMeasureGoesToZero}Let $(S, \mathcal{S}, \mu)$ be a measure space and
  integrable function $f:S \to \reals$, then for
  every $\epsilon>0$ there exists a $\delta>0$ such that for all $A
  \in \mathcal{S}$ such that $\mu(A) < \delta$ we have $\abs{\int_A f\,
  d\mu} < \epsilon$.
\end{lem}
\begin{proof}
First assume that $f$ is a positive integrable function.  For each $n
> 0$ define $f_n = f \wedge n$ and note that $f_n \uparrow f$;
moreover $f_n \characteristic{A} \uparrow f \characteristic{A}$ for
every $A \in \mathcal{S}$.  By
Monotone Convergence we know that $\int_A f_n \, d\mu \uparrow \int_A
f \, d\mu$.  Let $\epsilon > 0$ be given and choose $N > 0$ such that
$\int f \, d\mu - \epsilon/2 < \int f_N \, d\mu \leq \int f \, d\mu$.
Choose $\delta = \epsilon/2*N$ and note that if $\mu(A) < \delta$ then
\begin{align*}
\int_A f \, d\mu &= \int_A f_N \, d\mu + \int_A (f-f_N) \, d\mu \leq N
\mu(A) + \int (f-f_N) \, d\mu < \epsilon
\end{align*}

For general integrable $f$ simply note that $\abs{\int_A f \, d\mu}
\leq \int_A \abs{f} \, d\mu$ and apply the result just proved for
positive integrable functions.
\end{proof}

Specializing to the case of locally finite signed measures on $\reals$ we get
\begin{cor}\label{StieltjesIntegralBoundedVariationAndContinuous}Let $F$ be a right continuous function of bounded variation and let $g$ be a
  measurable function that is integrable with respect to $F$ then
  $\int_{-\infty}^t g \, dF$ has bounded variation.  If $F$ is also
  continuous then $\int_{-\infty}^t g \, dF$ is continuous.
\end{cor}
\begin{proof}
First assume that $F$ is
non-decreasing and right continuous.  If $g$ is integrable with respect to $F$ then
$\int_{-\infty}^t g_\pm \, dF$ is non-decreasing by monotonicity of integral and therefore
$\int_{-\infty}^t g \, dF = \int_{-\infty}^t g_+ \, dF -
\int_{-\infty}^t g_- \, dF$ is a difference of non-decreasing
functions and therefore is of bounded variation by Theorem \ref{BoundedVariationAsDifferenceOfMonotone}.  To extend to $F$ of
bounded variation, write 
\begin{align*}
\int_{-\infty}^t g \, dF &= \int_{-\infty}^t g_+ \, dF_+ +
\int_{-\infty}^t g_- dF_- -
\int_{-\infty}^t g_- \, dF_+ - \int_{-\infty}^t g_+ \, dF_-
\end{align*}
and apply Theorem  \ref{BoundedVariationAsDifferenceOfMonotone}.

Now suppose that $F$ is continuous and non-decreasing.  For $\epsilon > 0$, pick $\delta>0$ as in Lemma
\ref{LimitOfIntegralAsMeasureGoesToZero} and then as any union of
intervals is measurable we get $\sum_{j=1}^n (F(b_j)-F(a_j)) < \delta$
implies $\abs{\sum_{j=1}^n \int_{a_j}^{b_j} g \, dF} < \epsilon$.
Let $t$ be given and by continuity of $F$ pick $\rho > 0$ such that
$\abs{s - t} < \rho$ implies $\abs{F(s) - F(t)} < \delta$ and
therefore 
\begin{align*}
\abs{\int_{-\infty}^t g \, dF - \int_{-\infty}^s g \, dF} &=
\abs{\int_s^t g \, dF} < \epsilon
\end{align*}
and continuity at $t$ is proven.
\end{proof}

NOTE:  It is not the case that every continuous function of bounded
variation is absolutely continous.  For that to be true we need to add
the \emph{Lusin N property} that says every the image of every Lebesgue
null set is a null set.  It turns out that absolute continuity is
equivalent to continuity, bounded variation and the Lusin property.

\section{Approximation By Smooth Functions}
In this section we discuss a technique for approximating arbitrary
measurable and integrable functions by smooth functions.  

To start, we establish the existence of an infinitely differentiable
function which is supported on the interval $[-1,1]$.

\begin{lem}The function 
\begin{align*}
f(x) = \begin{cases}
e^\frac{-1}{1-x^2} & \abs{x} < 1\\
0 & \abs{x} \geq 1
\end{cases}
\end{align*} is compactly supported on $[-1,1]$ and has continuous
derivatives of all orders.
\end{lem}
\begin{proof}
It is clear from the definition that $f(x)$ is compactly supported on
$[-1,1]$.  To see that it has continuous derivatives of all orders we
use an induction to prove that for every $n\geq 0$, there exists a
polynomial $P_n(x)$ and a nonnegative integer $N_n$ such that 
\begin{align*}
f^{(n)}(x) = \frac{P_n(x)}{(1 - x^2)^{N_n}} e^\frac{-1}{1-x^2}
\end{align*}
Clearly this is true for $n=0$.  Supposing that it is true for $n >0$,
we calculate using the induction hypothesis, the product rule and
chain rule
\begin{align*}
f^{(n+1)}(x) &= \frac{d}{dx}\frac{P_n(x)}{(1 - x^2)^{N_n}}
e^\frac{-1}{1-x^2} \\
&= \frac{(1 - x^2)^{N_n} P_n^\prime(x) - P_n(x) N_n (1- x^2)^{N_n
    -1}}{(1 - x^2)^{2N_n}}e^\frac{-1}{1-x^2} + \frac{P_n(x)}{(1 - x^2)^{N_n}}\frac{-1}{1-x^2} \frac{-2x}{(1-x^2)^2}
e^\frac{-1}{1-x^2} \\
\end{align*}
which shows the result after creating a common denominator.

It is clear that the derivatives are continuous away from ${-1,1}$ so
it remains to show $\lim_{x \to -1^+} f^{(n)}(x) = 0$ and $\lim_{x \to
  1^-} f^{(n)}(x) = 0$.

Take the former limit.  We write $f^{(n)}(x) = \frac{P_n(x)}{(1 -
  x)^{N_n}(1 + x)^{N_n}} e^\frac{-1}{1-x^2}$ and note that


TODO: Show $\lim_{x \to -1} \frac{1}{(1 + x)^M} e^\frac{-1}{1-x^2} = 0$
for all $M \geq 0$.
\end{proof}

TODO: What is $\int f(x)?$

\begin{lem}\label{ApproximationByMollifiers}Let $\rho(x)$ be a positive
  function in $C^\infty_c(\reals)$ such
  that $\rho(x)$ is supported on $[-1,1]$ and $\int_{-\infty}^\infty
  \rho(x) \, dx = \int_{-1}^1
  \rho(x) \, dx= 1$.  Let $f : \reals \to \reals$ be a continuous function.  Define 
\begin{align*}
f_n(x) = n \int_{-n}^n \rho(n(x - y)) f(y) dy
\end{align*}
Then $f_n \in C_c^\infty(\reals)$, $f_n^{(m)}(x) = n \int_{-n}^n
\rho^{(m)}(n(x -y)) f(y) dy$ and $f_n$ converges to $f$ uniformly on
compact sets.  Furthermore, if $f$ is bounded then $\norm{f_n}_\infty \leq
\norm{f}_\infty$.
\end{lem}
\begin{proof}
First note that because $\rho(x)$ and all of its derivatives are
compactly supported, they are also bounded.  In particular, there is
an $M > 0$ such that $\abs{\rho^\prime(x)} \leq M$.  To clean up the notation
a little bit, define $\rho_n(y) = n\rho(ny)$ so we have
\begin{align*}
f_n(x) &= \int_{-n}^{n} \rho_n(x - y) f(y) dy
\end{align*}
Since the support of $\rho_n(x)$ is contained in
$[-\frac{1}{n},\frac{1}{n}]$, if we fix $x \in \reals$ and
view $\rho_n(x - y)$ as a  function of $y$, its support is
contained in $[x-\frac{1}{n},x+\frac{1}{n}]$.  Thus the support of
$f_n(x)$ is contained in  $[-n-\frac{1}{n},n+\frac{1}{n}]$.

To examine the derivative
of $f_n(x)$, pick $h > 0$ and consider the difference
quotient
\begin{align*}
\frac{f_n(x + h) - f_n(x)}{h} &= \frac{1}{h} \int_{-n}^{n}
(\rho_n(x+h - y) - \rho_n(x - y) ) f(y) dy
\end{align*}
Taylor's Theorem tells us that $\frac{1}{h}(\rho_n(x+h - y) - \rho_n(x - y)) =
\rho_n^\prime(c)$ for some $c \in [x+h - y, x - y]$.  Therefore,
$\abs{\frac{1}{h} (\rho_n(x+h - y) - \rho_n(x - y))f(y)} \leq M\abs{f(y)}$ and by
integrability of $f(y)$ on the interval $[-n,n]$ (i.e. the
integrability of $f(y) \cdot \characteristic{[-n,n]}(y)$ which follows
rom the boundedness of $f(y)$ on the compact set $[-n,n]$) we may use Dominated Convergence to conclude
that 
\begin{align*}
f_n^\prime(x) &=\lim_{h \to 0} \frac{f_n(x + h) - f_n(x)}{h} \\
&= \lim_{h \to 0} \frac{1}{h} \int_{-n}^{n}
(\rho_n(x+h - y) - \rho_n(x - y) ) f(y) dy \\
&= \int_{-n}^{n }
\lim_{h \to 0} \frac{1}{h} (\rho_n(x+h - y) - \rho_n(x - y) ) f(y) dy
\\
&= \int_{-n}^{n} \rho^\prime_n(x - y) f(y) dy 
\end{align*} 
Continuity of $f_n^\prime(x)$ follows from the continuity of $f(y)$
and $\rho^\prime_n(x - y) $ and Dominated Convergence as above.  A simple induction extends the result to derivatives of arbitrary
order.

Next we show the convergence.  Pick a compact set $K \subset \reals$
and  $\epsilon > 0$,
Since $f$ is uniformly continuous on $K$,  there is a $\delta >0$ such
that for any $x \in K$ we have $\abs{x - y} \leq \delta$ implies
$\abs{f(x) - f(y)} \leq \epsilon$.  Pick $N_1 > 0$ such that
$\frac{1}{n} < \delta$ for all $n \geq N_1$.  The hypothesis $\int_{-\infty}^\infty
\rho(y) \, dy = \int_{-1}^1
\rho(y) \, dy = 1$ and simple change of variables shows $\int_{-\infty}^\infty
\rho_n(x - y) \, dy = \int_{x - \frac{1}{n}}^{x + \frac{1}{n}}
\rho_n(x - y) \, dy = 1$ for all $x \in \reals$ and $n > 0$.  Pick $N_2>0$ so that for all $n > N_2$,
we have $K \subset [-n + \frac{1}{n}, n - \frac{1}{n}]$.  Therefore we can write $f(x) = \int_{- n}^{n}
\rho_n(x - y) f(x)  \, dy = 1$ for any $x \in K$ and $n > N_2$.  We
have for any $n \geq \max(N_1, N_2)$
\begin{align*}
\abs{f_n(x) - f(x)} &= \abs{\int_{- n}^{n} (\rho_n(x -
  y)f(y) -
\rho_n(x- y) f(x)) \, dy} \\
&= \abs{\int_{x - \frac{1}{n}}^{x + \frac{1}{n}} (\rho_n(x -
  y)f(y) -
\rho_n(x- y) f(x)) \, dy}  & & \text{since $n>N_2$}\\
&\leq \int_{x - \frac{1}{n}}^{x + \frac{1}{n}} \rho_n(x- y) \abs{f(y)
  - f(x)} \, dy\\
&\leq \epsilon \int_{x -\frac{1}{n}}^{x + \frac{1}{n}} \rho_n(x -  y)
\, dy & &\text{since $\frac{1}{n} < \delta$}\\
&\leq \epsilon & & \text{since $\rho_n$ is positive and
  $\int_{-\infty}^\infty \rho_n(x) \, dx = 1$}
\end{align*}

The last thing to prove is the norm inequality in case $f$ is
bounded.  
\begin{align*}
\abs{f_n(x)} &\leq n \int_{-n}^n \rho(n(x - y)) \abs{ f(y)} dy & &
\text{because $\rho$ is positive} \\
&\leq n \norm{f}_\infty \int_{-\infty}^\infty \rho(n(x - y)) dy = \norm{f}_\infty 
\end{align*}
\end{proof}

Approximation by convolution with a compactly supported bump function
is usually sufficient for our purposes, however it is also useful to
replace the bump function with Gaussians.  

We will need the following fact that is a standard exercise from multivariate calculus
\begin{lem}\label{IntegralGaussian}$\int_{-\infty}^\infty e^{-x^2/2}\, dx = \sqrt{2\pi}$.
\end{lem}
\begin{proof}
By Tonelli's Theorem,
\begin{align*}
\int_{-\infty}^\infty \int_{-\infty}^\infty e^{-(x^2 + y^2)/2} \, dxdy
&= \int_{-\infty}^\infty e^{-x^2/2} \,
dx \int_{-\infty}^\infty e^{-y^2/2} \,
dy = \left(int_{-\infty}^\infty e^{-x^2/2} \,
dx \right)^2
\end{align*}
However, if we switch to polar coordinates and Tonelli's Theorem,
\begin{align*}
\int_{-\infty}^\infty \int_{-\infty}^\infty e^{-(x^2 + y^2)/2} \, dxdy
&= \int_{0}^{2\pi} \int_{0}^\infty e^{-r^2/2} r \, dr d\theta =
\int_{0}^{2\pi} d\theta = 2\pi
\end{align*}
and we are done.
\end{proof}

Now we can see that we may uniformly approximate compactly supported continuous
functions by convolution with Gaussians.
\begin{lem}\label{UniformApproximationByGaussians}Define $\rho(x) =
  \frac{1}{\sqrt{2 \pi} }e^{-x^2/2}$ and let $\rho_n(x) = n\rho(nx)$.
Let $f \in C_c(\reals)$ then define $f_n(x) = (f *
  \rho_n)(x)$.  Then $f_n(x) \in C_c^\infty(\reals)$ and $f_n$
  converges to $f$ uniformly.
\end{lem}
\begin{proof}
The proof is rather similar to that in the preceeding Lemma
\ref{ApproximationByMollifiers}.  By simple change of variables and
Lemma \ref{IntegralGaussian} we see
that $\int_{-\infty}^{\infty} \rho_n(y) \, dy =
\int_{-\infty}^{\infty} \rho_n(x - y) \, dy = 1$ and therefore we
have the trivial identity $f(x) = \int_{-\infty}^{\infty} f(x)
\rho_n(x - y) \, dy$.  Because $f$ has compact support, we know that
$f$ is uniformly continuous, so given $\epsilon  > 0$ we can find
$\delta > 0$ such that $\abs{x -y} < \delta$ implies $\abs{f(x) -f(y)}
< \epsilon$.  Similarly, by compact support $f$ is bounded and we may
assume $f(x) < M$ for some $M > 0$.  Assume we are given
$\epsilon > 0$ then take $\delta>0$ as above and for any $n>0$ we have
Therefore
\begin{align*}
\abs{f*\rho_n(x) - f(x)} &= \abs{\int_{-\infty}^{\infty} \rho_n(x-y)
  (f(y) - f(x)) \, dy} \\
&\leq \int_{\abs{x-y} < \delta} \rho_n(x-y)
  \abs{  f(y) - f(x) } \, dy + \int_{\abs{x-y} \geq \delta} \rho_n(x-y)
  \abs{ f(y) - f(x) } \, dy \\
&\leq \epsilon + 2M \int_{\abs{x-y} \geq \delta} \rho_n(x-y) \, dy
\end{align*}
Now we consider the last term and change integration variables
\begin{align*}
\int_{\abs{x-y} \geq \delta} \rho_n(x-y) \, dy &= \int_{\abs{y} \geq
  \delta} \rho_n(y) \, dy \\
&= \frac{1}{\sqrt{2 \pi}} \int_{\abs{y} \geq
  n\delta} e^{-y^2/2} \, dy \\
&\leq \frac{2}{\sqrt{2 \pi}} \int_{n\delta}^\infty \frac{y}{n\delta}
e^{-y^2/2} \, dy \\
&= \frac{2}{n \delta \sqrt{2 \pi}} e^{-n^2\delta^2/2}
\end{align*}
One point here is the elementary fact that $\lim_{n \to \infty} \frac{2}{n \delta
  \sqrt{2 \pi}} e^{-n^2\delta^2/2} = 0$ but the second point is that this limit does
not depend on $x$.   Thus we may pick $N > 0$ independent of $x$, such
that $\int_{\abs{x-y} \geq \delta} \rho_n(x-y) \, dy  <
\frac{\epsilon}{2M}$ for $n > N$ and therefore
\begin{align*}
\abs{f*\rho_n(x) - f(x)} < 2 \epsilon
\end{align*}
which proves the uniform convergence of $f*\rho_n$.
\end{proof}

\section{Daniell-Stone Integrals}

We record some required facts about $\sigma$-rings that are completely
analogous to corresponding facts about $\sigma$-algebras.

\begin{lem}Let $X$ be a topological space and let $\mathcal{B}(X)$ be
  the Borel $\sigma$-algebra on $X$.  If $A$ is a Borel set then
  $\lbrace B \in \mathcal{B}(X) \mid B \subset A \rbrace$ is a
  $\sigma$-ring of sets in $X$.
\end{lem}
\begin{proof}
Clearly it contains the empty set and is closed under countable
union.  To see that it is closed under set difference simply note $B
\setminus C = B \cap C^c \subset B \subset A$ and is clearly a Borel
set of $X$.  
\end{proof}
Note that in fact the set of sets in the previous Lemma is the Borel
$\sigma$-algebra of $A$ with the induced topology.
By virtue of the above Lemma we will refer to the $\sigma$-ring of
Borel sets on $\reals$ that do not contain $0$ as $\mathcal{B}(\reals
\setminus \lbrace 0 \rbrace)$.  This is at the risk of potential
confusion about whether we are considering this a $\sigma$-ring of
subsets of $\reals$ or a $\sigma$-algebra of subsets of $\reals
\setminus \lbrace 0 \rbrace$; pretty much we always have the former
interpretation in mind.  Our first order of business is to establish a
simple generating set for Borel $\sigma$-ring on $\reals$.

\begin{lem}\label{IntervalsGenerateBorelPunctured}The $\sigma$-ring of Borel sets of $\reals$ that do not
  contain $0$ is generated by intervals $(-\infty, -c)$ and $(c,
  \infty)$ with $c > 0$.
\end{lem}
\begin{proof}
As noted above the $\sigma$-ring in the statement of the Lemma is the
$\sigma$-algebra of $\reals \setminus \lbrace 0 \rbrace$ in the
induced topology.  We know that open sets of $\reals$ are precisely
countable disjoint unions of open intervals (Lemma
\ref{OpenSetsOfReals}).  For any open interval $(a,b)$ we either have
$(a,b) \subset \reals \setminus \lbrace 0 \rbrace$ or $a < 0 < b$
hence $(a,b) \cap \reals \setminus \lbrace 0 \rbrace = (a,0) \cup
(0,b)$.  We conclude that the open sets of $\reals \setminus \lbrace 0
\rbrace$ are countable disjoint unions of open intervals none of which
contains $0$.  Now one can adapt the proof of Lemma
\ref{IntervalsGenerateBorel} to get the result.
\end{proof}

One of the most often used facts from measure theory is the fact that
measurable functions may be approximated by simple functions (Lemma
\ref{PointwiseApproximationBySimple}).  We need a small refinement of
that Lemma that applies with $\sigma$-rings.
\begin{lem}\label{PointwiseApproximationBySimpleSigmaRing}For any
  function $f : \Omega \to \overline{\reals}_+$ 
measurable with respect to a $\sigma$-ring $\mathcal{R}$, there exist a sequence of simple 
  functions $f_1, f_2, \dots$ measurable with respect to $\mathcal{R}$
  such that $0 \leq f_n \uparrow f$.
\end{lem}
\begin{proof}
Recalling the proof of \ref{PointwiseApproximationBySimple}, define
\begin{align*}
f_n(\omega) = 
\begin{cases}k2^{-n} & \text{if $k2^{-n} \leq f(\omega) < (k+1)2^{-n}$
    and $0 \leq k \leq n2^n -1$.} \\
n & \text{if $f(\omega) \geq n$.}
\end{cases}
\end{align*}
and we know that $f_n$ are simple functions $f_n \uparrow f$.  The
only thing to prove is that the $f_n$ are $\mathcal{R}$-measurable;
this follows because each preimage of $f_n$ is either of the form
$f^{-1}([k2^{-n}, (k+1)2^{-n}))$, for $k =0, \dotsc, n2^n -1$ or
$f^{-1}([n, \infty))$ and $f_n=0$ precisely on $f^{-1}([0,1/2^n))$.
Therefore every preimage of a set in $\mathcal{B}(\reals \setminus
\lbrace 0 \rbrace)$ is a union of sets $f^{-1}([k2^{-n}, (k+1)2^{-n}))$, for $k =1, \dotsc, n2^n -1$ or
$f^{-1}([n, \infty))$ and is therefore in $\mathcal{R}$ by the
$\mathcal{R}$-measurability of $f$.
\end{proof}

TODO:  Introduce notation for the $\sigma$-ring generated by a
set of sets.

\begin{lem}\label{SigmaRingPullbackGenerators}Let $f : S \to T$ be a set mapping and let $\mathcal{C}
  \subset 2^T$, then the $\sigma$-ring generated by
  $f^{-1}(\mathcal{C})$ is the same as the pullback of the
  $\sigma$-ring generated by $\mathcal{C}$.
\end{lem}
\begin{proof}
It is clear that the $\sigma$-ring generated by $f^{-1}(\mathcal{C})$
is contained in the pullback of the $\sigma$-ring generated by
$\mathcal{C}$.  To see the reverse conclusion, pushforward the
$\sigma$-ring generated by $f^{-1}(\mathcal{C})$; this is equal to
$\lbrace A \subset T \mid f^{-1}(A) \text{ is in the $\sigma$-ring
  generated by } f^{-1}(\mathcal{C})\rbrace$ and is itself a $\sigma$-ring
(Lemma \ref{SigmaRingPullback}).  It clearly contains $\mathcal{C}$ and therefore
the $\sigma$-ring generated by $\mathcal{C}$ as well.  Therefore the
pullback of the $\sigma$-ring generated by $\mathcal{C}$ is contained
in $\sigma$-generated by $f^{-1}(\mathcal{C})$ and we are done.
\end{proof}

It turns out that having a countably additive set function on a
$\sigma$-ring is almost the same thing as having a measure on the
generated $\sigma$-algebra.  This fact is made precise by the
following result.
\begin{lem}\label{ExtendingMeasuresFromSigmaRing}Let $\mathcal{R}$ be a $\sigma$-ring on a set $S$ and let
  $\mu : \mathcal{R} \to \overline{\reals}_+$ be a function that is
  countably additive on disjoint sets.  Let $\mu_*(E) = \sup \lbrace
  \mu(A) \mid A
  \subset E \text{ and } A \in \mathcal{R} \rbrace$ be the inner measure
  defined by $\mu$ on all of $2^S$.  Let $\mathcal{A} = \mathcal{R}
  \cup \mathcal{R}^c$ be the $\sigma$-algebra generated by
  $\mathcal{R}$.
\begin{itemize}
\item[(i)]If we define $\tilde{\mu}(A) = \mu(A)$ for $A \in
  \mathcal{R}$ and $\tilde{\mu}(A) = \infty$ for $A \in \mathcal{R}^c$
  then $\tilde{\mu}$ is a measure on $\mathcal{A}$.
\item[(ii)]For any $b \in \overline{\reals}_+$ if we define
  $\tilde{\mu}(A) = \mu(A)$ for $A \in
  \mathcal{R}$ and $\tilde{\mu}(A) = \mu_*(A) + b$ for $A \in \mathcal{R}^c$
  then $\tilde{\mu}$ is a measure on $\mathcal{A}$.
\item[(iii)]Every measure on $\mathcal{A}$ that extends $\mu$ on
  $\mathcal{R}$ is of the above form.
\item[(iv)]$\mu$ has a unique extension to $\mathcal{A}$ if and only
  if $\mathcal{R} = \mathcal{A}$ or $\mu_*(A) = \infty$ for every $A \in \mathcal{R}^c$.
\end{itemize}
\end{lem}
\begin{proof}
There is nothing to prove if $\mathcal{R} =
\mathcal{A}$ so we assume otherwise.  Note that in this case there are no
disjoint sets in $\mathcal{R}^c$ (if $A,B \in \mathcal{R}^c$ satisfy
$A \cap B = \emptyset$ then taking complements $A^c \cup B^c = S$
which shows $S \in \mathcal{R}$ which implies $\mathcal{R} =
\mathcal{A}$).

To prove the that the proposed set functions are measures we only need
to show countable additivity over all of $\mathcal{A}$.  By the above
comment we can assume that we have $A_1, A_2, \dots \in \mathcal{R}$
and $A_0 \in \mathcal{R}^c$ which are all disjoint.  Recall that $\cup_{i=0}^\infty
A_i \in \mathcal{R}^c$.  For (i) we have
\begin{align*}
\infty &= \tilde{\mu}(\cup_{i=0}^\infty A_i ) & &\text{by
  definition of $\tilde{\mu}$ on $\mathcal{R}^c$} \\
&=\sum_{i=0}^\infty \mu(A_i) & & \text{since $\tilde{\mu}(A_0)=\infty$}
\end{align*}

For (ii) things are a little more complicated.  First we handle the
case of $b=0$.  Since for any $A \in \mathcal{R}$ we have $\mu_*(A) =
\mu(A)$ we simplify notation and let the extension be denoted by $\mu_*$.  Note that 
for any $\epsilon > 0$ we can find $B_0 \in \mathcal{R}$ such that
$B_0 \subset A_0$ and $\mu(B_0) \geq \mu_*(A_0) -\epsilon$.  Then if
we define $B_i = A_i$ for $i=1,2,\dotsc$ we have the $B_i$ are all disjoint sets in
$\mathcal{R}$ and $\cup_{i=0}^\infty B_i \subset \cup_{i=0}^\infty A_i $.  Therefore
\begin{align*}
\mu_*(\cup_{i=0}^\infty A_i) &= \sup \lbrace \mu(C) \mid C \subset
\cup_{i=0}^\infty A_i \text{ and } C \in \mathcal{R}\rbrace \\
&\geq \mu(\cup_{i=0}^\infty B_i) \\
&= \sum_{i=0}^\infty \mu(B_i) \\
&\geq \sum_{i=0}^\infty \mu_*(A_i) - \epsilon \\
\end{align*}
Since $\epsilon$ was arbitrary we conclude
$\mu_*(\cup_{i=0}^\infty A_i) \geq \sum_{i=0}^\infty \mu_*(A_i)$.

To see the other inequality, for any $\epsilon >0$ we can pick $C \in
\mathcal{R}$ such that $C \subset \cup_{i=0}^\infty A_i$ and $\mu(C)
\geq \mu_*(\cup_{i=0}^\infty A_i) - \epsilon$.  Since $A_0 \in
\mathcal{R}^c$ there is a $B_0 \in \mathcal{R}$ such that $A_0 =
B_0^c$ and therefore $C \cap A_0 = C \cap B_0^c = C\setminus B_0 \in
\mathcal{R}$.  Because $A_i \in \mathcal{R}$ for $i=1,2,\dotsc$ we
know that $A_i \cap C \in \mathcal{R}$ for $i=1,2, \dotsc$.  Putting
these two observations together we know can write $C =
\cup_{i=0}^\infty C_i$ where each $C_i = C \cap A_i \in \mathcal{R}$,
$C_i \subset A_i$ and $C_i$ are disjoint.  Now applying the definition
of $\mu_*$ and countable additivity and monotonicity of $\mu$ we see
\begin{align*}
\mu_*(\cup_{i=0}^\infty A_i) - \epsilon &\leq \mu(C) = \sum_{i=0}^\infty \mu(C_i) \leq \sum_{i=0}^\infty \mu_*(A_i)
\end{align*}
Since $\epsilon > 0$ was arbitrary we conclude
$\mu_*(\cup_{i=0}^\infty A_i)  \leq \sum_{i=0}^\infty
\mu_*(A_i)$ and therefore we have proven $\mu_*(\cup_{i=0}^\infty A_i)  = \sum_{i=0}^\infty
\mu_*(A_i)$.

Now we extend the argument to see that defining $\tilde{\mu}(A) =
\mu_*(A) + b$ on $\mathcal{R}^c$ also defines a measure.  Once again
only countable additivity needs to be shown.  As noted
$\cup_{i=0}^\infty A_i \in \mathcal{R}^c$ so using what we have just
proven for $\mu_*$,
\begin{align*}
\tilde{\mu}(\cup_{i=0}^\infty A_i) &= \mu_*(\cup_{i=0}^\infty A_i ) +
b = \mu_*(A_0) + \sum_{i=1}^\infty \mu(A_i) + b = \sum_{i=0}^\infty \tilde{\mu}(A_i)
\end{align*}

To see (iii) we must show that every extension of $\mu$ to
$\mathcal{A}$ has the form $\mu_* + b$ on $\mathcal{R}^c$ for a particular $b \in
\overline{\reals}_+$.  Let $\tilde{\mu}$ be an extension of $\mu$ to
$\mathcal{A}$.  Suppose we have $A_1, A_2 \in
\mathcal{R}^c$.  From monotonicity we know that
$\mu_*(A) \leq \tilde{\mu}(A)$ for every $A\in \mathcal{R}^c$.  So
there exists constants $b_1, b_2 \in \overline{\reals}_+$ such that
$\tilde{\mu}(A_i) = \mu_*(A_i) + b_i$ for $i=1,2$ and we need to show
that $b_1 = b_2$.   In addition since $A_1 \cup A_2 \in \mathcal{R}^c$, there is a $b$ such that
$\tilde{\mu}(A_1 \cup A_2) = \mu_*(A_1 \cup A_2) + b$.  Note that $A_2 \setminus A_1 = A_2 \cap A_1^c = A_1^c
\setminus A_2^c \in \mathcal{R}$ therefore
\begin{align*}
\mu_*(A_1 \cup A_2) + b &= \tilde{\mu}(A_1 \cup A_2) =
\tilde{\mu}(A_1) + \tilde{\mu}(A_2 \setminus A_1) = \mu_*(A_1) + b_1 +
\mu_*(A_2 \setminus A_1)
\end{align*}
which implies $b = b_1$ since $\mu_*$ is a measure.  The same argument
shows that $b = b_2$ hence we see that $b_1 = b_2$ and we are done.

The claim in (iv) is direct consequence of what we have shown.  If
$\mu_*(A) \neq \infty$ for some $A \in \mathcal{R}^c$ then we have
constructed a uncountably infinite number of distinct extension of
$\mu$ given by $\mu_* + b$ on $\mathcal{R}^c$.  On the other hand if
$\mu_*(A) = \infty$ for all $A \in \mathcal{R}^c$ then we know any
extension must be of the form $\mu_* + b$ on $\mathcal{R}^c$ but these
are all equal to $\infty$ so the uniqueness of the extension is established.
\end{proof}

\begin{examp}It is instructive to consider the scenario of the
  previous Lemma in the context of the specific example of the
  $\sigma$-ring generated by taking the set of Borel sets on $\reals$
  that do not contain $0$ and Lebesgue measure.  We are clearly in the
  non-unique case with this example and the different extensions
  correspond to putting point masses with different weights at $0$.
\end{examp}
We have developed tools that enable us to define measures based on
more primitive set functions and this has allowed us to create very
important measures such as Lebesgue measure on $\reals$.  There is
another broad class of results that exist that allow one to construct
measures.  The basic observation is that a measure begets an integral
that is a linear function from measurable functions to the extended
reals hence it makes sense to pose the question of when a linear
functional on some set of measurable functions arises from a measure.
Being in possession of such results we are in a position to construct
measures by constructing linear functionals instead.  In all cases the
results in the space make some assumptions about the space of
measurable functions on which the functional is defined.  In this
section we consider the first result in this class; one that is
distinguished by the fact that it works on general spaces that do not
possess any topological structure.

\begin{defn}Let $\mathcal{L}$ be a real vector space of real valued
  functions on a set $\Omega$.  We say $\mathcal{L}$ is a \emph{vector
    lattice} if given any $f,g \in \mathcal{L}$ we have $f \vee g \in
  \mathcal{L}$ and $f \wedge g \in \mathcal{L}$.
\end{defn}

\begin{prop}If $\mathcal{L}$ is a real vector space of real valued
  functions on a set $\Omega$ such that for any $f,g \in \mathcal{L}$
  we have $f \vee g \in \mathcal{L}$ then $\mathcal{L}$ is a vector lattice.
\end{prop}
\begin{proof}
Simply note that $f \wedge g = -(-f \vee -g)$.  
\end{proof}

\begin{defn}Given a set $\Omega$ and a vector lattice $\mathcal{L}$ of
  real functions on $\Omega$ a \emph{pre-integral} is a linear
  function $I : \mathcal{L} \to \reals$ such that 
\begin{itemize}
\item[(i)]if $f \in \mathcal{L}$ and $f \geq 0$ then $I(f) \geq 0$
\item[(ii)]if $f_1, f_2, \dots \in \mathcal{L}$ such that $f_n
  \downarrow 0$ then $I(f_n) \downarrow 0$.
\end{itemize}
\end{defn}

To construct a measure that corresponds to a pre-integral we make an
intermediate step using the interpretation of an integral as the area
under a curve.  This will provide us with a measure on the product
space $\Omega \times \reals$ and then we will show how we restrict
this measure in an appropriate way to construct the measure that
generates an integral equivalent to $I$.

\begin{thm}\label{Zaanen}Let $\mathcal{L}$ be a vector lattice of
  functions on a set $S$ with a pre-integral $I$.  For any $f, g \in \mathcal{L}$ such
  that $f \leq g$ we define
\begin{align*}
[f, g) &= \lbrace (s, t) \in S \times \reals \mid f(s)
\leq t < g(s) \rbrace
\end{align*}
, $\mathcal{D} = \lbrace [f,g) \mid f,g \in \mathcal{L}
\text{ such that } f\leq g\rbrace$ and $\nu([f,g)) = I(g - f)$.  Then
$\nu$ is countably additive on $\mathcal{D}$ and extends to a measure on the
$\sigma$-algebra generated by $\mathcal{D}$.

For every $c > 0$, we let $M_c : S \times \reals \to S \times
\reals$ be the mapping $M_c(s,t) = (s, ct)$.  Then $M_c^{-1} : 2^{S
  \times \reals} \to 2^{S \times \reals}$ restricts to a bijection on
the $\sigma$-algebra generated by $\mathcal{D}$ and furthermore for
every set $A \in \sigma(\mathcal{D})$ and $c >0$ we have $c
\nu(M_c^{-1} A) = \nu(A)$.
\end{thm}
\begin{proof}
The proof proceeds by showing that $\mathcal{D}$ is a semiring, that
$\nu$ is countably additive on $\mathcal{D}$ and by applying Lemma (TODO:).

Let $c > 0$ and consider the mapping $M_c(s,t) = (s, ct)$.  

Claim 1: $M_c^{-1}(\sigma(\mathcal{D})) = \sigma(\mathcal{D})$.

Since $M_c$ is a bijection it follows that $M_c^{-1} : 2^{S \times \reals}
\to 2^{S \times \reals}$ is also a bijection.  Furthermore if we
consider a set of the form $[f,g)$ then 
\begin{align*}
M_c^{-1}([f,g)) &= \lbrace (s,t) \in S \times \reals \mid f(s) \leq ct
< g(s) \rbrace \\
&= \lbrace (s,t) \in S \times \reals \mid (f/c)(s) \leq t
< (g/c)(s) \rbrace = [f/c, g/c)
\end{align*}
So if $[f,g) \in \mathcal{D}$ then it follows from the fact that
$\mathcal{L}$ is a vector space that $M_c^{-1}$ is bijection of
$\mathcal{D}$
to itself.  In particular, we know that $M_c^{-1}
(\sigma(\mathcal{D}))$ is a $\sigma$-algebra containing $\mathcal{D}$
  and therefore $M_c^{-1}
(\sigma(\mathcal{D})) \supset \sigma(\mathcal{D})$.  On the other
  hand, $(M_c)_*(\sigma(\mathcal{D})) = \lbrace A \subset S \times
  \reals \mid M_c^{-1}(A) \in \sigma(\mathcal{D}) \rbrace$ is also
  $\sigma$-algebra (Lemma \ref{SigmaAlgebraPullback}) containing
  $\mathcal{D}$; hence $\sigma(\mathcal{D}) \subset
  (M_c)_*(\sigma(\mathcal{D}))$ which implies
  $M_c^{-1}(\sigma(\mathcal{D})) \subset \sigma(\mathcal{D})$.

Claim 2: For any $A \in \sigma(\mathcal{D})$ and $c > 0$ we have $c
\nu(M_c^{-1}(A)) = \nu(A)$.

We start with considering $[f,g) \in \mathcal{D}$.  We have already
seen that $M_c^{-1}([f,g)) = [f/c, g/c)$ so we can just apply the
definition to see the claim holds.
\begin{align*}
c \nu(M_c^{-1}([f,g))) &= c \nu([f/c,g/c)) = c I(f/c-g/c) = I(f-g) =
\nu([f,g))
\end{align*}
To extend to the ring $\mathcal{R}$ generated by $\mathcal{D}$ we note that every
element of the ring is a disjoint union of elements in $\mathcal{D}$.
Furthermore $M_c^{-1}$ preserves the Boolean algebra structure on
$2^{S \times \reals}$ (Lemma \ref{SetOperationsUnderPullback})
therefore 
we have
\begin{align*}
c \nu(M_c^{-1}(\cup_{i=1}^n [f_i, g_i))) &= c \nu(\cup_{i=1}^n
M_c^{-1}([f_i, g_i))) = c \sum_{i=1}^n \nu(M_c^{-1}([f_i,g_i))) \\
&= \sum_{i=1}^n \nu([f_i,g_i)) = \nu(\cup_{i=1}^n [f_i, g_i))
\end{align*}
To extend to all of $\sigma(\mathcal{D})$ we use the fact that $\nu$
is defined as its associated outer measure $\nu(A) = \inf \lbrace
\nu(B) \mid B \supset A \text{ and } B \in \mathcal{R}\rbrace$.
Consider $A \in \sigma(\mathcal{D})$ and let $\epsilon > 0$.  By
definition we can find $B \in \mathcal{R}$ such that $B \supset A$ and
$\nu(B) \leq \nu(A) + \epsilon$.  Again applying Lemma
\ref{SetOperationsUnderPullback} we see that $M_c^{-1} (B) \in
\mathcal{R}$ and $M_c^{-1}(B) \supset M_c^{-1}(A)$ and therefore
\begin{align*}
c \nu(M_c^{-1}(A)) & c \leq M_c^{-1}(B) = \nu(B) \leq \nu(A) +\epsilon
\end{align*}
Since $\epsilon>0$ was arbitrary we conclude that $c \nu(M_c^{-1}(A))
\leq \nu(A)$.  In the opposite direction for every $\epsilon > 0$ we
can find $M_c^{-1}(B) \supset M_c^{-1}(A)$ such that $\nu(M_c^{-1}(B)
\leq \nu(M_c^{-1}(A)) + \epsilon$.  We know that $B \supset A$ and
therefore
\begin{align*}
\nu(A) &\leq \nu(B) = c \nu(M_c^{-1}(B) \leq c \nu(M_c^{-1}(A)) + \epsilon
\end{align*}
so letting $\epsilon$ go to zero we conclude $\nu(A) \leq c
\nu(M_c^{-1}(A))$ and we are done.

TODO: In the proof we use the fact that $M_c^{-1}$ is a bijection on
$\mathcal{R}$ which is a simple consequence of the fact $M_c^{-1}$ is
a bijection on $\mathcal{D}$ and Lemma \ref{SetOperationsUnderPullback};
find the correct place to note this fact explicitly.
\end{proof}

\begin{thm}\label{DaniellStoneTheorem}Let $I$ be a pre-integral on a Stone vector lattice
  $\mathcal{L}$.  Then on the $\sigma$-algebra generated by the
  lattice $\mathcal{L}$ there is a measure $\mu$ such that $I(f) =
  \int f \, d\mu$ for all $f \in \mathcal{L}$.  Futhermore the measure
  $\mu$ is uniquely determined on the $\sigma$-ring generated by $\mathcal{L}$.
\end{thm}
\begin{proof}
We proceed by first defining our measure on the $\sigma$-ring
$\mathcal{R}$ generated by the functions $\mathcal{L}$.  This can be extended (not
necessarily uniquely) to a measure on the $\sigma$-algebra using Lemma \ref{ExtendingMeasuresFromSigmaRing}.
Because we have arranged for all of the functions in $\mathcal{L}$ to
be $\mathcal{R}$ measurable their integrals will not depend on the
extension of $\mu$ to a full $\sigma$-algebra and their integrals will
be determined by the values of $\mu$ on $\mathcal{R}$ alone.

Claim 1: $\mathcal{R}$ is generated by sets of the form $f^{-1}(1,
\infty)$ for $f \in \mathcal{L}$.

Note that for $c > 0$, 
\begin{align*}
f^{-1}(c, \infty) &= 
\lbrace \omega \in \Omega \mid f(\omega) \geq c \rbrace = 
\lbrace \omega \in \Omega \mid \left(f/c\right)(\omega) \geq 1 \rbrace =
\left(f/c\right)^{-1}(1, \infty)
\end{align*}
and since $\mathcal{L}$ is a Stone lattice (a fortiori a real vector
space) we know that $f/c \in \mathcal{L}$.  A similar argument
shows that for $c > 0$, $f^{-1}(-\infty, -c) = (-f/c)^{-1}(1,
\infty)$.  We know that intervals $(-\infty, -c)$ and $(c, \infty)$
generate the $\sigma$-ring on $\reals \setminus \lbrace 0 \rbrace$,
therefore for any $f \in \mathcal{L}$, we have
$f^{-1}(\mathcal{B}(\reals\setminus \lbrace 0 \rbrace)$ is the
$\sigma$-ring generated by sets $f^{-1}(c, \infty)$ and
$f^{-1}(-\infty, -c)$ for $c > 0$
(Lemma \ref{SigmaRingPullbackGenerators}) which are the same as the sets
$(f/c)^{-1}(1, \infty)$ for $c \neq 0$. Thus the $\sigma$-ring generated by $\cup_{f
  \in \mathcal{L}} f^{-1}(\mathcal{B}(\reals\setminus \lbrace 0
\rbrace)$ is contained in the $\sigma$-ring generated by $\cup_{f \in
  \mathcal{L}} f^{-1}(1, \infty)$.

Claim 2: We can define a measure $\mu$ on the $\sigma$-algebra
generated by $\mathcal{L}$.

If suffices to define a countably additive set function on the $\sigma$-ring $\mathcal{R}$
(Lemma \ref{ExtendingMeasuresFromSigmaRing}).  We define the measure by embedding $\mathcal{R}$ as
sub-$\sigma$-ring in $\sigma$-algbra $\mathcal{A}$ constructed in
Theorem \ref{Zaanen}.  To see this, suppose that we have a set $A =
f^{-1}(1, \infty)$ with $f \in \mathcal{L}$ and $f \geq 0$.  For arbitrary $c > 0$,
we define
\begin{align*}
f_n(\omega) &= n(f(\omega) - f(\omega) \wedge 1) \wedge c
= \begin{cases}
0 &  \text{if $\omega \notin A$} \\
n(f(\omega) - 1) \wedge c & \text{if $\omega \in A$}
\end{cases}
\end{align*}
and observe that $f_n \in \mathcal{L}$ and $f_n \uparrow c\characteristic{A}$.  Applying this
observation to graphs of $f_n$ in $\Omega \times \reals$ we see that
$A \times [0,c) = [0, c\characteristic{A}) = \cup_{n=1}^\infty [0, f_n)$ which shows that $A
\times [0,c) \in \mathcal{A}$ for all $c > 0$.  From this it follows
that $A \times [0,c) \in \mathcal{A}$ for all $A \in \mathcal{R}$.  To
see this note that for a fixed $c >0$, the set $\mathcal{R}_c = \lbrace A \times [0,c)
\mid A \in \mathcal{R} \rbrace$ is a $\sigma$-ring and the set
$\lbrace A \subset \Omega \mid A \times [0,c) \in \mathcal{R}_c
\rbrace$ is a $\sigma$-ring (it can be constructed as a pushforward
under an appropriately constructed map or one can see it directly)
that contains sets of the form $f^{-1}(1, \infty)$.  Thus,
$\mathcal{R} \subset \lbrace A \subset \Omega \mid A \times [0,c) \in \mathcal{R}_c
\rbrace$.

Having shown that $\mathcal{R}_c$ is a $\sigma$-ring in $\mathcal{A}$,
we take $c=1$ and define $\mu(A) = \nu(A \times [0,1)$.  That this
is countably additive follows from the fact that $\nu$ is a measure,
so we can extend $\mu$ to the $\sigma$-algebra $\mathcal{R} \cup
\mathcal{R}^c$ in any way we chose.

Now we show how to compute integrals of functions $f \in \mathcal{L}$
with respect to $\mu$ and show that they agree with the pre-integral
$I$.
Claim 3: For every $\mathcal{R}/\mathcal{B}(\reals \setminus \lbrace 0
\rbrace)$ simple function $f \geq 0$ of the form $f = \sum_{i=1}^n c_i
\characteristic{A_i}$ we have $\int f \, d\mu = \nu([0,f))$.

To see this we know by Theorem \ref{Zaanen} that for every $c > 0$ and
$B \in \mathcal{A}$ we have $c \nu(M_c^{-1}(B) = \nu(B)$.  We have
shown that for every $A \in \mathcal{R}$, we have $A \times [0,c) \in
\mathcal{A}$ and by definition $M_c^{-1}(A \times [0,c)) = A \times
[0,1)$; therefore $\nu(A \times [0,c)) = c \nu(A \times [0,1)) = c
\mu(A)$. It is also easy to see that $A \times [0,c) = [0,
c\characteristic{A})$, so we have for scalar multiples of
characteristic functions $\int f \, d\mu = \nu([0,f))$.  As for simple
functions, each can be expressed as a sum $f = \sum_{i=1}^n c_i
\characteristic{A_i}$ with $A_i \in \mathcal{R}$ and the $A_i$
disjoint.  Once again by definition we can see that $[0,f) =
\cup_{i=1}^n [0, c \characteristic{A_i})$ where the disjointness of
the $A_i$ implies that the sets $ [0, c \characteristic{A_i})$ are
disjoint.  Now by definition of the integral for a simple function and
the additivity of the measure $\nu$ we get
\begin{align*}
\int f \, d \mu &= \sum_{i=1}^n c_i \mu(A_i) = \sum_{i=1}^n \nu([0,c_i
\characteristic{A_i})) = \nu([0,f))
\end{align*}

Claim 4: For every $\mathcal{R}/\mathcal{B}(\reals \setminus \lbrace 0
\rbrace)$-measurable function $f \geq 0$ we have $\int f \, d\mu =
\nu([0,f))$.

We take a sequence of positive simple functions $f_n \uparrow f$ which
exists by Lemma \ref{PointwiseApproximationBySimpleSigmaRing}.
Since $[0,f_n) \uparrow [0,f)$ we can use the definition of integral
with respect to $\mu$, continuity of measure with respect to $\nu$ and
Claim 3 to see
\begin{align*}
\int f \, d \mu &= \lim_{n \to \infty} \int f_n \, d\mu = \lim_{n \to
  \infty} \nu([0,f_n)) = \nu([0,f))
\end{align*}

By definition we have arranged for all $f \in
\mathcal{L}$ to be $\mathcal{R}/\mathcal{B}(\reals \setminus \lbrace 0
\rbrace)$-measurable so by Claim 4 and the definition of $\nu$, for $f
\in \mathcal{L}$ with $f \geq 0$ we have $\int f \, d \mu = \nu([0,f))
= I(f)$.  For arbitrary $f \in \mathcal{L}$ we write $f = f_+ - f_-$
with $f_+, f_- \in \mathcal{L}$ and $f_+, f_- \geq 0$ and use
linearity of integral and pre-integral to conclude that $\int f \, d
\mu = \int f_+ \, d\mu - \int f_- \, d\mu = I(f_+) - I(f_-) = I(f)$.
\end{proof}

It should be remarked that one can develop a good deal of measure an
integration theory starting from some of the concepts introduced in
this section; indeed for a short period of time it was fashionable to
do this instead of taking the approach of developing the theory of
$\sigma$-algebras, measure and integral in the way we have done.
Alas, that fashion has passed so we content ourselves with the most
streamlined presentation of these ideas we know that gives us Theorem \ref{DaniellStoneTheorem}.

