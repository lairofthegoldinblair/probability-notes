\chapter{More Real Analysis}
Holding area for more advanced topics in real analysis that are
eventually required (and in some cases there may be some topics that I
am just interested in).
\section{Topological Spaces}
\begin{lem}\label{OpenAlternative}A set $U \subset X$ is open if and only if for every $x \in
  U$ there is an open set $V \subset U$ such that $x \in V$.
\end{lem}
\begin{proof}
Suppose $U$ is open and $x \in U$, then let $V = U$.

Suppose for every $x \in U$ there exist an open set $V_x$ such that $x
\in V_x \subset U$.  Note that $\cup_x V_x \subset U$ because each
$V_x \subset U$ and on the other hand $\cup_x V_x \supset U$ since
every $x \in U$ satisfies $x \in V_x$.  Thus $U = \cup_x V_x$ which
shows that $U$ is open.
\end{proof}
\begin{defn}A mapping $f : X \to Y$ between topological spaces is said
  to be \emph{continuous} if and only if $f^{-1}(V)$ is open in $X$
  for every $V$ open in $Y$.
\end{defn}
\begin{defn}A mapping $f : X \to Y$ between topological spaces is said
  to be \emph{continuous at x} if and only if for every $V$ open in
  $Y$ such that $f(x) \in V$, there exists an open set $U$ in $X$ with $x \in U$ and $f(U)
  \subset V$.
\end{defn}
\begin{lem}A mapping $f : X \to Y$ between topological spaces is
  continuous if and only if it is continuous at $x$ for every $x \in X$.
\end{lem}
\begin{proof}
Suppose $f$ is continuous and let $x \in X$ and $V$ be open in $Y$
with $f(x) \in V$.  By continuity of $f$, we know that $f^{-1}(V)$ is
open in $X$ and $x \in f^{-1}(V)$.  By Lemma \ref{OpenAlternative} we
can pick an open set $U$ such that $x \in U$ and $U \subset
f^{-1}(V)$.  It follows that $f(U) \subset V$.

Now suppose $f$ is continuous at every $x \in X$ and let $V$ be open
in $Y$.  If $x \in f^{-1}(V)$ then $f$ is continuous at $x$ hence
there exists and open $U$ such that $x \in U$ and $f(U) \subset V$.
It follows that $U \subset f^{-1}(V)$ and by Lemma
\ref{OpenAlternative}  we have shown that $f^{-1}(V)$ is open.
\end{proof}

\begin{defn}A \emph{base} of a topology $\mathcal{T}$ at a point $x
  \in X$ is a collection
  of sets $\mathcal{B}$ such that for every open set $U \in
  \mathcal{T}$ such that $x \in U$ there exists a $B \in \mathcal{B}$ such
  that $x \in B \subset U$.  A base of a topology is a collection of
  sets that is a base at all points $x \in X$.
\end{defn}

\begin{lem}A set $\mathcal{B}$ of sets $B \subset X$ is a base of a
  topology if and only if for every $x \in X$ there exists $B \in
  \mathcal{B}$ such that $x \in B$ and for every $A, B \in
  \mathcal{B}$ and $x \in A \cap B$ there exists $C \in \mathcal{B}$
  such that $x \in C \subset A \cap B$.
\end{lem}
\begin{proof}
Suppose $\mathcal{B}$ satisfies the hypothesized conditions and let
\begin{align*}
\tau &= \lbrace U \subset X \mid \text { for every } x \in U \text{
  there exists } B \in \mathcal{B} \text{ such that } x \in B \subset
U \rbrace
\end{align*}
It is certainly the case that $\mathcal{B}\subset \tau$ and we claim that $\tau$ is a topology.  Certainly $\emptyset \in \tau$.
Let $U_\alpha$ for $\alpha \in \Lambda$ are sets in $\tau$.
Then if $x \in \cup_{\alpha \in \Lambda} U_\alpha$ there exists an
$\alpha \in \Lambda$ such that $x \in U_\alpha$ and by hypothesis we
pick $B$ such that $x \in B \subset U_\alpha \subset  \cup_{\alpha \in
  \Lambda} U_\alpha$.  If $U_1, \dotsc, U_n \in \tau$ and $x \in U_1
\cap \dotsc \cap U_n$ then there exists $B_1, \dotsc, B_n$ such that
$x \in B_j \subset U_j$ for $j = 1, \dotsc, n$ and therefore $x \in
B_1 \cap \dotsc \cap B_n \subset U_1 \cap \dotsc \cap U_n$.  A simple
induction on the hypothesis shows that $B_1 \cap \dotsc \cap B_n \in \mathcal{B}$.
Because $\mathcal{B}$ is cover of $X$ we have $X = \cup_{B \in
  \mathcal{B}} B \in \tau$ and therefore $\tau$ is a topology.  By the
definition of $\tau$ it is immediate that $\mathcal{B}$ is a base of
the topology.
\end{proof}


\begin{defn}
\begin{itemize}
\item[(i)]A topological space is said to be \emph{separable} if and
  only if it has a countable dense subset.
\item[(ii)]A topological space is said to be \emph{first countable} if and
  only if every point has a countable local base.
\item[(ii)]A topological space is said to be \emph{second countable} if and
  only if every the topology has a countable base.
\end{itemize}
\end{defn}
\begin{lem}A metric space is separable if and only if it is second countable.
\end{lem}
\begin{proof}
TODO:
outline of proof is to pick a countable dense subset $\lbrace x_n
\rbrace$ and then pick the open balls $B(x_n; \frac{1}{m})$ for $m \in
\naturals$.  Show this is a base of the topology.
\end{proof}

TODO: The goal of the next set of results is to show that separable
complete metric spaces are Borel.


The following appears in Royden as Theorem 8.11 (with proof delgated
to exercises)
\begin{lem}Let $X$ be a Hausdorff topological space, $Y$ be a
  complete metric space and $Z \subset X$ be a dense subset.  If $f :
  Z \to X$ is a homeomorphism then $Z$ is a countable intersection of
  open sets.
\end{lem}
\begin{proof}
For each $n$ let 
\begin{align*}
O_n &= \lbrace x \in X \mid \text{there exists $U$
  open with $x \in U$ and $\diam(f(U \cap Z)) < \frac{1}{n}$} \rbrace
\end{align*}
Note that $O_n$ is open because for any $x \in O_n$ by definition we
have the open set $U$ that provides the evidence that $x \in O_n$;
$U$ also provides the evidence that proves that every $y \in U$
belongs to $O_n$.  Also
note that $Z \subset O_n$ since for any $n$, by continuity of $f$ at $x \in Z$ and Lemma
\ref{OpenAlternative}  we
can find an open $U \subset X$ such that $x \in U \cap Z$ and $f(U \cap Z) \subset B(f(x),
\frac{1}{2n})$ (sets of the form $U \cap Z$ being precisely the open
sets in $Z$).

Now define $E = \cap_n O_n$.  As noted we know $Z \subset E$ so we
will be done if we can show $E
\subset Z$ as well.  Let $x \in E$; we will construct $z \in Z$
such that $x = z$.  For each $n$ pick $U_n$ such $x \in U_n$ and $\diam(f(U_n \cap Z)) <
\frac{1}{n}$ and let $x_n$ be an arbitrary point in $\cap_{j=1}^n
U_j \cap Z$ (the intersection is non-empty because $Z$ is dense in
$X$).  
For every $n$ and $m \geq n$ we have by construction that $x_n
\in U_n$ and $x_m \in U_n$ hence $d(f(x_n), f(x_m)) < \frac{1}{n}$.
Therefore $f(x_n)$ is Cauchy in
$Y$ and by completeness of $Y$ we know that $f(x_n)$ converges to a
value $y \in Y$ with $d(y, f(x_n)) \leq \frac{1}{n}$.  
Because $f$ is a homeomorphism we know that 
there is a unique $z \in Z$ such that $f(z) = y$; we claim that $x =
z$.  Suppose that $x
\neq z$, then by the Hausdorff property on $X$ we can pick open sets $U$ and
$V$ such that $U \cap V = \emptyset$, $x \in U$ and $z \in V$.  Since
$f$ is a homeomorphism, we know $f(Z \cap V)$ is open and contains
$f(z)$ hence for sufficiently large $n$, $f^{-1}(B(f(z), \frac{1}{n}))
\subset Z \cap V \subset V$.  On
the other hand, by the definition of $x$ we have $U_{2n}$ open such that
$x \in U_{2n}$ and $\diam(f(Z \cap U_{2n})) < \frac{1}{2n}$.  By openness of
$U \cap U_{2n}$ and density of $Z$ we know there is a $w \in U \cap
U_{2n} \cap Z$.  Putting these observations together we have
\begin{align*}
d(f(w), f(z)) &\leq  d(f(w), f(x_{2n})) + d(f(x_{2n}), f(z)) 
< \frac{1}{2n} + \frac{1}{2n} = \frac{1}{n}
\end{align*}
which implies $w \in V$ providing a contradiction of $U \cap V =
\emptyset$ hence we conclude $x = z$.
\end{proof}

\begin{thm}[Tychonoff's Theorem]\label{Tychonoff}Let $I$ be index set
  and let $(X_i,
  \mathcal{T}_i)$ be a topological space for each $i \in I$, the
  cartesian product $\prod_{i \in I} X_i$ with the product topology is
  compact.
\end{thm}
\begin{proof}
TODO:
\end{proof}

Separation axioms tells us that we have enough open sets in a topology
to distinguish features of the the underlying set (e.g. distinguishing
points from points or closed sets from closed sets).  Another way of
thinking about the size of a topology is by considering the number of
continuous functions that the topology allows.  The following theorem
shows that in normal topological spaces we have enough continuous
functions to approximate indicator functions of closed sets.

\begin{thm}[Uryshon's Lemma]\label{UrysohnsLemma}Let $X$ be a
  topological space, then following are equivalent
\begin{itemize}
\item[(i)]$X$ is normal
\item[(ii)]Given a closed set $F \subset X$ and an open neighborhood
  $F \subset U$ there is an open set $V$ such that $F \subset V
  \subset \overline{V} \subset U$.
\item[(iii)]Given disjoint closed sets $F$ and $G$ there exists a
  continuous function $f : X \to [0,1]$ such that $f \equiv 1$ on $F$
  and $f \equiv 0$ on $G$.
\item[(iv)]Given a closed set $F$ with an open neighborhood $U$ there
  is a continuous function $f$ such that $\characteristic{F}(x) \leq
  f(x) \leq \characteristic{U}(x)$ for all $x \in X$.
\end{itemize}
\end{thm}
\begin{proof}
(i) $\implies$ (ii): Since $U^c$ is and $F \cap U^c = \emptyset$ we
use normality to find disjoint open sets $V$ and $O$ such that $F \subset V$
and $U^c \subset O$.  Note that $\overline{V} \cap U^c = \emptyset$; if $x \in U^c$ then $O$ is an open neighborhood $x$ such that
$O \cap V$ which implies $x \notin \overline{V}$. Therefore we have $F
\subset V \subset \overline{V} \subset U$.

(ii) $\implies$ (i): Let $F$ and $G$ be closed subsets of $X$, it
follows that $G^c$ is open and $F \subset G^c$.  Find an open set $V$
such that $F \subset V \subset \overline{V} \subset G^c$ and observe
that if we define $U = \overline{V}^c$ then we have $V \cap U =
\emptyset$ and $F \subset V$ and $G \subset U$.

(iii) $\implies$ (iv): Construct continuous $f : X \to [0,1]$ such
that $f$ equals $1$ on $F$ and $f$ equals 0 on $U^c$.  Clearly
$\characteristic{F} \leq f$ and $\characteristic{U^c} \leq 1 -f$.  The
latter is equivalent to $f \leq \characteristic{U}$ since
$\characteristic{U^c} = 1 - \characteristic{U}$.

(iv) $\implies$ (iii):  Note that $F \subset G^c$ and construct $f$
such that $\characteristic{F} \leq f \leq \characteristic{G^c}$.  The
first inequality implies that $f \equiv 1$ on $F$ while the second
implies that $f \equiv 0$ on $(G^c)^c = G$.

(iii) $\implies$ (i):  Given $F$ and $G$ and a continuous function $f
: X \to [0,1]$ such that $F \subset f^{-1}(1)$ and $G \subset
f^{-1}(0)$, simply define $U =  f^{-1}(2/3,1]$ and $V = f^{-1}[0,1/3)$
and note that by continuity of $f$ both $U$ and $V$ are open.  

(ii) $\implies$ (iv):  We construct $f$ as a limit of (discontinuous)
indicator functions.  Suppose that $F$ and $U$ are given as in the
hypothesis in (iv).  Define $F_1 = F$ and $U_0 = U$.  Using (ii) we
find an open neighborhood $V$ such that $F_1 \subset V \subset
\overline{V} \subset U$.  Define $F_{1/2} = \overline{V}$ and $U_{1/2}
= V$ so we may rewrite our inclusions as 
\begin{align*}
F_1 &\subset U_{1/2} \subset F_{1/2} \subset U_{0}
\end{align*}
Now we iterate this construction.  To make it clear and to set the
notation for the iteration we turn the crank one more time we apply
(ii) to the pair $F_1 \subset U_{1/2}$ to construct an open set $U_{3/4}$
and closed set $F_{3/4}$ and to the pair $F_{1/2} \subset U_{0}$ to
construct an open set $U_{1/4}$
and closed set $F_{1/4}$ yielding the inclusions
\begin{align*}
F_1 &\subset U_{3/4} \subset F_{3/4} \subset U_{1/2} \subset F_{1/2} \subset U_{1/4} \subset F_{1/4} \subset U_{0}
\end{align*}
Now we induct over the dyadic rationals $\mathcal{D} = \lbrace a/2^n
\mid a \in \naturals \text{ and } n \in \naturals \rbrace \cap (0,1)$ so that we create a sequence
of open and closed sets $U_q$ and $F_q$ satisfying
\begin{itemize}
\item[(i)] $U_q \subset F_q$ for all $q \in \mathcal{D}$
\item[(i)] $F_r \subset U_q$ for all $r,q \in \mathcal{D}$ with $r > q$.
\end{itemize}
Now let $f(x) = \inf \lbrace q \mid x \in U_q \rbrace$.  
TODO: Show that $f$ works...
\end{proof}

\begin{thm}[Tietze's Extension
  Theorem]\label{TietzeExtensionTheorem}Let $F$ be a closed subset of
  a normal topological space, let $a < b$ be real numbers and let $f :
  F \to [a,b]$ be a continuous function.  There exists a continuous
  function $g : X \to [a,b]$ such that $g\mid_F = f$.  If $f : F \to
  \reals$ is a continuous function then there exists a continuous
  function $g: X \to \reals$ such that $g \mid_F = f$.
\end{thm}
\begin{proof}
We begin with the case of $f$ with bounded range.  We construct $g$
via an iterative procedure.  
TODO:
\end{proof}

\begin{defn}Given a topological space $(X, \mathcal{T})$ the Baire
  $\sigma$-algebra is smallest $\sigma$-algebra for which all bounded
  continuous functions are measurable.  Equivalently 
\begin{align*}
Ba(X,\mathcal{T}) &= \sigma(\lbrace f^{-1}(U) \mid U \subset \reals
\text{ is open; } f \in C_b(X,\reals)\rbrace)
\end{align*}
\end{defn}
\begin{lem}For every topological space $(X, \mathcal{T})$, $Ba(X)
  \subset \mathcal{B}(X)$.  For a metric space $(S,d)$, $Ba(S) = \mathcal{B}(S)$.
\end{lem}
\begin{proof}
To see the inclusion $Ba(X)
  \subset \mathcal{B}(X)$, note that by continuity of $f \in
  C_b(X;\reals)$, every set $f^{-1}(U)$ is open.

Now suppose $(S,d)$ is a metric space.  To show $\mathcal{B}(S)
\subset Ba(S)$, it suffices if we show every closed set $F \subset S$
can be written as $f^{-1}(G)$ where $G \subset \reals$ is closed and
$f \in C_b(S; \reals)$.  By the triangle inequality (see e.g. Lemma
\ref{DistanceToSetLipschitz}) we know
that $g(x) = d(x, F)$ is continuous (in fact Lipschitz) and by Lemma
\ref{MaxMinOfLipschitz} we know that $f(x) = d(x, F) \wedge 1$ is also
Lipschitz and therefore $f(x) \in C_b(S; \reals)$.  Because $F$ is
closed we also know that $F = f^{-1}(\lbrace 0 \rbrace)$ and we are done.
\end{proof}


\begin{lem}\label{SeparabilityOfBoundedUniformlyContinuous}Let $(S,d)$ be a separable metric space, then $X$ is
  homeomorphic to a subset of $[0,1]^{\integers_+}$ and furthermore
\begin{itemize}
\item[(i)]$S$ has a metric making it totally bounded
\item[(ii)]If $S$ is compact then $C(S; \reals)$ with the uniform
  topology is separable.
\item[(iii)]If $\hat{d}$ is a totally bounded metric on $S$ then
  $U_b(S)$ is separable
\end{itemize}
\end{lem}
\begin{proof}
Let $\rho$ be the product metric $\rho(x,y) = \sum_{n=1}^\infty
\frac{\abs{x_n-y_n}}{2^n}$ on the space $[0,1]^{\integers_+}$. 
 Pick a countable dense subset $x_1, x_2, \dotsc$ of $S$ and define 
$f : S \in [0,1]^{\integers_+}$ by 
\begin{align*}
f(x) &= \left ( \frac{d(x_1, x)}{1 + d(x_1, x)}, \frac{d(x_2, x)}{1 +
    d(x_2, x)}, \dotsc \right )
\end{align*}
 
Claim 1: $f(x)$ is continuous.

By definition of the product topology $f(x)$ is continuous if and only
if each coordinate is.  For any given fixed $x_j$, we know that
$d(x_j, x)$ is continuous (in fact Lipschitz by Lemma
\ref{DistanceToSetLipschitz}) and thus the result follows from the
continuity of $x/(1+x)$ on $\reals_+$.

Claim 2: $f(x)$ is injective.

For any $z \neq y$ we find $\epsilon > 0$ such that $B(z ; \epsilon)
\cap B( y ; \epsilon) = \emptyset$ and then using density of $x_1,
x_2, \dotsc$ to pick an $x_n$ such that $d(z,x_n) < \epsilon$ and
$d(y, x_n) \geq \epsilon$ showing $f(z) \neq f(y)$.  

Claim 3: The inverse of $f(x)$ is continuous.

Fix an $x \in S$ and let $\epsilon >0$ be given.  Pick $x_n$ such that
$d(x_n, x) < \epsilon/2$.  If we let $g(x) : [0,1) \to \reals_+$ be
defined by $g(x) = x/(1-x)$ then $g(x)$ is the inverse of $x/(1+x)$ 
and by continuity of $g(x)$ at the point $\frac{d(x_n, x)}{1+d(x_n,x)}$ we know that there exists a $\delta > 0$
such that $\abs{\frac{d(x_n, x)}{1+d(x_n,x)} - 
\frac{d(x_n,  y)}{1+d(x_n,y)}}< \delta$ implies $\abs{d(x_n,x) - d(x_n,y)} <
  \epsilon/2$.
Then if $f(y) \in B(f(x), \frac{\delta}{2^n})$ we have
\begin{align*}
\abs{\frac{d(x_n, x)}{1+d(x_n,x)} - 
\frac{d(x_n,  y)}{1+d(x_n,y)}} &\leq 2^n \rho(f(x), f(y)) < \delta
\end{align*}
$d(x,y) \leq d(x_n,x) + \abs{d(x_n,x) - d(x_n,y)} < \epsilon$.

Now to see (i) we simply pull back the metric $\rho$ via the embedding
$f(x)$ and use the facts that $\rho$ generates the product topology,
$[0,1]^{\integers_+}$ is compact in product topology
(by Tychonoff's Theorem \ref{Tychonoff}; alternatively one can avoid
the use of Tychonoff's Theorem for it is easy to
see with a diagonal subsequence argument that a countable product of
sequentially compact metric spaces is sequentially compact) hence totally bounded (Theorem
\ref{CompactnessInMetricSpaces}).

Here is the argument that $\rho$ generates the product topology; TODO:
put this in a separate lemma.  To see that the topology generated by
$\rho$ is finer than the product topology, suppose $U$ is open in the
topology generated by $\rho$.  Pick $x \in U$ and select $N > 0$ such
that $B(x,\epsilon) \subset U$.  Then pick $N > 0$ such that $2^{-N-1} <
\epsilon$ and consider $B=B(x_1, \epsilon/2)
\times \dotsb \times B(x_{2^N}, \epsilon/2) \times S \times \dotsb$
which is open in the product topology.  If $y \in B$ then 
\begin{align*}
\rho(x,y) &=
\sum_{n=1}^\infty \frac{\abs{x_n-y_n}}{2^n} = \sum_{n=1}^{2^N}
\frac{\abs{x_n-y_n}}{2^n} + \sum_{n=2^N+1}^\infty \frac{\abs{x_n-y_n}}{2^n} \leq
\frac{\epsilon}{2} \sum_{n=1}^{2^N} \frac{1}{2^n} +
\sum_{n=2^N+1}^\infty \frac{1}{2^n} < \epsilon
\end{align*}
To see that the product topology is finer than the metric topology,
suppose $n >0$ is an integer, $U\subset[0,1]$ is open and consider $\pi_n^{-1}(U)$.  Let $x
\in \pi_n^{-1}(U)$ and find an $\epsilon > 0$ such that $B(x_n,
\epsilon) \subset U$.  Note that if $y \in B(x, \frac{\epsilon}{2^n})$
then $\abs{x_n - y_n} < 2^n \rho(x,y) \leq \epsilon$ and therefore
$B(x, \frac{\epsilon}{2^n}) \subset \pi_n^{-1}(B(x_n, \epsilon))
\subset U$.

To see (ii), if $S$ is compact then $f(S) \subset [0,1]^{\integers_+}$
is compact (Lemma \ref{ContinuousImageOfCompact}).  Observe that 
\begin{align*}
A &= \lbrace \Pi_{i=1}^np_i(x_i) \mid n \in \naturals \text{ and } p_i
\in \rationals[x] \rbrace
\end{align*}
is a subalgebra of $C([0,1]^{\integers_+} ; \reals)$ and $A$ separates points (
given $x \neq y \in [0,1]$, pick
$n$ such that $x_n \neq y_n$ and pick the function $g(x) = x_n$).  By
the Stone-Weierstrass Theorem \ref{StoneWeierstrassApproximation} we know that $A$ is dense in $C([0,1]^{\integers_+};
\reals)$; now pullback $A$ under $f(x)$ to a countable dense subset of
$C(S;\reals)$. 

To see (iii), suppose $\hat{\rho}$ is a totally bounded metric on
$S$.  Let $\hat{S}$ be the completion of $S$ with respect to
this metric.  

Claim 4: $\hat{\rho}$ extends to a totally bounded
metric on $\hat{S}$.  

Let $\epsilon>0$ be given and cover $S$ by ball
$B(x_i, \epsilon/2)$; we show that $B(x_i, \epsilon)$ covers
$\hat{S}$.  Biven $y \in \hat{S}$ we can find $x \in
S$ such that $\hat{\rho}(x,y) < \epsilon/2$.  Since $x \in S$ there
exists an $x_i$ such that $x \in B(x_i, \epsilon/2)$ and therefore
$\hat{\rho}(x_i,y) \leq \hat{\rho}(x,x_i) + \hat{\rho}(x_i,y) <
\epsilon$.

Because $(\hat{S},\hat{\rho})$ is complete and totally bounded we know
it is compact (Theorem \ref{CompactnessInMetricSpaces}) and we have
just shown that $C(\hat{S} ; \reals)$ has a countable dense subset.

Claim 5: $f\vert_S : C(\hat{S} ; \reals) \to U_b^{\hat{\rho}}(S ;
\reals)$ is a well defined, continuous and surjective.

Being well defined in this context means that restriction to $S$
results in a bounded uniformly continuous function.  This follows
from the fact that any continuous function of a compact set is bounded
and uniformly continuous (Theorem \ref{ContinuousImageOfCompact} and
Theorem \ref{UniformContinuityOnCompactSets} respectively) and these
properties are preserved upon restriction.  To see surjectivity, let
$g : S \to \reals$ be bounded and uniformly continuous.  TODO: Make
this a separate Lemma.  Let $x \in \hat{S}$, pick a sequence $x_n$
in $S$ such that $\lim_{n \to \infty} x_n = x$ and observe that by
uniform continuity of $f(x)$, for
any $\epsilon > 0$ there exists a $\delta > 0$ such that $\hat{d}(x,y)
< \delta$ implies $\abs{f(x) - f(y)} < \epsilon$.  If we pick $N > 0$
such that $\hat{d}(x_n,y) < \delta/2$ for $n \geq N$ then
$\hat{d}(x_n, x_m) < \delta$ for all $n,m \geq N$ and thus $\hat{d}(f(x_n), f(x_m)) < \epsilon$ for all
$n,m \geq N$.  This shows that the sequence $f(x_n)$ is Cauchy and by
completeness of $\reals$ we can take the limit; we define $f(x) =
\lim_{n\to infty} f(x_n)$.  We claim that this definition is
independent of the sequence chosen.  Indeed, let $y_n$ be another
sequence from $S$ such that $\lim_{n \to \infty} y_n = x$.  Pick an
$\epsilon > 0$ and by uniform continuity of $f(x)$ let $\delta$ be
chosen such that $\abs{f(x)-f(y)} < \epsilon/2$ whenever $\hat{d}(x,y) < \delta$.
There exists $N_1 > 0$ such that $\rho(y_n, x_n) < \delta$ for every
$n > N_1$ and there exists $N_2 > 0$ such that $\abs{f(x_n) - f(x)} <
\epsilon/2$ for all $n \geq N_2$.  Then we have for all $n \geq N_1 \vee
N_2$ by the triangle inequality $\abs{f(y_n) - f(x)} < \epsilon$.
Note that this also shows that the extension $f(x)$ to $\hat{S}$ is
continuous at $x \in \hat{S}$; since is was continuous at all points
of $S$ we know the extension is continuous.  

Now the continuous image of a dense set under a surjective map is also
dense.  This is easily seen by picking a point $f(x)$ in the image;
picking a sequence $x_n$ such that $x_n \to x$ and then considering
the image $f(x_n) \to f(x)$.  Thus the result is proven.
\end{proof}

\begin{lem}[Dini's Theorem]\label{DinisTheorem}Let $K$ be a compact
  topological space and let $f_n: K \to \reals$ be a sequence  of continuous
  functions such that $f_n \downarrow 0$ pointwise on $K$, then $f_n
  \to 0$ uniformly.
\end{lem}
\begin{proof}
Given $\epsilon > 0$ define $U_n = f_n^{-1}((-\infty,\epsilon))$.
Then each
$U_n$ is open, $U_1 \subset U_2 \subset \dotsb$ (since the $f_n$ are
decreasing) and the $U_n$ form an open cover of $K$.  We can extract a
finite subcover which since the $U_n$ are nested implies that $K =
U_N$ for some $N > 0$.  This is exactly the statement that $\sup_{x
  \in K} \abs{f_n(x)} < \epsilon$ for all $n \geq N$ hence the result proven.
\end{proof}

\begin{lem}\label{StoneDaniellProbability}Let $(S,d)$ be a separable metric space and let $\Lambda :
  U_b^d(S; \reals) \to \reals$ be a linear map such that 
\begin{itemize}
\item[(i)] $\Lambda$ is non-negative (i.e. if
  $f \geq 0$ then $\Lambda(f) \geq 0$) 
\item[(ii)] $\Lambda(1) = 1$
\item[(iii)] for all $\epsilon > 0$ there exists a compact set $K
  \subset S$ such that for all $f \in U_b^d(S; \reals)$,
\begin{align*}
\abs{\Lambda(f)} &\leq \sup_{x \in K} \abs{f(x)} + \epsilon \norm{f}_u
\end{align*}
\end{itemize}
then there exists a Borel probability measure $\mu$ on $S$ such that
$\Lambda(f) = \int f \, d\mu$.  Whenever such a probability measure
exists it is unique.
\end{lem}
\begin{proof}
We construct $\mu$ by use of the Daniell-Stone Theorem
\ref{DaniellStoneTheorem}.  It is clear that $U_b^d(S; \reals)$ is
closed under max and min and contains the constant functions so
$U_b^d(S; \reals)$ is a Stone Lattice.  It remains to show that
$\Lambda$ obeys the ``montone convergence'' property: if $f_n
\downarrow 0$ pointwise then $\Lambda(f_n) \downarrow 0$.  This
property is a corollary of Dini's Theorem \ref{DinisTheorem} since by that result,
if $f_n$ are continuous and $f_n \downarrow 0$ pointwise on a compact
set then the converge uniformly to $0$ on the compact set.  In
particular, pick an $\epsilon > 0$ and let $K \subset S$ be compact
as in the hypothesis.  By Dini's Theorem there exists $N > 0$ such
that $\sup_{x \in K} f_n(x) < \epsilon$ for all $n \geq N$.  Therefore
for all $N > 0$,
\begin{align*}
\abs{\Lambda(f_n)} &\leq \sup_{x \in K} \abs{f_n(x)} + \epsilon
\norm{f_n}_\infty \\
&\leq \epsilon(1 + \norm{f_1}_\infty)
\end{align*}
thus $\lim_{n \to \infty} \Lambda(f_n) = 0$ and we can apply Theorem \ref{DaniellStoneTheorem}. 

Uniqueness follows because a probability measure is determined by its
integrals over $U_b^d(S;\reals)$ (in fact over the subset of bounded
Lipschitz functions).  This follows because for any closed $F \subset
S$ we can define $f_n(x) = n d(x, F) \wedge 1$ so that $f_n
\downarrow \characteristic{F}$ and apply Montone Convergence (see the
proof of the Portmanteau Theorem \ref{PortmanteauTheorem} for complete
details on this argument).
\end{proof}

\begin{thm}[Prohorov's Theorem]\label{Prohorov}Let $(S,d)$ be a
  separable metric space, then a tight set of probability measures on
  $S$ is weakly relatively compact.  If $S$ is also complete then a
  weakly relatively compact set is tight.
\end{thm}
\begin{proof}
By the Portmanteau Theorem \ref{PortmanteauTheorem} we know that a
set of measures is tight if and only if its weak closure is tight
(compact sets are closed hence can only gain mass in a weak limit).  Thus it suffices to assume
that we have a closed tight set $M$ of measures.  Put a totally
bounded metric $\hat{d}$ on $S$ so that $U_b^{\hat{d}}(S;\reals)$ is separable
(Lemma \ref{SeparabilityOfBoundedUniformlyContinuous}); let $f_1, f_2,
\dotsc$ be a countable uniformly dense subset.  

Pick a sequence $\mu_n$ from $M$; we must show that it has a weakly
convergent subsequence.  For every fixed $f_m$
we know that $\abs{\int f_m \, d\mu_n} \leq \norm{f_m}_u < \infty$ so
there is a subsequence $N \subset \naturals$ such that $\int f_m \,
d\mu_n$ converges along $N$.  Since is true for every $m>0$ by a
diagonalization argument we know there is a subsequence $\hat{\mu}_{k}$ such that
$\lim_{k \to \infty} \int f_m \, d\hat{\mu}_{k}$ exists for every
$m>0$.  Define $\Lambda(f_m) =   \lim_{k \to \infty} \int f_m \,
d\hat{\mu}_{k}$ for every such $f_m$.  Our next goal is to extend
$\Lambda$ to all of $U_b^\rho(S;\reals)$.  Since $\Lambda$ is
uniformly continuous on a dense subset we know that a continuous
extension is defined; however we need a little bit more information.

Claim 1: $\lim_{k \to \infty} \int f \, d\hat{\mu}_{k}$ exists for every
$f \in U_b^\rho(S;\reals)$; moreover $\lim_{k \to \infty} \int f_m \,
d\hat{\mu}_{k} = lim_{m \to \infty} \Lambda(\hat{f}_m)$ where
$\hat{f}_m$ is any subsequence of $f_m$ that converges uniformly to $f$.

Pick a subsequence of the $f_m$ that converges to $f$.  Let that
subsequence be donoted $\hat{f}_m$ so that $\lim_{m \to \infty} \norm{\hat{f}_m -
  f}_\infty = 0$.  For every $m > 0$ we have
\begin{align*}
\int \hat{f}_m \, d \hat{\mu}_k -\norm{\hat{f}_m - f}_\infty &\leq 
\int f \, d\hat{\mu}_k \leq \int \hat{f}_m \, d \hat{\mu}_k + \norm{\hat{f}_m - f}_\infty
\end{align*}
and therefore taking limits in $k$ and using the definition of
$\Lambda$ at the points $f_m$,
\begin{align*}
\Lambda(\hat{f}_m) -\norm{\hat{f}_m - f}_\infty 
&\leq \liminf_{k \to \infty} \int f \, d\hat{\mu}_k 
\leq \limsup_{k \to \infty} \int f \, d\hat{\mu}_k 
\leq \Lambda(\hat{f}_m) + \norm{\hat{f}_m - f}_\infty
\end{align*}
Now letting $m$ go to infinity we get $\lim_{m \to \infty}
\Lambda(\hat{f}_m) = \lim_{k \to \infty} \int f \, d\hat{\mu}_k$.

As a result of the claim, we now define $\Lambda(f) = \lim_{k \to
  \infty} \int f \, d\hat{\mu}_{k}$ for every $f$  and it is clearly
linear (by linearity of integral and limits), nonnegative (by
monotonicity of integral) and satisfies $\Lambda(1) = 1$ (by direct
computation).  

To show that $\Lambda$ defines a probability measure, we bring the
tightness hypothesis to the table.  Pick $\epsilon > 0$ and by
tightness take a compact set $K \subset S$ such that $\sup_{\mu \in M}
\mu(K) > 1 - \epsilon$.  For any $f \in U_b^{\hat{d}}(S ; \reals)$ we
have
\begin{align*}
\abs{\Lambda(f)} 
&= \lim_{k \to \infty} \abs{\int f \, d\hat{\mu}_k}
= \lim_{k \to \infty} \abs{\int f \characteristic{K} \, d\hat{\mu}_k +
\int f \characteristic{S \setminus K} \, d\hat{\mu}_k} \leq \sup_{x
\in K} \abs{f(x)} + \epsilon \norm{f}_\infty
\end{align*}
so we may apply Lemma \ref{StoneDaniellProbability} to conclude there
exists a probability measure $\mu$ such that for all $f \in U_b^{\hat{d}}(S ; \reals)$ we
have $\Lambda(f) =  \lim_{k \to \infty} \abs{\int f \, d\hat{\mu}_k} =
\int f \, d\mu$.  Since $U_b^{\hat{d}}(S ; \reals)$ contains all
bounded Lipschitz functions by the Portmanteau Theorem
\ref{PortmanteauTheorem} we conclude $\mu_n$ converges weakly to
$\mu$.

Now assume that $S$ is complete and separable and let $M$ be a weakly
relatively compact set of measures.  Let $x_1, x_2, \dotsc$ be a countable dense
subset of $S$.  For every integer $n > 0$ we have $S =
\cup_{k=1}^\infty B(x_k, 1/n)$.  Thus $\cap_{N=1}^\infty \cap_{k=1}^N
B(x_k, 1/n)^c = \emptyset$ so by continuity of measure (Lemma
\ref{ContinuityOfMeasure}) for any fixed probability measure $\mu$ we
can find an $N_{n, \mu} > 0$ such that $\mu(\cap_{k=1}^{N_{n, \mu}}
B(x_k, 1/n)^c ) < \epsilon/2^n$.  We claim that, because $M$ is
compact, we can find an $N_n$ for
which this is true uniformly over the measures in $M$.

Claim 2: For every $n > 0$ there exists $N_n > 0$ such that $\mu(\cap_{k=1}^{N_{n}}
B(x_k, 1/n)^c ) < \epsilon/2^n$ for all $\mu \in M$.
 
We argue by contraction by reducing the case where $M$ is a singleton
set (where we have already shown the claim holds).  If Claim 2 is not
true then there exists $n$ such that for every integer $N>0$ we have
some $\mu_N \in M$ such that $\mu_N(\cap_{k=1}^{N} B(x_k, 1/n)^c )
\geq \epsilon/2^n$.  By sequential compactness of $M$ we know that
there is a weakly convergent subsequence $\mu_{N_j}$ such that
$\mu_{N_j} \toweak \mu$ for some probability measure $\mu$.  For every
$N > 0$ we have $\cap_{k=1}^{N} B(x_k, 1/n)^c$ is closed and therefore
by the Portmanteau Theorem \ref {PortmanteauTheorem}
\begin{align*}
\epsilon/2^n &\leq \limsup_{j \to \infty} \mu_{N_j}(\cap_{k=1}^{N_j}
B(x_k, 1/n)^c) \\
&\leq \limsup_{j \to \infty} \mu_{N_j}(\cap_{k=1}^{N} B(x_k, 1/n)^c)
\\
&\leq \mu(\cap_{k=1}^{N} B(x_k, 1/n)^c)
\end{align*}
where in the second inequality we have used the fact that the limit
only depends on the tail of the sequence of sets $\cap_{k=1}^{N_j}
B(x_k, 1/n)^c$ and by a union bound for sufficiently large $N_j$ we
have $\mu_{N_j}(\cap_{k=1}^{N_j} B(x_k, 1/n)^c)  \leq
\mu_{N_j}(\cap_{k=1}^{N} B(x_k, 1/n)^c)$.  To finish we get a
contradiction by taking the 
limit and using continuity of measure
\begin{align*}
0 < \epsilon/2^n \leq \lim_{N \to \infty} \mu(\cap_{k=1}^{N} B(x_k,
1/n)^c) = 0
\end{align*}

With Claim 2 proven we mimic the proof of Ulam's Theorem.  Let 
\begin{align*}
K &=
\cap_{m=1}^\infty \cup_{j=1}^{N_m} \overline{B}(x_j,\frac{1}{m})
\end{align*}
which is easily seen to be closed (hence complete) and by construction
is totally bounded thus is compact (Theorem
\ref{CompactnessInMetricSpaces})
and furthermore for all $\mu \in M$,
\begin{align*}
\mu(K^c) &\leq \mu((\cap_{m=1}^\infty
\cup_{j=1}^{N_m} B(x_j,\frac{1}{m}))^c) \\
&=\mu(\cup_{m=1}^\infty 
\cap_{j=1}^{N_m} B(x_j,\frac{1}{m})^c) \\
&=\sum_{m=1}^\infty \mu(
\cap_{j=1}^{N_m} B(x_j,\frac{1}{m})^c) \\
&\leq \sum_{m=1}^\infty \frac{\epsilon}{2^m} = \epsilon
\end{align*}

\end{proof}

\begin{lem}For $f,g \in C([0,\infty) ; \reals)$ define
\begin{align*}
\rho(f,g) &= \sum_{n=1}^\infty \frac{1}{2^n} \sup_{0 \leq t \leq n}
(\abs{f(t) - g(t)} \wedge 1)
\end{align*}
then $\rho$ is a metric on $C([0,\infty) ; \reals)$ and $C([0,\infty);
\reals)$ is complete and separable with respect to this metric.
\end{lem}
\begin{proof}
It is clear that $\rho(f,f) = 0$ and furthermore if $\rho(f,g) = 0$
then $f = g$ on every interval $[0,n]$ and therefore $f = g$.
Symmetry and the triangle inequality of $\rho$ is immediate from the
corresponding properties of the absolute value (TODO: OK the triangle
inequality may need a bit more of an argument).

We claim that the set of polynomials with rational coefficients is
dense in $C([0,\infty); \reals)$.  Pick $f \in C([0,\infty); \reals)$
and let $\epsilon > 0$ be given.  Now take $m > 0$ sufficiently large
so that $1/2^m < \epsilon / 2$ and by the Stone Weierstrass Theorem \ref{StoneWeierstrassApproximation} we
pick a polynomial with rational coefficients $p$ such that $\sup_{0
  \leq t \leq m} \abs{f(t) - p(t)} < \epsilon/2$ then we have
\begin{align*}
\rho(f,p) &\leq \sum_{n=1}^m\frac{1}{2^n} \sup_{0 \leq t \leq n}
\abs{f(t) - p(t)} + \sum_{n=m+1}^\infty \frac{1}{2^n} \\
&\leq \sup_{0 \leq t \leq m}
\abs{f(t) - p(t)} \sum_{n=1}^m\frac{1}{2^n} + \epsilon/2 <\epsilon
\end{align*}

Completeness follows from arguing over intervals $[0,n]$.  Suppose
$f_n$ is a Cauchy sequence in $C([0,\infty); \reals)$.  Given
$\epsilon > 0$ and $n > 0$ we can find $N > 0$ such that $\rho(f_m,
f_N) < \epsilon/2^n$ for all $m \geq N$.  Thus $\sup_{0 \leq t \leq n}
\abs{f_m(t) - f_N(t)} < \epsilon$ for all $m \geq N$ so we see that
$f_n$ is uniformly  Cauchy on every interval $[0,n]$.  By completeness
of $C([0,n];\reals)$ we know that the pointwise limit of $f_n$ exists
on every $[0,n]$ and is a continuous function.  Therefore we have a
limit $f$ defined on $[0,\infty)$ and since continuity is a local
property $f \in C([0,\infty); \reals)$.  It remains to show that $f_n$
converges to $f$ in the metric $\rho$.  This follows arguing as we
have above.  Let $\epsilon > 0$ be given and choose $n > 0$ such that
$\frac{1}{2^n} < \epsilon/2$ and choose $N > 0$ such that $\sup_{0 \leq t \leq n}
\abs{f_m(t) - f_N(t)} < \epsilon/2$ and then observe
\begin{align*}
\rho(f_m, f_N) &\leq \sum_{k=1}^n \frac{1}{2^k} \sup_{0 \leq t \leq k}
\abs{f_m(t) - f_N(t)} + \sum_{k=n+1}^\infty \frac{1}{2^k}  < \epsilon
\end{align*}
\end{proof}

The topology defined by $\rho$ is often refered to as the topology of
uniform convergence on compact sets by virtue of the following lemma.
\begin{lem}\label{UniformConvergenceOnCompacts}A sequence $f_n$
  converges to $f$ in $C^\infty([0,\infty), \reals)$ if and only if
  $f_n$ converges to $f$ uniformly on every interval $[0,T]$ for $T > 0$.
\end{lem}
\begin{proof}
TODO:  This is elementary.
\end{proof}

\begin{defn}Given a function $f : [0,T] \to \reals$ the \emph{modulus
    of continuity} is the function
\begin{align*}
m(T, f, \delta) &= \sup_{\substack{\abs{s - t} < \delta \\
0 \leq s,t \leq T}} \abs{f(s) - f(t)}
\end{align*}
\end{defn}

\begin{lem}For fixed $T > 0$ and $\delta > 0$, $m(T, f, \delta)$ is a
  continuous function on $C([0,\infty); \reals)$.  For fixed $T > 0$
  and function $f : \reals \to \reals$, $m(T,f,\delta)$ is
  nonincreasing in $\delta$ and 
\begin{align*}
\lim_{\delta \to 0} m(T, f, \delta) = 0
\end{align*}
provided $f \in C([0,\infty); \reals)$.
\end{lem}
\begin{proof}
To see continuity on $C([0,\infty); \reals)$ let $f \in C([0,\infty);
\reals)$, $T > 0$, $\delta > 0$ and $\epsilon > 0$ be given and pick $g$ that $\rho(f,g) <
\epsilon/2^{\ceil{T}+1}$.
From the definition of the metric $\rho$ for any $n > 0$, $\sup_{0 \leq t \leq n} \abs{f(t) - g(t)} \wedge
1 \leq 2^n \epsilon$, so for any $T > 0$, 
\begin{align*}
\sup_{0 \leq t \leq T} \abs{f(t) - g(t)} \wedge
1 &\leq \sup_{0 \leq t \leq \ceil{T}} \abs{f(t) - g(t)} \wedge
1 \leq \epsilon/2
\end{align*}  
Therefore by the triangle inequality,
\begin{align*}
\sup_{\substack{
\abs{s -t} < \delta \\
0 \leq s,t \leq T}} \abs{g(s) - g(t)} \wedge 1 
&\leq 
\sup_{\substack{
\abs{s -t} < \delta \\
0 \leq s,t \leq T}} \left ( \abs{g(s) - f(s)} + \abs{f(s) - f(t)} + \abs{f(t)
- g(t)} \right ) \wedge 1 \\
&\leq \epsilon/2 + 
\sup_{\substack{
\abs{s -t} < \delta \\
0 \leq s,t \leq T}} \abs{f(s) - f(t)} \wedge 1 + \epsilon/2
\end{align*}
and therefore arguing with the roles of $f$ and $g$ reversed shows 
$\abs{m(T, f, \delta) - m(T, g, \delta) } \leq \epsilon$.

The fact that $m(T, f, \delta)$ is decreasing in $\delta$ is clear
because the definition shows that for $\delta_1 \leq \delta_2$ we
have 
\begin{align*}
\lbrace \abs{f(t) - f(s) } \mid 0 \leq s,t \leq T \text{ and }
  \abs{s-t} < \delta_1 \rbrace 
&\subset 
\lbrace \abs{f(t) - f(s) } \mid 0 \leq s,t \leq T \text{ and }
  \abs{s-t} < \delta_2 \rbrace
\end{align*} and therefore $m(T, f, \delta_2) \leq
  m(T, f, \delta_1)$.

Lastly if we suppose $f \in C([0,\infty); \reals)$ then $f$ is
uniformly continuous on $[0,T]$ for every $T > 0$ (Theorem
\ref{UniformContinuityOnCompactSets}).  Thus given an $\epsilon > 0$
there exists $\delta>0$ such that 
\begin{align*}
\sup_{\substack{
\abs{s -t} < \delta \\
0 \leq s,t \leq T}} \abs{f(s) - f(t)} < \epsilon
\end{align*}
which shows $\lim_{\delta \to 0} m(T, f, \delta) = 0$.
\end{proof}
The following Theorem is a version of the Arzela-Ascoli Theorem of
real analysis.
\begin{thm}[Arzela-Ascoli Theorem]\label{ArzelaAscoliTheorem}A set $A
  \subset C([0,\infty); \reals)$ is relatively compact if and only if 
\begin{itemize}
\item[(i)]$\sup_{f \in A} \abs{f(0)} < \infty$
\item[(ii)]$\lim_{\delta \to 0} \sup_{f \in A} m(T, f, \delta) = 0$
  for all $T > 0$.
\end{itemize}
\end{thm}
\begin{proof}
To see the necessity of condition (i), observe that $\overline{A}$ is
compact and by completeness of $C([0,\infty); \reals)$ we know that
$\overline{A}$ comprises continuous functions.  Therefore we know that
$A \subset \overline{A} \subset \cup_{n=1}^\infty \lbrace f \in
C([0,\infty) \mid
\abs{f(0)} < n\rbrace$.  Since each $\lbrace f \in
C([0,\infty) \mid
\abs{f(0)} < n\rbrace$ is easily seen to be an open set, by
compactness of $\overline{A}$ we have a finite subcover which implies
there exists an $N$ such that $A \subset \overline{A} \subset \lbrace f \in
C([0,\infty) \mid
\abs{f(0)} < N\rbrace$.

To see the necessity of condition (ii), fix $\epsilon > 0$, $T > 0$
and define for each $\delta > 0$ the set 
\begin{align*}
F_\delta &= \lbrace f \in \overline{A} \mid m(T, f, \delta) \geq
\epsilon \rbrace
\end{align*}
By continuity of $m(T, f, \delta)$ we know that $F_\delta$ is closed.
Since $F_\delta \subset \overline{A}$ with $\overline{A}$ compact we
conclude that $F_\delta$ is compact.  Furthermore since for fixed $f
\in \overline{A}$ continuity (more specifically uniform continuity on compact
sets) implies $\lim_{\delta \to 0} m(T,f,\delta) = 0$, we know that
$\cap_{\delta > 0} F_\delta = \emptyset$.  By nestedness and
compactness of the
$F_\delta$ we know that there is some specific $\delta>0$ for which $F_\delta =
\emptyset$ (Lemma \ref{IntersectionOfNestedCompactSets}) and (ii) is established.

To see the sufficiency of conditions (i) and (ii), we first construct
the limiting subsequence on a the set of rationals $\rationals_+
\subset [0,\infty)$.  To do this, we first claim that for any $T \in
\rationals_+$, (in fact any $T \in [0,\infty)$, the set $\lbrace
\abs{f(x)} \mid f \in A \rbrace$ is bounded.  The claim follows for
$T>0$ by using (ii) to select a $\delta > 0$ such that $\sup_{f \in A} m(T, f,
\delta) < 1$.  Picking the integer $m \geq 0$ such that $m \delta < T \leq
(m+1)\delta$ and considering  the grid $0, \delta, 2\delta, \dotsc,
m\delta, T$ we can write the telescoping sum
\begin{align*}
f(T) - f(0) = f(T) - f(m\delta) + \sum_{k=1}^m f(k \delta) - f((k-1)\delta)
\end{align*}
and use the triangle inequality to conclude that $\abs{f(T)}
\leq \abs{f(0)} + m+1$ for every $f \in A$.  Coupled with (i) this shows that
$\sup_{f \in A} \abs{f(T)} < \infty$.

We now enumerate the rationals $\rationals_+$ and use
compactness in $\reals$ and a diagonal
subsequence argument to pick a sequence $f_n$ with $f \in A$ such that
$f_n(T)$ converges for every $T \in \rationals_+$.  Define $f :
\rationals_+ \to \reals$ by $f(T) = \lim_{n \to \infty} f_n(T)$.

Having selected a convergent subsequence $f_n$ and defined $f$ on
$\rationals_+$ we proceed to see that $f$ is uniformly continuous.
This follows by using (ii) to see that for every $f_n$, $T > 0$ and 
$\epsilon > 0$ there is $\delta > 0$ such that $\abs{f_n(s) - f_n(t)} <
\epsilon$ when $0 \leq s,t \leq T$ and $\abs{s - t} <\delta$.  From
this we have for every $n>0$, and $s,t \in \rationals$, $0 \leq s,t
\leq T$ and $\abs{s-t} < \delta$
\begin{align*}
\abs{f(s) -f(t)} &\leq \abs{f(s) -f_n(s)} + \abs{f_n(s) -f_n(t)} +
\abs{f_n(t) - f(t)} \\
&\leq \abs{f(s) -f_n(s)} + \epsilon +
\abs{f_n(t) - f(t)}
\end{align*}
Taking the limit as $n \to \infty$ using pointwise convergence of
$f_n$ to $f$ shows uniform continuity on every
$[0,T] \cap \rationals$ hence on $\rationals_+$.  Since $f$ is uniformly continuous on
$\rationals_+$ it follows that $f$ has a continuous extension to $f :
[0,\infty) \to \reals$.  Moreover we have shown that $\abs{f(s) -f(t)}
< \epsilon$ when $\abs{s -t} < \delta$.

It remains to prove that $f_n \to f$ in $C([0,\infty); \reals)$.  It
suffices (Lemma \ref{UniformConvergenceOnCompacts}) to show that $f_n
\to f$ uniformly on every interval $[0,T]$.  Let $T > 0$ be given.
Pick $\epsilon > 0$ and let
$\delta > 0$ be such that $m(T,f_n,\delta) < \epsilon$ (hence $m(T,f,\delta)
< \epsilon$ by the above comment).   Pick $N > 0$ such that
$\abs{f_n(k\delta) - f(k\delta)} < \epsilon/3$ for all $k=0,1, \dotsc,
\ceil{T/\delta}$ and $n \geq N$.  Then for every $0 \leq t \leq T$ and
$n \geq N$ let $k\geq 0$ be such that $k\delta \leq t < (k+1)\delta$
\begin{align*}
\abs{f_n(t) - f(t)} &\leq \abs{f_n(t) - f_n(k\delta)}
+\abs{f_n(k\delta) - f(k\delta)} +\abs{f(k\delta) - f(t)} < \epsilon
\end{align*}
and we are done.
\end{proof}

Provided with a characterization of compact sets in
$C^\infty([0,\infty); \reals)$ we can now state the probabilistic
analogue.
\begin{lem}\label{TightnessOfContinuousFunctions}A sequence of Borel probability measures $\mu_n$ on $C^\infty([0,\infty);
  \reals)$ is tight if and only if 
\begin{itemize}
\item[(i)]$\lim_{\lambda \to \infty} \sup_{n \geq 1} \sprobability{\abs{f(0)}
  \geq \lambda}{\mu_n} = 0$.
\item[(ii)] $\lim_{\delta \to 0} \sup_{n \geq 1} \sprobability{m(T, f,
  \delta) \geq \lambda}{\mu_n} = 0$ for all $\lambda > 0$ and $T > 0$.
\end{itemize}
\end{lem}
\begin{proof}
Let $\mu_n$ be a tight sequence.  Let $\epsilon > 0$ be given and pick
$K \subset C^\infty([0,\infty); \reals)$ compact with $\mu_n(K) >
1-\epsilon$ for all $n$.  Then by Theorem \ref{ArzelaAscoliTheorem} we know that $\sup_{f \in K}
\abs{f(0)} < \infty$ and therefore $\sprobability{\abs{f(0)}\geq
\lambda}{\mu_n} \leq \mu_n(K^c) < \epsilon$ for any $\lambda > \sup_{f
\in K} \abs{f(0)}$.  Thus (i) is shown.  Similarly applying Theorem \ref{ArzelaAscoliTheorem} we know that for
every $T > 0$ and $\lambda>0$
there exists $\delta>0$ such that $\sup_{f \in K} m(T, f, \delta) <
\lambda$.  Therefore $\lbrace f \mid m(T,f,\delta) \geq \lambda \rbrace
\subset K^c$ and by a union bound, for every $n>0$ we have $\sprobability{m(T,f,\delta) \geq
  \lambda}{\mu_n} \leq \sprobability{K^c}{\mu_n} < \epsilon$.
Therefore we have shown (ii).

Now assume that (i) and (ii) hold and suppose that $\epsilon > 0$ is
given.  By (i) there exists $\lambda > 0$ such that $\sup_{n \geq 1}
\sprobability{\abs{f(0)} \geq \lambda}{\mu_n} < \epsilon/2$.  By (ii)
for every integer $T > 0$ and $k > 0$, there exists a $\delta_{T,k}$
such that $\sup_{n \geq 1} \sprobability{m(T, f, \delta_{T,k}) \geq
  1/k}{\mu_n} < \epsilon/2^{T+k+1}$.  If we define 
\begin{align*}
A_T &= \lbrace f \mid 
m(T,f,\delta_{T,k}) < 1/k \text{ for all } k \geq 1\rbrace
\end{align*}
so that $A^c_T \subset \cup_{k=1}^\infty \lbrace f \mid m(T, f, \delta_{T,k}) \geq
  1/k \rbrace$ then by a union bound
\begin{align*}
\sup_{n \geq 1} \mu_n(A_T) &= \sup_{n \geq 1} (1 - \mu_n(A^c_T))\\
&\geq \sup_{n \geq 1} \left(1 - \sum_{k=1}^\infty \sprobability{m(T, f, \delta_{T,k}) \geq
  1/k}{\mu_n}\right ) \\
&\geq 1 - \epsilon/2^{T+1}
\end{align*}
If we define $K = \lbrace f \mid \abs{f(0)} < \lambda \rbrace \cap
\cap_{T=1}^\infty A_T$ then another union bound shows $\sup_{n \geq 1}
\mu_n(K) > 1 - \epsilon$ and by construction the set $K$ satisfies the
conditions of Theorem \ref{ArzelaAscoliTheorem} so is proven compact.  
\end{proof}

To prove that the rescaled and linearly interpolated random walk converges we need
prove tightness.  To prove tightness we need to show equicontinuity.
The following Lemma begins the process by demonstrating equicontinuity
at $0$.  Keep in mind the picture of the scaling of the random walk at
level $n$
which places the value of $S_j$ at the point $j/n$ scaled by the
factor $1/\sigma\sqrt{n}$.  With this geometry in mind note that what
we are proving is a bound for each of the sequence of rescaled random
walks on the interval $[0,\delta]$.

TODO: Replace $\epsilon$ by $\lambda$ in the following Lemma?
\begin{lem}\label{RandomWalkEquicontinuityAt0} Let $\xi_n$ be i.i.d. with mean $0$ and finite variance
  $\sigma^2$ and define $S_n = \sum_{k=1}^n \xi_k$.  Then for all
  $\epsilon > 0$ 
\begin{align*}
\lim_{\delta \to 0} \limsup_{n \to \infty} \frac{1}{\delta}
\probability{\max_{1 \leq j \leq \floor{n\delta}+1} \frac{\abs{S_j}}{\sigma\sqrt{n}} \geq
  \epsilon} = 0
\end{align*}
\end{lem}
\begin{proof}
The idea of the proof is to leverage the Central Limit Theorem and
Gaussian tail bounds to control behavior at the right endpoint of the
interval under consideration.  Then independence of increments and
finite variance can be used to control the behavior over the entire
interval.

The sequence of random variables $\frac{1}{\sigma
  \sqrt{\floor{n\delta}+1}}S_{\floor{n\delta}+1}$ is a subsequence of
$\frac{1}{\sigma\sqrt{n}}S_n$ and therefore converges in distribution
to $N(0,1)$ by the Central Limit Theorem.  Furthermore, $\lim_{n \to
  \infty} \frac{\sqrt{\floor{n\delta}+1}}{\sqrt{n\delta}} = 1$ so by
Slutsky's Lemma we also have $\frac{1}{\sigma\sqrt{n\delta}}
S_{\floor{n\delta}+1} \todist Z$ where $Z$ is an $N(0,1)$ Gaussian
random variable.  By the Portmanteau Theorem (Theorem
\ref{PortmanteauTheorem}) and
a Markov bound (Lemma \ref{MarkovInequality}) we have
\begin{align*}
\limsup_{n \to \infty}
\probability{\abs{\frac{1}{\sigma\sqrt{n\delta}}S_{\floor{n\delta}+1}}
  \geq \lambda} &\leq \probability{\abs{Z}  \geq \lambda} \leq \frac{\expectation{\abs{Z}^3}}{\lambda^3}
\end{align*}

We want to leverage this bound to create a maximal inequality that controls the entire interval of
values of the rescaled random walk the approach being to leverage the
fact that either the final point is in the tail (in which
case the Central Limit Theorem bound just proven applies) or the final
point is outside the tail and some interior point is in the tail
providing us with an amount of variation whose probability can be
controlled by use of a second moment bound.  With $\epsilon > 0$ fixed as in
the hypothesis of the Lemma, define the random variable $\tau
= \min \lbrace j \geq 1 \mid \abs{\frac{S_j}{\sigma\sqrt{n}} } >
\epsilon\rbrace$ (this is a stopping time though we make no use of the
concept here).  Pick $\delta > 0$ satisfying $0 < \delta <
\epsilon^2/2$.

\begin{align*}
&\probability{\max_{1 \leq j \leq \floor{n\delta} + 1} \abs{\frac{S_j}{\sigma \sqrt{n}}} \geq \epsilon
  } \\
&=\probability{\max_{1 \leq j \leq \floor{n\delta} + 1}
  \abs{\frac{S_j}{\sigma \sqrt{n}}} \geq \epsilon; 
\abs{\frac{S_{\floor{n\delta}+1}}{\sigma \sqrt{n}}}  \geq \epsilon -
\sqrt{2\delta}} \\
&+ \probability{\max_{1 \leq j \leq \floor{n\delta} + 1}
  \abs{\frac{S_j}{\sigma \sqrt{n}}} \geq \epsilon; 
\abs{\frac{S_{\floor{n\delta}+1}}{\sigma \sqrt{n}}} < 
  \epsilon - \sqrt{2\delta}} \\
&\leq \probability{\abs{\frac{S_{\floor{n\delta}+1}}{\sigma \sqrt{n}}}
  \geq \epsilon - \sqrt{2\delta}} + 
\sum_{j=1}^{\floor{n\delta}}
\probability{\abs{\frac{S_{\floor{n\delta}+1}}{\sigma \sqrt{n}}} <
  \epsilon - \sqrt{2\delta}; \tau = j} \\
&= \probability{\abs{\frac{S_{\floor{n\delta}+1}}{\sigma \sqrt{n}}}
  \geq \epsilon - \sqrt{2\delta}} + 
\sum_{j=1}^{\floor{n\delta}}
\probability{\abs{\frac{S_{\floor{n\delta}+1}}{\sigma \sqrt{n}} -
    \frac{S_j}{\sigma \sqrt{n}}} > \sqrt{2\delta}; \tau = j} \\
&\leq \probability{\abs{\frac{S_{\floor{n\delta}+1}}{\sigma \sqrt{n}}}
  \geq \epsilon - \sqrt{2\delta}} + 
\frac{1}{2\delta}\sum_{j=1}^{\floor{n\delta}}
\expectation{\left(
    \frac{S_{\floor{n\delta}+1}}{\sigma \sqrt{n}} - \frac{S_j}{\sigma
      \sqrt{n}} \right)^2 \characteristic{\tau = j}} \\
&= \probability{\abs{\frac{S_{\floor{n\delta}+1}}{\sigma \sqrt{n}}}
  \geq \epsilon - \sqrt{2\delta}} + 
\frac{1}{2\delta}\sum_{j=1}^{\floor{n\delta}}
\expectation{\left( \sum_{i=j+1}^{\floor{n\delta}+1}
    \frac{\xi_i}{\sigma\sqrt{n}} \right)^2 } \probability{\tau = j} \\
&= \probability{\abs{\frac{S_{\floor{n\delta}+1}}{\sigma \sqrt{n}}}
  \geq \epsilon - \sqrt{2\delta}} + 
\frac{\floor{n\delta}}{2 n \delta}\sum_{j=1}^{\floor{n\delta}}
\probability{\tau = j} \\
&= \probability{\abs{\frac{S_{\floor{n\delta}+1}}{\sigma \sqrt{n}}}
  \geq \epsilon - \sqrt{2\delta}} + 
\frac{1}{2}\probability{\max_{1 \leq j \leq \floor{n\delta} + 1} \abs{\frac{S_j}{\sigma \sqrt{n}}} \geq \epsilon}
\end{align*}
Therefore we have shown that 
\begin{align*}
\probability{\max_{1 \leq j \leq \floor{n\delta} + 1} \abs{\frac{S_j}{\sigma \sqrt{n}}} \geq \epsilon}
&\leq 2 \probability{\abs{\frac{S_{\floor{n\delta}+1}}{\sigma \sqrt{n}}}
  \geq \epsilon - \sqrt{2\delta}} 
\end{align*}
and we can use our tail bound derived from the Central Limit Theorem
(with $\lambda = \frac{\epsilon - \sqrt{2\delta}}{\sqrt{\delta}}$)
to see that 
\begin{align*}
\lim_{\delta \to 0} \limsup_{n \to \infty} \frac{1}{\delta} \probability{\max_{1 \leq j \leq \floor{n\delta} + 1} \abs{\frac{S_j}{\sigma \sqrt{n}}} \geq \epsilon}
&\leq \lim_{\delta \to 0 } \frac{2}{\delta} \expectation{\abs{Z}^3}
\left(\frac {\sqrt{\delta}}{\epsilon - \sqrt{2\delta}}\right)^3 = 0
\end{align*}
\end{proof}

The next step is to extend the estimate that provides equicontinuity
at $0$ to prove equicontinuity of the random walk on all finite intervals.  
\begin{lem}\label{RandomWalkEquicontinuity}
Let $\xi_n$ be i.i.d. with mean $0$ and finite variance
  $\sigma^2$ and define $S_n = \sum_{k=1}^n \xi_k$.  Then for all
  $\epsilon > 0$ and $T > 0$ 
\begin{align*}
\lim_{\delta \to 0} \limsup_{n \to \infty} 
\probability{\max_{
\substack{1 \leq j \leq \floor{n\delta}+1 \\
0 \leq k \leq \floor{nT}+1}} \frac{\abs{S_{j+k}
    - S_k}}{\sigma\sqrt{n}} \geq
  \epsilon} = 0
\end{align*}
\end{lem}
\begin{proof}
Pick $0 \leq \delta \leq T$ and let $m \geq 2$ be the integer such that
$T/m < \delta \leq T/(m-1)$.  Since
\begin{align*}
\lim_{n \to \infty} \frac{\floor{nT}+1}{\floor{n\delta}+1} &=
\frac{T}{\delta} < m
\end{align*}
we know that for sufficiently large $n$ we have $\floor{nT}+1  <
(\floor{n\delta}+1)m$.  For any such $n$, suppose $\frac{\abs{S_{j+k}
    - S_k}}{\sigma\sqrt{n}} > \epsilon$ for some $k$ with $0 \leq k
\leq \floor{nT}+1$ and some $j$ with $0 \leq j \leq
\floor{n\delta}+1$.  Now let $p$ be the integer such that $0 \leq p
\leq m -1$ and 
\begin{align*}
(\floor{n\delta}+1)p \leq k < (\floor{n\delta}+1)(p+1)
\end{align*}
Since $0 \leq j \leq \floor{n\delta}+1$ either 
\begin{align*}
(\floor{n\delta}+1)p \leq k+j < (\floor{n\delta}+1)(p+1)
\end{align*}
or
\begin{align*}
(\floor{n\delta}+1)(p+1) \leq k+j < (\floor{n\delta}+1)(p+2)
\end{align*}
In the first case by the triangle inequality we have
\begin{align*}
\abs{S_{j+k} - S_k} \leq \abs{S_{k} - S_{(\floor{n\delta}+1)p}}+ \abs{S_{j+k} - S_{(\floor{n\delta}+1)p}}
\end{align*}
and therefore we know that either $\frac{\abs{S_{k}
    - S_{(\floor{n\delta}+1)p}}}{\sigma\sqrt{n}} \geq \epsilon/2 > \epsilon/3$ or $\frac{\abs{S_{k+j}
    - S_{(\floor{n\delta}+1)p}}}{\sigma\sqrt{n}} \geq \epsilon/2 > \epsilon/3$.  In
the second case by the triangle inequality we have
\begin{align*}
\abs{S_{j+k} - S_k} \leq \abs{S_{k} - S_{(\floor{n\delta}+1)p}}+ \abs{S_{(\floor{n\delta}+1)(p+1)} - S_{(\floor{n\delta}+1)p}}+ \abs{S_{j+k} - S_{(\floor{n\delta}+1)(p+1)}}
\end{align*}
and therefore we know that either  
$\frac{\abs{S_{k} - S_{(\floor{n\delta}+1)p}}}{\sigma\sqrt{n}} \geq
\epsilon/3$,  
$\frac{\abs{S_{(\floor{n\delta}+1)(p+1)} -
    S_{(\floor{n\delta}+1)p}}}{\sigma\sqrt{n}} \geq \epsilon/3$ or 
$\frac{\abs{S_{k+j} - S_{(\floor{n\delta}+1)(p+1)}}}{\sigma\sqrt{n}}
\geq \epsilon/3$.  Therefore we have the inclusion of events
\begin{align*}
\left \lbrace\max_{
\substack{1 \leq j \leq \floor{n\delta}+1 \\
0 \leq k \leq \floor{nT}+1}} \frac{\abs{S_{j+k}
    - S_k}}{\sigma\sqrt{n}} \geq
  \epsilon\right \rbrace 
&\subset 
\bigcup_{p=0}^{m} \left \lbrace \max_{1 \leq j \leq \floor{n\delta}+1}
\frac{\abs{S_{j + (\floor{n\delta}+1)p} - S_{(\floor{n\delta}+1)p}}}{\sigma\sqrt{n}} \geq
\epsilon/3 \right \rbrace
\end{align*}
By the i.i.d. nature of $\xi_n$ and the fact that $S_0 = 0$ we know that 
\begin{align*}
\probability{\max_{1 \leq j \leq \floor{n\delta}+1}
\frac{\abs{S_{j + (\floor{n\delta}+1)p} - S_{(\floor{n\delta}+1)p}}}{\sigma\sqrt{n}} \geq
\epsilon/3 } &= \probability{\max_{1 \leq j \leq \floor{n\delta}+1}
\frac{\abs{S_{j}}}{\sigma\sqrt{n}} \geq \epsilon/3 }
\end{align*}
and therefore 
\begin{align*}
\probability{\max_{
\substack{1 \leq j \leq \floor{n\delta}+1 \\
0 \leq k \leq \floor{nT}+1}} \frac{\abs{S_{j+k}
    - S_k}}{\sigma\sqrt{n}}} \leq (m+1) \probability{\max_{1 \leq j \leq \floor{n\delta}+1}
\frac{\abs{S_{j}}}{\sigma\sqrt{n}} \geq \epsilon/3 }
\end{align*}
Since $\lim_{\delta \to 0} (m+1)\delta < \lim_{\delta \to 0} (T/\delta
+ 2) \delta = T < \infty$ we can apply Lemma \ref{RandomWalkEquicontinuityAt0} to get the result.
\end{proof}

By Prohorov's Theorem \ref{Prohorov} we know that a tight sequence of probability
measures on a separable metric space has a convergent subsequence.  What is often required is some
way of proving that a particular measure is indeed the limit of that
subsequence.  Recalling Lemma \ref{ProcessLawsAndFDDs} we know that
finite dimensional distributions characterize the laws of stochastic
processes which leads one to the following general procedure for
proving convergence of a sequence of processes.

TODO: Kallenberg (Chapter 16) has general results here for $C(T ; S)$ with $T$ a
$lcscH$-space and $S$ metric.  Of course there are also results for
spaces of discontinuous functions for use in proving convergence of
empirical distribution functions.  Kallenberg also has results for
point process/spaces of measures.

We are taking the point of view of Brownian motion and the linearly
interpolated random walk as being a random element in $C([0,\infty) ;
\reals)$.  On the other hand we have thus far treated a stochastic
process as a random element in a subset of a path space $(S^T,
\mathcal{S}^{\otimes T})$ \emph{equipped with the product
  $\sigma$-algebra}.  It is tempting to gloss over this
point, however to tie in the general definition of stochastic
processes with the random elements of $C([0,\infty); \reals)$ we are
dealing with it is
important to understand the relationship between the Borel
$\sigma$-algebra on $C([0,\infty); \reals)$ and the product
$\sigma$-algebra $\mathcal{B}(\reals)^{\otimes [0,\infty)}$ used in the definition of
processes.
\begin{lem}\label{BorelGeneratedByProjections}For every $t \in [0,\infty)$ let $\pi_t : C([0,\infty); \reals) \to
  \reals$ be the evaluation map $\pi_t(f) = f(t)$.  The Borel $\sigma$-algebra on $C([0,\infty); \reals)$ is
  equal to $\sigma(\lbrace \pi_t \mid t \in [0,\infty) \rbrace)$ and
  therefore $\mathcal{B}(C([0,\infty); \reals)) = C([0,\infty);
  \reals) \cap \mathcal{B}(\reals)^{\otimes [0,\infty)}$.
\end{lem}
\begin{proof}Since each $\pi_t$ is a continuous function, it is Borel
  measurable and therefore the Borel $\sigma$-algebra contains
  $\sigma(\lbrace \pi_t \mid t \in [0,\infty) \rbrace)$.

On the other hand, we know that $C([0,\infty) ; \reals)$ is separable
so we may pick a countable dense set $f_1, f_2, \dotsc$.
If we let $U \subset C([0,\infty) ; \reals)$ be open then for every
$f_j \in U$ there exists $r_j > 0$ such that $B(f_j, r_j) \subset U$
and $U$ is the union of such $B(f_j, r_j)$ (indeed, any $y \in U$ not in the
union of balls can't be the limit of the $f_j$ that are in $U$; on the
other hand it can't be the limit of the $f_j$ that are in $U^c$ since
the latter set is closed; thus the existence of such a $y$ would
contradict the density of $f_1, f_2, \dotsc$).  To show $U \in
\sigma(\lbrace \pi_t \mid t \in [0,\infty) \rbrace)$
it suffices to show that $B(f, r) \in \sigma(\lbrace \pi_t \mid t \in
[0,\infty) \rbrace)$ for every $f \in C([0,\infty) ; \reals)$ and $r > 0$.

Let $B(f, r)$ be given and note that by continuity of the
elements of $C([0,\infty) ; \reals)$ the closed ball
\begin{align*}
\overline{B(f, r)} &= \lbrace g \mid \sup_{x \in [0,\infty)} \abs{f(x)
  - g(x)} \leq r \rbrace \\
&= \lbrace g \mid \sup_{\substack{x \in
    [0,\infty) \\ x \in \rationals}} \abs{f(x)
  - g(x)} \leq r \rbrace \\
&= \cap_{\substack{x \in
    [0,\infty) \\ x \in \rationals}} \pi_x^{-1} ([f(x)-r,f(x)+r]) 
\end{align*}
which shows that $\overline{B(f, r)} \in \sigma(\lbrace \pi_t \mid t \in
[0,\infty) \rbrace)$ and $B(f, r) = \cap_{n=1}^\infty \overline{B(f, r+1/n)}$
which shows that $B(f, r) \in \sigma(\lbrace \pi_t \mid t \in
[0,\infty) \rbrace)$.
\end{proof}

\begin{thm}\label{ConvergenceInDistributionOfContinuousAsTightnessAndFDDs}Let $X_n$ be a tight sequence of continuous processes such
  that for all $d > 0$ and $0 \leq t_1 < \dotsb < t_d < \infty$ the
  sequence $(X_{n, t_1}, \dotsc , X_{n, t_d})$ converges in
  distribution, then the laws $X_n$ converge to a Borel probability
  distribution $\mu$ on $C([0,\infty); \reals)$ for which the
  canonical process $W_t(\omega) = \omega(t)$ satisfies
\begin{align*}
(X_{n, t_1}, \dotsc , X_{n, t_d}) \todist (W_{t_1}, \dotsc, W_{t_d})
\end{align*}
\end{thm}
\begin{proof}
By tightness and Prohorov's Theorem \ref{Prohorov} we know that $X_n$
has a weakly convergent subsequence.  Our first claim is that any two weakly convergent subsequences of
$X_n$ have the same limiting distribution.  Let $\check{X}_n$ and $\hat{X}_n$ be two
such subsequences and suppose that $\pushforward{\check{X}_n}{P} \to
\check{\mu}$ and $\pushforward{\hat{X}_n}{P} \to\hat{\mu}$
respectively.  Fix $0 \leq t_1 < \dotsb < t_d < \infty$ and note that
by the Continuous Mapping Theorem \ref{ContinuousMappingTheorem} we
know that $\pushforward{(\check{X}_{n,t_1}, \dotsc,
  \check{X}_{n,t_d})}{P} \todist \pushforward{(\pi_{t_1}, \dotsc,
  \pi_{t_d})}{\check{\mu}}$ and $\pushforward{(\hat{X}_{n,t_1}, \dotsc,
  \hat{X}_{n,t_d})}{P} \todist \pushforward{(\pi_{t_1}, \dotsc,
  \pi_{t_d})}{\hat{\mu}}$.  By hypothesis we conclude that $\pushforward{(\pi_{t_1}, \dotsc,
  \pi_{t_d})}{\check{\mu}} = \pushforward{(\pi_{t_1}, \dotsc,
  \pi_{t_d})}{\hat{\mu}}$ and therefore by
Lemma \ref{BorelGeneratedByProjections} we can apply Lemma
\ref{ProcessLawsAndFDDs} to conclude $\check{\mu}=\hat{\mu}$ which we
now refer to as $\mu$.

Now suppose that the distributions of $X_n$ do not converge weakly to
$\mu$.  Then there exists a bounded continuous $f$ such that either
$\lim_{n \to \infty} \expectation{f(X_n)}$ does not exist or exists
and is different from $\int f \, d\mu$.  In either case by the
boundedness of $f$ we know that 
\begin{align*}
-\infty &< -\norm{f}_\infty \leq \liminf_{n \to \infty}
\expectation{f(X_n)} \leq \limsup_{n \to \infty} \expectation{f(X_n)}
\leq \norm{f}_\infty  < \infty
\end{align*}
and we can extract
a subsequence $\check{X}_n$ such that $\lim_{n \to \infty}
\expectation{f(\check{X}_n)}$ exists and $\lim_{n \to \infty}
\expectation{f(\check{X}_n)} \neq \int f \, d\mu$.  This is a
contradiction since by tightness we know that $\check{X}_n$ has a weakly
convergent subsequence and we have already just shown that the limiting
distribution is $\mu$.
\end{proof}

The power of this Theorem is that it is often not too difficult to
prove weak convergence of finite dimensional distributions because we
have the power of a rich theory available (e.g. the Central Limit
Theorem, Slutsky's Theorem, characteristic functions).

\begin{lem}\label{ConvergenceOfRandomWalkFDD}Let $\xi_n$ be i.i.d. with mean $0$ and finite variance
  $\sigma^2$, define $S_n = \sum_{k=1}^n \xi_k$, $S_n^*(t) =
  S_{\floor{t}} + (t - \floor{t})\xi_{\floor{t}+1}$ and
  $X_n(t) = \frac{1}{\sigma \sqrt{n}} S_n^*(nt)$ where the latter are
  interpreted as random elements of the Borel measurable space
  $C([0,\infty);\reals)$.  For every $d > 0$ and real numbers $0 \leq t_1 < \cdots < t_d
  < \infty$ we have 
\begin{align*}
(X_n(t_1), \dotsc, X_n(t_d)) \todist (B_{t_1}, \dotsc, B_{t_d})
\end{align*}
where $B_t$ is a standard Brownian motion.
\end{lem}
\begin{proof}
Let $0 \leq t_1 < \dotsb < t_n < \infty$ be given.  The basic point is
that the result follows by the Central Limit Theorem; however due to
the linear interpolation there is a bit of extra work to do.

First note that by definition 
\begin{align*}
\abs{X_n(t) - \frac{1}{\sigma \sqrt{n}} S_{\floor{nt}} }
&\leq  \frac{1}{\sigma \sqrt{n}}\abs{\xi_{\floor{nt}+1}}
\end{align*}
so by a Chebyshev bound (Lemma \ref{ChebInequality}) we have
\begin{align*}
\lim_{n \to \infty} \probability{\abs{X_n(t) - \frac{1}{\sigma
      \sqrt{n}} S_{\floor{nt}} } > \epsilon}
&\leq  \lim_{n \to \infty} \frac{1}{n\epsilon^2} = 0
\end{align*}
thus $X_n(t)  \toprob \frac{1}{\sigma\sqrt{n}} S_{\floor{nt}}$ and by
Lemma \ref{ConvergenceInProbabilityInProductSpaces}
we have $(X_n(t_1), \dotsc, X_n(t_d)) \toprob (\frac{1}{\sigma\sqrt{n}}
S_{\floor{nt_1}}, \dotsc, \frac{1}{\sigma\sqrt{n}}
S_{\floor{nt_d}})$.  Our result will follow by Slutsky's Theorem
\ref{Slutsky} if we can show that
\begin{align*}
(\frac{1}{\sigma\sqrt{n}}
S_{\floor{nt_1}}, \dotsc, \frac{1}{\sigma\sqrt{n}}S_{\floor{nt_d}}) \todist (B_{t_1}, \dotsc, B_{t_d})
\end{align*}
Application of the Continuous Mapping Theorem
\ref{ContinuousMappingTheorem} lets us reduce further to showing that 
\begin{align*}
(\frac{1}{\sigma\sqrt{n}}(S_{\floor{nt_1}} -
S_{\floor{nt_0}}), \dotsc, \frac{1}{\sigma\sqrt{n}}
(S_{\floor{nt_d}}- S_{\floor{nt_{d-1}}}))\todist (B_{t_1} - B_{t_0}, \dotsc, B_{t_d} - B_{t_{d-1}})
\end{align*}
where for uniformity of notation we have defined $t_0 = 0$.  Since the
$\xi_n$ are independent this implies that the $S_{\floor{nt_j}}-
S_{\floor{nt_{j-1}}}$ are independent for $j=1, \dotsc, d$ and by
definition of independent increments property of Brownian motion we
know that $B_{t_j} - B_{t_{j-1}}$ are independent, thus by Lemma \ref{IndependenceProductMeasures} it suffices to
show that $\frac{1}{\sigma\sqrt{n}} (S_{\floor{nt_j}}-S_{\floor{nt_{j-1}}}) \todist N(0, t_j -
t_{j-1})$.  We shall prove this fact for an arbitrary $0 \leq s < t < \infty$.

By the definition of $S_n$ we write $\frac{1}{\sigma\sqrt{n}}
(S_{\floor{nt}}-S_{\floor{ns}}) =
\frac{1}{\sigma\sqrt{n}}\sum_{i=\floor{ns}+1}^{\floor{nt}}
\xi_i$.  For every $\epsilon > 0$ we have by another Chebyshev bound 
\begin{align*}
&\lim_{n \to \infty} \probability{\abs{\frac{1}{\sigma\sqrt{n}}
\sum_{i=\floor{ns}+1}^{\floor{nt}}\xi_i
- \frac{\sqrt{t-s}}{\sigma\sqrt{\floor{nt}-\floor{ns}}}
\sum_{i=\floor{ns}+1}^{\floor{nt}}\xi_i } > \epsilon} \\
&\leq \lim_{n \to \infty}\frac{1}{\epsilon^2}\variance{\left(\frac{1}{\sigma\sqrt{n}}
-\frac{\sqrt{t-s}}{\sigma\sqrt{\floor{nt}-\floor{ns}}} \right)
\sum_{i=\floor{ns}+1}^{\floor{nt}}\xi_i} \\
&= \lim_{n \to \infty}\frac{1}{\epsilon^2}\left(\frac{1}{\sigma\sqrt{n}}
-\frac{\sqrt{t-s}}{\sigma\sqrt{\floor{nt}-\floor{ns}}} \right)^2
(\floor{nt}-\floor{ns}) \sigma^2\\
&= \lim_{n \to \infty} \frac{1}{\epsilon^2} \left(
  \frac{\sqrt{\floor{nt}-\floor{ns}}}{\sqrt{n}} -
  \sqrt{t-s}\right)^2 = 0
\end{align*}
Therefore we have $\frac{1}{\sigma\sqrt{n}}
\sum_{i=\floor{ns}+1}^{\floor{nt}}\xi_i \toprob \frac{\sqrt{t-s}}{\sigma\sqrt{\floor{nt}-\floor{ns}}}
\sum_{i=\floor{ns}+1}^{\floor{nt}}\xi_i $ and one last appeal to
Slutsky's Theorem \ref{Slutsky} implies that it suffices to show
\begin{align*}
\frac{\sqrt{t-s}}{\sigma\sqrt{\floor{nt}-\floor{ns}}}
\sum_{i=\floor{ns}+1}^{\floor{nt}}\xi_i \todist N(0, t-s)
\end{align*}
which is just the Central Limit Theorem (and to be precise the
Continuous Mapping Theorem \ref{ContinuousMappingTheorem} to account for the multiplication by $\sqrt{t-s}$).
\end{proof}

The last step we make is in extending the equicontinuity of the random
walk to equicontinuity of the linearly interpolated random walk which
are honest elements of $C([0, \infty); \reals)$.  This equicontinuity
will prove tightness and weak convergence of the linearly interpolated
random walk.  One of the elements of proving the equicontinuity of the
linearly interpolated random walk is a general fact about the modulus
of continuity of a class of piecewise linear functions which we prove
as a separate lemma.

\begin{lem}\label{ModulusOfContinuityOfPL}Let $f(t)$ be a continuous function that is linear on every
  interval $[j,j+1]$ for $j=0, 1, \dotsc$.  For every integer $M
  > 0$ and $N > 0$, we have
\begin{align*}
\sup_{\substack{\abs{s -t} \leq M \\ 0 \leq s,t
    \leq N} } \abs{f(s) - f(t)}
&\leq
\sup_{\substack{1 \leq j \leq M \\ 0 \leq k
    \leq N}} \abs{f(k+j) - f(k)}
\end{align*}
\end{lem}
\begin{proof}
Pick $0 \leq s<t \leq M$.  If there exists $j < N$ such that $j \leq s
< t \leq j+1$ then it is clear from linearity  that $\abs{f(s) - f(t)}
\leq \abs{f(j) - f(j+1)}$ so it suffices to consider the case in which 
$j \leq s < j +1 < \dotsb < j+k < t \leq j+k+1$ for some $j \geq 0$ and $k
> 0$.  If we let $f(t)$ has slope $a_j$ on the interval $[j,j+1]$
then we can write $f(t) - f(s) = a_{j}(j+1 -s) + \dotsb + a_{j+k}(t -
j -k)$.  Note that
if $f(t) - f(s)$ has a different sign  than $a_j$ then $\abs{f(t) -
  f(s)} \leq \abs{f(t) -  f(j+1)}$ and similarly with $a_{j+k}$ so if
suffices to assume that $a_j$ and $a_{j+k}$ have the same sign as
$f(t)-f(s)$.  Now if $\abs{a_j} \leq \abs{a_{j+k}}$ then we slide the
pair $(s,t)$ to the right until either $s$ or $t$ hits an integer.
More formally if $j+1 - s \leq j+k+1 -t$ then we get
$\abs{f(t) -
  f(s)} \leq \abs{f(t + j+1-s) - f(j+1)}$ and if $j+k+1 -t \leq j+1 -
  s$
we get the bound $\abs{f(t) -
  f(s)} \leq \abs{f(j+k+1) - f(s + j+k+1 -t)}$.  If we $\abs{a_j} \geq
\abs{a_{j+k}}$ we slide to the left in an analogous way.  The point is
that we are reduced to the case in which either $s=j-1$ or $t=j+k+1$.

Once we know that either $s=j-1$ or $t=j+k+1$ , because $M$ is integer
we know that in fact $k \leq M$ and therefore we get a final bound
$\abs{f(t) - f(s)} \leq \abs{f(j+k+1) - f(j-1)}$ which proves the
result.

TODO: This proof is grotesque.  Try to do better!
\end{proof}

We are finally ready to put all of the pieces together to prove
Donsker's Theorem on the convergence of random walks to Brownian
motion.  Note that we have not used the existence of Brownian motion
anywhere in the proof so this Theorem is among other things an
existence proof for Brownian motion.
\begin{thm}[Donsker's Invariance Principle for Random Walks]\label{Donsker2}Let $\xi_n$ be i.i.d. with mean $0$ and finite variance
  $\sigma^2$, define $S_n = \sum_{k=1}^n \xi_k$, $S_n^*(t) =
  S_{\floor{t}} + (t - \floor{t})\xi_{\floor{t}+1}$ and
  $X_n(t) = \frac{1}{\sigma \sqrt{n}} S_n^*(nt)$ where the latter are
  interpreted as random elements of the Borel measurable space
  $C([0,\infty);\reals)$.  
Then the law of $X_n$  converges weakly to a probability measure under
which the coordinate mapping $(f,t) \to f(t)$ is a standard Brownian motion.
\end{thm}
\begin{proof}
Lemma \ref{ConvergenceOfRandomWalkFDD} shows that finite dimensional
distributions of the linearly interpolated and rescaled random walk
converge to the finite dimensional distributions of Brownian motion.
Therefore by Theorem
\ref{ConvergenceInDistributionOfContinuousAsTightnessAndFDDs} it
remains to show that $X_n$ is a tight sequence of processes.
By Lemma \ref{TightnessOfContinuousFunctions} we must show for all $X_n(t)$,
\begin{itemize}
\item[(i)]$\lim_{\lambda \to \infty} \sup_{n \geq 1} \probability{\abs{X_n(0)}
  \geq \lambda}= 0$.
\item[(ii)] $\lim_{\delta \to 0} \sup_{n \geq 1} \probability{m(T, X_n,
  \delta) \geq \lambda} = 0$ for all $\lambda > 0$ and $T > 0$.
\end{itemize}
Since $X_n(0) = 0$ the condition (i) holds trivially.  As for
condition (ii) we first argue that it suffices to show $\lim_{\delta \to 0} \limsup_{n \geq 1} \probability{m(T, X_n,
  \delta) \geq \lambda}= 0$.  This follows from the fact that for
fixed $n > 0$,
$\lim_{\delta \to 0} \probability{m(T, X_n,  \delta) \geq \lambda} =
0$ (continuity of $X_n$) and $\probability{m(T, X_n,  \delta) \geq \lambda}$ is a decreasing
function of $\delta$.  Indeed, if we let $\epsilon > 0$ be given pick
$\Delta > 0$ such that $\limsup_{n \geq 1} \probability{m(T, X_n,
  \delta) \geq \lambda} < \epsilon$ for all $\delta \leq \Delta$.  Then pick $N > 0$ is such that $\sup_{n \geq N} \probability{m(T, X_n,
  \Delta) \geq \lambda} < \epsilon$ and note that because $\probability{m(T, X_n,
  \delta) \geq \lambda}$ is decreasing in fact we have $\sup_{n \geq N} \probability{m(T, X_n,
  \delta) \geq \lambda} < \epsilon$ for all $\delta \leq \Delta$.
Since $\lim_{\delta \to 0} \probability{m(T, X_n,
  \delta) \geq \lambda} = 0 $ for every $n>0$ we can find
$\hat{\Delta} < \Delta$ such that $\probability{m(T, X_n,
  \delta) \geq \lambda}  < \epsilon$ for all $n=1, \dotsc, N-1$ and
$\delta \leq \hat{\Delta}$ and
thus $\sup_{n \geq 1} \probability{m(T, X_n,  \Delta) \geq \lambda} < \epsilon$ for all $\delta < \hat{\Delta}$.

With this reduction in hand, we can estimate
\begin{align*}
\probability{m(T, X_n,  \delta) \geq \lambda} &=
\probability{\sup_{\substack{\abs{s -t} \leq \delta \\ 0 \leq s,t
    \leq T}} \abs{X_n(s) - X_n(t)} \geq \lambda} \\
&\leq
\probability{\sup_{\substack{\abs{s -t} \leq \floor{n \delta} + 1 \\ 0 \leq s,t
    \leq \floor{T \delta}+1}} \abs{S^*_n(s) - S^*_n(t)} \geq \sigma
\sqrt{n} \lambda} \\
&\leq 
\probability{\sup_{\substack{1 \leq j \leq \floor{n \delta} + 1 \\ 0 \leq k
    \leq \floor{T \delta}+1}} \abs{S_n(k+j) - S_n(k)} \geq \sigma
\sqrt{n} \lambda} 
\end{align*}
where the last inequality follows Lemma \ref
{ModulusOfContinuityOfPL}.  Now we can apply Lemma
\ref{RandomWalkEquicontinuity} to conclude $\lim_{\delta \to
  0}\limsup_{n \to \infty} \probability{m(T, X_n,  \delta) \geq
  \lambda}$ and tightness is shown.
\end{proof}

\section{Skorohod Space}
TODO: Currently going through this.  

Question 1:  In the definition of the $J_1$ topology on $D([0,\infty);
S)$ given a time shift $\lambda(t)$ we define $d(f,g,\lambda, u) = \sup_{t \geq 0} q(f(t \wedge u),
g(\lambda(t) \wedge u))$ and take the distance given the time shift as
$\int_0^\infty e^{-u} d(f,g,\lambda,u) \, du$.  Why is $d$ defined
this way and not as  $d(f,g,\lambda, u) = \sup_{0 \leq t \leq u} q(f(t),
g(\lambda(t)))$?  Would the latter fail to define a metric or would it
fail to be complete?

Question 2: Given a cadlag function $f : [0,1] \to S$, we know that
$f$ has only countably many jump discontinuities; is there some notion
of uniform continuity that can be preserved?  E.g. can we say that
given $\epsilon > 0$ for
all points of continuity $x$ of $f$  there exists a uniform $\delta > 0$
such that $\abs{x-y} < \delta$ implies $q(f(x), f(y)) < \epsilon$?

\begin{lem}\label{CadlagCountableDiscontinuitySet}If $x \in D([0,T];
  S)$ or $x \in D([0,\infty); S)$ then $x$ is continuous at all but a
  countable number of points.
\end{lem}
\begin{proof}
We begin by considering the case of $x \in D([0,t]; S)$.  Pick an
$\epsilon > 0$ and define
\begin{align*}
A_\epsilon &= \lbrace 0 \leq t \leq T \mid r(x(t-), x(t)) \geq
\epsilon \rbrace
\end{align*}

Claim: $A_\epsilon$ is finite.

Suppose otherwise, then by compactness of $[0,T]$ there is an
accumulation point $t$ of $A_\epsilon$.  By passing to a further
subsequence we can assume that we have a sequence $t_n$ such that $t_n
\in A_\epsilon$ and
either $t_n \downarrow t$ or $t_n \uparrow t$.  First consider the
case $t_n \downarrow t$.  For every $n$ by the existence of the left
limit $x(t_n-)$ we can find $t_n^\prime$ such that $t_{n+1} >
t_n^\prime > t_n$ and $r(x(t_n), x(t_n^\prime)) > \epsilon/2$.  Now by
construction we
know that $t_n^\prime \downarrow t$ and by right continuity we get
$\lim_{n \to \infty} x(t_n) = \lim_{n \to \infty} x(t_n) = x(t)$.  
However this is a contradiction since we can find $N > 0$ such that
$r(x(t), x(t_N)) < \epsilon/4$ and $r(x(t), x(t_N^\prime) <
\epsilon/4$ which yields $r(x(t_N), x(t_N^\prime)) < \epsilon/2$.  If
$t_n \uparrow t$ we argue similarly construction a sequence
$t_n^\prime$ such that $t_{n-1} < t_n^\prime < t_n$ and $r(x(t_n),
x(t_n^\prime)) > \epsilon/2$.  By existence of left limits, we know that $\lim_{n \to \infty}
x(t_n^\prime) = \lim_{n \to \infty} x(t_n) = x(t-)$ and this gives a
contradiction as before.

Now simply note that the set of
discontinuities of $x$ is $\cup_{n=1}^\infty A_{1/n}$ and is therefore
countable.  In a similar way we see that the set of discontinuities
for $x \in D([0,\infty); S)$ is countable since it is equal to the
union of the discontinuities of $x$ restricted to $[0,n]$ for $n \in \naturals$.
\end{proof}

\begin{defn}Let $\Lambda$ denote the set of all $\lambda : [0,T] \to
  [0,T]$ such that $\lambda$ is continuous, strictly increasing and
  bijective.  Then for each $\lambda \in \Lambda$ we define 
\begin{align*}
\rho(x,y,\lambda) &= \abs{\lambda(t) - t} \vee \sup_{t \in [0,T]} r(x(t), y(\lambda(t))
\end{align*}
and define $\rho : D([0,T]; E) \times D([0,T]; E) \to  reals$ by 
\begin{align*}
\rho(x,y) &= \inf_{\lambda \in \Lambda} \rho(x,y,\lambda)
= \inf_{\lambda \in \Lambda} \sup_{t \in [0,T]}
\abs{\lambda(t) - t} \vee \sup_{t \in [0,T]} r(x(t), y(\lambda(t))
\end{align*}
\end{defn}

\begin{lem}\label{SkorohodJ1RhoMetric}$\rho$ is a metric on $D([0,T];E)$.
\end{lem}
\begin{proof}
It is clear that $\rho(x,y) \geq 0$, now suppose that $\rho(x,y) =
0$.  By definition we can find a sequence $\lambda_n \in \Lambda$ such
that $\sup_{t \in [0,T]} \abs{\lambda_n(t) - t} < 1/n$ and $\sup_{t
  \in [0,T]} r(x(t), y(\lambda_n(t)) < 1/n$.  From the former
inequality we see that $\lim_{n \to \infty} \lambda_n(t) = t$ and the second
inequality we see that $\lim_{n \to \infty} y(\lambda_n(t) = x(t)$.
By the cadlag nature of $y$ shows that either $x(t) = y(t)$ or $x(t) =
y(t-)$; so in particular, $x(t) = y(t)$ at all continuity points of
$y(t)$.  However, since the set of discontinuity points is countable
it follows that the set of continuity points is dense in $[0,T]$ and
therefore for every $t \in T$ we can find a set of continuity points
$t_n$ such that $t_n \downarrow t$ and therefore by right continuity
of $y$ we conclude $x(t) = y(t)$.

To see symmetry of $\rho$ we first note that $\lambda \in \Lambda$
implies $\lambda^{-1} \in \Lambda$.   To see this, it is first off
clear that $\lambda^{-1}$ exists because $\lambda$ is a bijection.
The fact that $\lambda^{-1}$ is strictly increasing follows because
if $0 \leq t < s \leq T$ and $0 \leq \lambda^{-1}(s) \leq lambda^{-1}(t) \leq T$ then strictly
increasing and bijective nature of $\lambda$ tells $s \leq t$ which is
contradiction.  To see that $\lambda^{-1}$ is continuous, pick $0 < t
< T$ and let $\epsilon > 0$ be given such that $0 < \lambda^{-1}(t) -
\epsilon < \lambda^{-1}(t)  < \lambda^{-1}(t) + \epsilon < T$.  By strict increasingness
and bijectivity 
of $\lambda$ we know that $0 < \lambda(\lambda^{-1}(t) -
\epsilon) < t < \lambda(\lambda^{-1}(t) + \epsilon) < T$.  Let 
\begin{align*}
\delta &< ( t -  \lambda(\lambda^{-1}(t) -\epsilon)) \wedge (
\lambda(\lambda^{-1}(t) +\epsilon) -t)
\end{align*}
and note by the strict increasingness of $\lambda^{-1}$ we have
\begin{align*}
0 &< \lambda^{-1}(t) -\epsilon < \lambda^{-1}(t - \delta) <
\lambda^{-1}(t) < \lambda^{-1}(t + \delta) < \lambda^{-1}(t) + \epsilon
< T
\end{align*}
Now by the bijectivity of $\lambda$ we know that by a change of variables
\begin{align*}
\sup_{0 \leq t \leq T} \abs{\lambda(t) - t} &= \sup_{0 \leq s \leq T} \abs{s - \lambda^{-1}(s)} \\
\sup_{0 \leq t \leq T} r(x(t), y(\lambda(t))) &= \sup_{0 \leq s \leq
  T} r(x(\lambda^{-1}(s)), y(s)) = 
\sup_{0 \leq s \leq  T} r(y(s), x(\lambda^{-1}(s)))\\
\end{align*}
and therefore $\rho(x,y,\lambda) = \rho(y,x,\lambda^{-1}$.  Because
inversion is a bijection on $\Lambda$ we then get
\begin{align*}
\rho(x,y) &= \inf_{\lambda \in \Lambda} \rho(x,y,\lambda) =
\inf_{\lambda \in \Lambda} \rho(y,x,\lambda^{-1}) = \inf_{\lambda^{-1}
  \in \Lambda} \rho(y,x,\lambda^{-1}) = \rho(y,x)
\end{align*}
\end{proof}

The metric $\rho$ defines the Skorohod $J_1$ topology on the space
$D([0,T];E)$.  We emphasize here that we are actually interested in
the underlying topology as much as the metric space structure itself
since $\rho$ is not a complete metric.

\begin{examp}\label{NoncompletenessSkorohod}Let $f_n =
  \characteristic{[1/2, 1/2 + 1/(n+2))}$ for $n >0$ be a sequence in
  $D([0,1];\reals)$.  We show that $f_n$ is a Cauchy sequence with
  respect to $\rho$ but $f_n$ does not converge in the $J_1$ topology.
To see that $f_n$ is Cauchy, let $n > 0$ be given and suppose $m \geq
n$.  Define 
\begin{align*}
\lambda_{n,m}(t) &= \begin{cases}
t & \text{if $0 \leq t \leq 1/2$} \\
\frac{n+m+2}{n+2}(t - 1/2) + 1/2 & \text{if $1/2 \leq t < 1/2 +
  1/(n+m+2)$} \\
\frac{\frac{1}{2} - \frac{1}{n}}{\frac{1}{2} - \frac{1}{n+m+2}}(t - \frac{1}{2} - \frac{1}{n+m+2}) + \frac{1}{2} + \frac{1}{n} & \text{if $1/2 +
  1/(n+m+2) \leq t \leq 1$} \\
\end{cases}
\end{align*}
so that $f_{n+m} (t) = f_{n}(\lambda_{m+n}(t))$ for all $t \in [0,1]$
and $\sup_{0 \leq t \leq 1} \abs{\lambda_{m+n}(t) - t} = \frac{1}{n} -
\frac{1}{n+m+2} < \frac{1}{n}$ which shows $\rho(f_n, f_{n+m}) < \frac{1}{n}$.

Claim: If $f_n$ converges in then it must converge to $0$.

Suppose that $f_n$ converges to some $f \in D([0,1];\reals)$.  Then
there exist $\lambda_n \in \Lambda$ such that $\lim_{n \to \infty} \sup_{0 \leq t \leq 1}
\abs{\lambda_n(t) - t} = 0$ and 
$\lim_{n \to \infty} \sup_{0 \leq t \leq 1}\abs{f_n(t) -
  f(\lambda_n(t))} = 0$.  Therefore for each $0 \leq t \leq 1$ that is
a point of continuity of $f$ we have 
$\lim_{n \to \infty} f_n(t) = \lim_{n \to \infty} f(\lambda_n(t)) =
f(t)$.  By definition of $f_n(t)$ and Lemma
\ref{CadlagCountableDiscontinuitySet} we see that $f(t) = 0$ for all
but a countable number of $0 \leq t \leq 1$.  Therefore by right
continuity and the existence of left limits we conclude $f(t) = 0$ for
all $0 \leq t \leq 1$.  Since $f(\lambda(t))$ is identically zero for
all $\lambda \in \Lambda$ we conclude that $\rho(f_n, 0) = 1$ hence
$f_n$ does not converge.
\end{examp}

\begin{defn}Given $f \in D([0,T];E)$ the function
\begin{align*}
w(f,\delta) &= \inf_{\substack{0=t_0 < t_1 < \dotsb < t_n = T \\
  \min_{1 \leq i \leq n} (t_i - t_{i-1}) > \delta \\ n \in \naturals}}
\max_{1 \leq i \leq n} \sup_{t_{i-1} \leq s < t < t_i} r(f(s), f(t))
\end{align*}
is called the modulus of continuity.
\end{defn}

\begin{lem}\label{SkorohodJ1ModulusOfContinuity}If $f \in D([0,T];E)$ then $\lim_{\delta \to 0} w(f,\delta)
  = 0$.
\end{lem}
\begin{proof}
First note that for fixed $f$ the function $w(f, \delta)$ is a
non-decreasing function of $\delta$.  This is simply because any
candidate partition $0 = t_0 < t_1 < \dotsb < t_n=T$ with $\min_{1
  \leq i \leq n} (t_i - t_{i-1}) > \delta$ is also a candidate for any
smaller value of $\delta$.  Thus the set of candidate partitions gets
larger as $\delta$ shrinks and the infimum over the set of candiates
shrinks.

Let $\epsilon > 0$ be given.  Define $t_0 = 0$ then so long as
$t_{i-1} < T$ we inductively define
$t_i = \inf \lbrace t > t_{i-1} \mid r(f(t), f(t_{i-1})) > \epsilon \rbrace \wedge T$.  We claim that
there exists $n$ such $t_n = T$.  First, note that the sequence $t_i$
is strictly increasing while $t_i < T$ by the right continuity of
$f$.  If there are an infinite number of $t_i < T$ then by compactness
of $[0,T]$ there is a limit point $0 \leq t \leq T$.  However the
existence of the left limit $f(t-)$ says
exists $\delta > 0$ such that for all $0 < t - s < \delta$ we have
$r(f(s), f(t-)) < \epsilon/3$.
This is a contradiction since we can find an $n > 0$ such that for all
$i \geq n$ we have $t - t_i < \delta$.  By definition of the
$t_i$ for any $i \geq n+1$ we can pick
$t_i \leq s < t$ such that $r(f(s), f(t_{i-1})) >
\epsilon$ which provides us with $0 < t -s < \delta$ and 
\begin{align*}
r(f(s),f(t-)) &> r(f(s), f(t_{i-1})) - r(f(t_{i-1}), f(t-)) > \epsilon -
\epsilon/2 = \epsilon/2
\end{align*}

Thus we have constructed a sequence $0 =t_0 < t_1 < \dotsb < t_n = T$
such that $\max_{1 \leq i \leq n} \sup_{t_{i-1} < s < t < t_i}
r(f(s),f(t)) < 2 \epsilon$ so it we define $\delta = \frac{1}{2} \min_{1 \leq i
  \leq n} (t_i - t_{i-1})$ we have shown $w(f, \delta) \leq 2
\epsilon$.  Since $\epsilon$ was arbitrary and $w(f,\delta)$ is a
non-decreasing function of $\delta$ we are done.
\end{proof}

Even though the metric $\rho$ is not complete, the underlying topology
is Polish because we can define an equivalent metric that is
complete.  To repair the incompleteness of $\rho$ we have to be a bit
more strict about the types of time changes that are allowed; more
specifically we have to prevent time changes are asymptotically flat
(or by considering taking the inverse of a time change prevent time
changes that are asymptotically vertical).  The following is a way of
quantifying such a requirement.
\begin{defn}For every $\lambda \in \Lambda$ define 
\begin{align*}
\gamma(\lambda) =
  \sup_{0 \leq s < t \leq T} \abs{\log \frac{\lambda(t) -
      \lambda(s)}{t-s}}
\end{align*}
For every $x,y \in D([0,T]; E)$ define 
\begin{align*}
d(x,y) = \inf_{\substack{\lambda \in \Lambda \\ \gamma(\lambda) <
    \infty}} \gamma(\lambda) \vee \sup_{0 \leq t \leq T} r(x(t) ,y(\lambda(t)))
\end{align*}
\end{defn}

The main goal is to prove
\begin{lem}\label{SkorohodJ1Metric}$d$ is a metric on $D([0,T];E)$ that is equivalent to
  $\rho$.
\end{lem}
Before proving the result we need a few simple facts about $\gamma$.
\begin{lem}\label{SkorohodJ1GammaFacts}$\gamma(\lambda) = \gamma(\lambda^{-1})$ and
  $\gamma(\lambda_1 \circ \lambda_2) \leq \gamma(\lambda_1) +
  \gamma(\lambda_2)$.
\end{lem} 
\begin{proof}
These both follow from reparameterizations using the fact that
$\lambda^{-1}$ is a strictly increasing bijection.  For the first
\begin{align*}
\gamma(\lambda) &= 
\sup_{0 \leq s < t \leq T} \abs{\log  \frac{\lambda(t) -
    \lambda(s)}{t-s}} \\
&=\sup_{0 \leq \lambda^{-1}(s) < \lambda^{-1}(t) \leq T} \abs{\log
  \frac{\lambda(\lambda^{-1}(t)) -
    \lambda(\lambda^{-1}(s))}{\lambda^{-1}(t)-\lambda^{-1}(s)}} \\
&= \sup_{0 \leq s < t \leq T} \abs{\log  \frac{\lambda^{-1}(t) - \lambda^{-1}(s)}{t-s}} 
\end{align*}
and for the second
\begin{align*}
\gamma(\lambda) &= 
\sup_{0 \leq s < t \leq T} \abs{\log  \frac{\lambda_2(\lambda_1(t)) -
    \lambda_2(\lambda_1(s))}{t-s}} \\
&\leq \sup_{0 \leq s < t \leq T} \abs{\log  \frac{\lambda_2(\lambda_1(t)) -
    \lambda_2(\lambda_1(s))}{\lambda_1(t)-\lambda_1(s)}} +
\sup_{0 \leq s < t \leq T} \abs{\log  \frac{\lambda_1(t) -
    \lambda_1(s)}{t-s}} \\
&\leq \sup_{0 \leq s < t \leq T} \abs{\log  \frac{\lambda_2(t) -
    \lambda_2(s)}{t-s}} +
\sup_{0 \leq s < t \leq T} \abs{\log  \frac{\lambda_1(t) -
    \lambda_1(s)}{t-s}} \\
&=\gamma(\lambda_2) + \gamma(\lambda_1)
\end{align*}
\end{proof}

\begin{lem}\label{SkorohodEquivalenceA}For all $\lambda$ such that $\gamma(\lambda) < 1/2$ we have
  $\sup_{0 \leq t \leq T} \abs{\lambda(t) - t} \leq
  2T\gamma(\lambda)$.  For all $f,g \in D([0,T]; S)$ such that $d(f,g) < 1/2$ we
  have $d(f,g) \leq 2T\rho(f,g)$.
\end{lem}
\begin{proof}
From the inequality $1+x \leq e^x$ we have
$\log(1+2x) \leq 2x$ for all $x > -1/2$ and therefore for $0 < x <
1/2$ we have $\log(1-2x) \leq -2x < -x < 0$.  
Similarly we have
$\log(1-2x) \leq -2x$ for all $x < 1/2$ and therefore for $0 < x <
1/2$ we have $\log(1-2x) \leq -2x < -x < 0$ for $0 < x < 1/2$.  On the
other hand, we see that $\frac{d}{dx} \left ( \log(1+2x) - x \right) =
\frac{2}{1+2x} - 1$ is positive for $0 < x < 1/2$ and therefore we
conclude 
\begin{align*}
\log(1-2x) &< -x < 0 < x < \log(1+2x) \text{ for } 0 < x < 1/2
\end{align*}

Suppose $\gamma(\lambda) < 1/2$ and let $0 \leq t \leq T$.  By definition and the
fact that $\lambda(0) = 0$ we have
\begin{align*}
\abs{\log \frac{\lambda(t)}{t}} &\leq \sup_{0 \leq s < t \leq
  T}\abs{\log \frac{\lambda(t) - \lambda(s)}{t-s}} = \gamma(\lambda) 
\end{align*}
and therefore we get
\begin{align*}
\log(1-2\gamma(\lambda)) &< -\gamma(\lambda) < \log \frac{\lambda(t)}{t} < \gamma(\lambda) < \log(1+2\gamma(\lambda))
\end{align*}
and exponentiating
\begin{align*}
1 - 2\gamma(\lambda) < \frac{\lambda(t)}{t} < 1 + 2 \gamma(\lambda)
\end{align*}
which shows $\sup_{0 \leq t \leq T} \abs{\lambda(t) - t} < 2 T \gamma(\lambda)$.  

Now suppose we have $d(f,g) < 1/2$.  Let $\epsilon$ be given and
select $\lambda \in \Lambda$ such that $\gamma(\lambda) < 1/2 \wedge
(d(f,g) + \epsilon)$ and $\sup_{0 \leq t \leq T} r(f(t),
g(\lambda(t))) < d(f,g) + \epsilon$.  By what we have just shown, we
get that $\sup_{0 \leq t \leq T} \abs{\lambda(t) - t} < 2 T
\gamma(\lambda) < 2T(d(f,g) + \epsilon)$ and therefore $\rho(f,g) <
2T(d(f,g) + \epsilon)$.  Now let $\epsilon \to 0$.
\end{proof}

\begin{proof}
The fact that $d(f,g) \geq 0$ is immediate. Suppose $d(f,g)$ and pick $\lambda_n$ such that
$\lim_{n \to \infty} \gamma(\lambda_n) = 0$ and $\lim_{n \to \infty} \sup_{0 \leq t \leq
  T} r(f(t), g(\lambda_n(t))) = 0$.  By Lemma
\ref{SkorohodEquivalenceA}  we know that $\lim_{n \to \infty} \sup_{0
  \leq t \leq T} \abs{\lambda_n(t) - t} = 0$ as well and therefore we
can repeat the argument of Lemma \ref{SkorohodJ1RhoMetric} to conclude $f=g$.

To see symmetry just note that by reparametrizing and Lemma \ref{SkorohodJ1GammaFacts}
\begin{align*}
d(f,g) &= \inf_{\substack{\lambda \in \Lambda \\ \gamma(\lambda) <
    \infty}} \gamma(\lambda) \vee \sup_{0 \leq t \leq T} r(f(t),
g(\lambda(t))) \\
&= \inf_{\substack{\lambda \in \Lambda \\ \gamma(\lambda) <
    \infty}} \gamma(\lambda^{-1}) \vee \sup_{0 \leq \lambda^{-1}(t) \leq T}
r(g(t), f(\lambda^{-1}(t))) = d(g,f)
\end{align*}
and similarly with the triangle inequality.

TODO: Write out the triangle inequality part.
\end{proof}

The goal in introducing $d$ was to provide a complete metric; a useful
thing to check first is that $d$ fixes the example which showed $\rho$
was not a complete metric.
\begin{examp}Here we continue the Example
  \ref{NoncompletenessSkorohod} by showing directly that $f_n$ is not
  Cauchy in the metric $d$.  Because $f_n$ are indicator functions it
  follows that $\sup_{0 \leq t \leq 1} \abs{f_{n+m}(t) - f_{n}(\lambda(t))}$ is
  either $0$ or $1$.  Therefore if $f_n$ is Cauchy then we can find
  $\lambda_{nm}(t)$ such that $\sup_{0 \leq t \leq 1} \abs{f_{n+m}(t) -
    f_{n}(\lambda_{nm}(t))} = 0$.  By definition this tells us that
  $\lambda_{nm}([1/2,1/2 + 1/n+m+2]) =  [1/2,1/2+1/n]$ 
(of course $\lambda_{nm}([0,1/2]) = [0,1/2]$ and
$\lambda_{nm}([1/2 + 1/n+m+2, 1]) = [1/2 + 1/n,1]$ as well).  
From this fact we see that $\gamma(\lambda_{mn}) \geq
\frac{n+m+2}{n+2} > 1$ which shows that $d(f_n, f_{n+m}) \geq 1$ so
$f_n$ is not Cauchy with respect to $d$.
\end{examp}

\section{Riesz Representation}

We saw in the Daniell-Stone Theorem \ref{DaniellStoneTheorem} that one
may recapture a part of integration theory by considering certain
linear functionals on a space of functions.  There is a analogue to
that result that applies in the case of measure on topological
spaces and allows one to bring the machinery of functional analysis to
bear on problems of measure theory.  

The Riesz representation theorem is actually a class of different
theorems with different hypotheses made about the measures involved
and the topology on the
underlying space.  Here we concentrate the reasonable general case of
Hausdorff locally compact spaces.  Other presentations may treat the
slightly simpler cases in which either second countability,
compactness or
$\sigma$-compactness are added as hypotheses on the topological space.  More general
presentations may drop the the assumption of local compactness and treat
arbitrary Hausdorff spaces.  

\begin{defn}A topological space $X$ is said to be \emph{locally
    compact} if every point in $X$ has a compact neighborhood
  (i.e. for every $x \in X$ there exists an open set $U$ and a compact
  set $K$ such that $x \in U \subset K$).
\end{defn}

\begin{lem}\label{LocallyCompactEquivalences}Let $X$ be a Hausdorff topological space then the following
  are equivalent
\begin{itemize}
\item[(i)]$X$ is locally compact
\item[(ii)]Every point in $X$ has an open neighborhood with compact closure
\item[(iii)]$X$ has a base of relatively compact neighborhoods
\end{itemize}
\end{lem}
\begin{proof}
(i) implies (ii):  If $X$ is Hausdorff then a closed subset of a compact set is compact
and therefore if $X$ is locally compact and $x \in X$ we take $U$ open
and $K$ compact such that $x \in U \subset K$ and then it follows that
$\overline{U}$ is compact hence (ii) follows.  

The fact that (ii) implies (i) is immediate.

(ii) implies (iii): For each $x \in X$ pick a relatively compact
neighborhood $U_x$, let $\mathcal{B}_x = \{ U \subset U_x \mid U
\in \mathcal{T} \}$ and let $\mathcal{B} = \cup_{x \in X}
\mathcal{B}_x$.  It is clear that $\mathcal{B}$ is a base for the
topology $\mathcal{T}$.  Moreover for each $U
\in \mathcal{B}$ there exists $x \in X$ such that $U \subset U_x$ with
$\overline{U}_x$ compact and then since $X$ is Hausdorff we know that
$\overline{U}$ is compact.

(iii) implies (ii) is immediate.
\end{proof}

\begin{prop}\label{CompleteRegularityLCH}A locally compact Hausdorff space X is completely regular
  (i.e. for every $x \in X$ and closed set $F \subset X$ such that $x
  \notin F$ there is are disjoint open sets $U$ and $V$ such that $x
  \in U$ and $F \subset V$).
\end{prop}
\begin{proof}
Let $F$ be a closed set and pick $x \in X \setminus F$.  By Lemma
\ref{LocallyCompactEquivalences} and the openness of $X \setminus F$
we can find a relatively compact neighborhood $U_0$ of $x$ such that $x
\in U_0 \subset X \setminus F$.  The set $\overline{U_0} \cap F$ is a closed subset of a compact
set hence is compact.  For each $y \in \overline{U_0} \cap F$ by the
Hausdorff property we may find open neighborhoods $x \in U_y$ and $y
\in V_y$ such that $U_y \cap V_y = \emptyset$.  By compactness of
$\overline{U} \cap F$ we get a finite subcover $V_{y_1}, \dotsc,
V_{y_n}$ of $\overline{U_0} \cap F$.  Now define $U = U_0 \cap U_{y_1}
\cap \dotsb U_{y_n}$.  This is an open neighborhood of $x$ and
moreover $\overline{U} \cap F = \emptyset$.  Define $V = X \setminus \overline{U}$.
\end{proof}

\begin{defn}Let $X$ be a topological space, then a subset $A \subset
  X$ is said to be \emph{bounded} if there exists a compact set $K$
  such that 
  $A \subset K \subset X$.  A subset $A \subset
  X$ is said to be \emph{$\sigma$-bounded} if there exists a sequence
  of compact sets $K_1, K_2, \dotsc$ such that
$A \subset  \cup_{i=1}^\infty K_i \subset X$.
\end{defn}

\begin{prop}\label{SigmaBoundedEquivalence}A set $A$ is $\sigma$-bounded Borel set if and only if
  there exist disjoint bounded Borel sets $A_1, A_2, \dotsc$ such that $A =
  \cup_{i=1}^\infty A_i$.
\end{prop}
\begin{proof}
Suppose $A$ is a $\sigma$-bounded Borel set and let $K_1, K_2, \dotsc$
be compact sets such that $A \subset \cup_{i=1}^\infty K_i$.  Define
$A_1= A \cap K_1$ and for $n>1$ let $A_n = A \cap K_n \setminus
\cup_{j=1}^{n-1} A_j$  Trivially each $A_n$ is bounded (it is contained in
$K_n$), $A = \cup_{i=1}^\infty A_i$ (by construction $A_n \subset A$
and for any $x \in A$ we can find $n$ such that $x \in K_n$; it
follows that $x \in A_n$).  Moreover by construction it is clear that
the $A_n$ are Borel.  On the other hand, if $A =
\cup_{i=1}^\infty A_i$ with $A_i$ bounded and Borel and disjoint, then take $K_i$ compact
such that $A_i \subset K_i$ and it follows that $A \subset
\cup_{i=1}^\infty K_i$.  $A$ is clearly Borel as it is a countable
union of Borel sets.
\end{proof}

\begin{lem}\label{BoundedNeighborhoodsOfCompactSets}Let $K$ be a
  compact set in a locally compact Hausdorff topological
  space $X$, then there exists a bounded open set $U$ such that $K
  \subset U$.  Moreover if $V$ is a open set such that $K \subset V$
  then there is a bounded open set $U$ such that $K \subset U \subset
  \overline{U} \subset V$.
\end{lem}
\begin{proof}
By taking $V = X$ we see the second assertion implies the first so it
suffices to prove the second assertion.  By complete regularity of $X$
(Proposition \ref{CompleteRegularityLCH}) and local compactness of $X$
for each $x \in K$ we may
find a relatively compact open neighborhood $x \in U_x$ such that
$\overline{U}_x \cap V^c = \emptyset$.  By compactness of $K$ we may
take a finite subcover $U_{x_1}, \dotsc, U_{x_n}$.  Then
$U = U_{x_1} \cup \dotsb \cup U_{x_n}$ is an open set with $K \subset
U$ and
$\overline{U} = \overline{U}_{x_1} \cup \dotsb \cup \overline{U}_{x_n}$ is
a finite union of
compact sets and is therefore compact.  Lastly $\overline{U} \cap
V^c = (\overline{U}_{x_1} \cap V^c) \cup \dotsb \cup
(\overline{U}_{x_n} \cap V^c) = \emptyset$ and therefore $K \subset U
\subset \overline{U} \subset V$.
\end{proof}

For our purposes the reason for bringing up $\sigma$-bounded sets is
the fact that the properties of inner and outer regularity are
essentially equivalent on them.

\begin{lem}\label{InnerOuterRegularityEquivalence}Let $X$ be a locally compact Hausdorff topological space and let $\mu$ be a measure
  that is finite on compact sets.  Then $\mu$ is inner regular on
  $\sigma$-bounded Borel sets if and only if $\mu$ is outer regular on
  $\sigma$-bounded Borel sets.
\end{lem}
\begin{proof}
Suppose that $\mu$ is inner regular on $\sigma$-bounded sets.  Let $A$
be a bounded Borel set and suppose $\epsilon > 0$ is given.   First,
note that $\overline{A}$ is compact so may apply
Lemma \ref{BoundedNeighborhoodsOfCompactSets} to find a bounded
open set $U$ such that $\overline{A} \subset U$.  Therefore
$\overline{U} \setminus A$ is a bounded Borel set so by inner
regularity we may find a
compact set $K \subset \overline{U} \setminus A$ such that 
\begin{align*}
\mu(\overline{U} \setminus A) - \epsilon &< \mu(K) \leq \mu(\overline{U} \setminus A)
\end{align*}
Let $V = U \cap K^c$.  Then $V$ is an open set and $A \subset V$.
Moreover,
\begin{align*}
\mu(V) &= \mu(U) - \mu(K) \leq \mu(\overline{U}) - \mu(\overline{U}
\setminus A) + \epsilon = \mu(A) + \epsilon
\end{align*}
Since $\epsilon > 0$ was arbitrary we see that $\mu$ is outer regular
on bounded Borel sets.  Now we need to extend to outer regularity on
$\sigma$-bounded sets.  Let $A$ be a $\sigma$-bounded Borel set and
let $\epsilon > 0$ be given.  Apply Lemma
\ref{SigmaBoundedEquivalence}
to find disjoint bounded Borel sets $A_i$ such that $A = \cup_{i=1}^\infty
A_i$.  By the just proven outer regularity on bounded Borel sets we
may find open sets $U_i$ such that $\mu(U_i) \leq \mu(A_i) +
\epsilon/2^i$.  Then clearly $A \subset U$, $U$ is open and 
\begin{align*}
\mu(U) &\leq \sum_{i=1}^\infty \mu(U_i) \leq \epsilon + \sum_{i=1}^\infty
\mu(A_i)  = \epsilon + \mu(A)
\end{align*}
Again, as $\epsilon > 0$ is arbitrary we see that $\mu$ is outer
regular on $\sigma$-bounded Borel sets.

Now we assume that $\mu$ is outer regular on $\sigma$-bounded Borel
sets.  As before we start with the bounded case.  Let $A$ be a bounded
Borel set and suppose that $\epsilon > 0$ is given.  Let $L$ be a
compact set such that $A \subset L$.  Since $L \setminus A$ is also a
bounded Borel set, we may apply outer regularity to find an open set
$U$ such that $L \setminus A \subset U$ and 
\begin{align*}
\mu(U) - \epsilon < \mu(L \setminus A) \leq \mu(U)
\end{align*}
Define $K = L \setminus U = L \cap U^c$. As $K$ is a closed subset of the compact set $L$
it is compact.  Also
\begin{align*}
\mu(K) &= \mu(L) - \mu(L \cap U) \geq \mu(L) - \mu(U) = \mu(A) + \mu(L
\setminus A) - \mu(U) > \mu(A) - \epsilon
\end{align*}
As $\epsilon >0$ was arbitrary we see that $\mu$ is inner regular on
bounded Borel sets.  

Lastly we extend inner regularity to
$\sigma$-bounded Borel sets.  Let $A$ be $\sigma$-bounded Borel and
write $A = \cup_{i=1}^\infty A_i$ with the $A_i$ disjoint and each
$A_i$ bounded Borel (Lemma \ref{SigmaBoundedEquivalence}).  Let
$\epsilon > 0$ be given.  As each
$A_i$ is bounded and $\mu$ is finite on compact sets it follows that
$\mu(A_i) < \infty$ for all $i \in \naturals$.  Now by the just proven
inner regularity on bounded Borel sets we find $L_i \subset A_i$ with
$L_i$ compact and
\begin{align*}
\mu(A_i) - \epsilon/2^i < \mu(L_i) \leq \mu(A_i)
\end{align*}
The disjointness of the $A_i$ implies that the $L_i$ are disjoint as well.
Let $K_n = L_1 \cup \dotsb \cup L_n$ and note that
\begin{align*}
\mu(K_n) &= \sum_{i=1}^n \mu(L_i) > \sum_{i=1}^n \left( \mu(A_i) -
\epsilon/2^i \right ) > \sum_{i=1}^n \mu(A_i) - \epsilon
\end{align*}
Now take the limit as $n \to \infty$ to conclude that 
\begin{align*}
\sup \lbrace \mu(K) \mid K \subset A \text{ and $K$ is compact}
\rbrace &\geq \sup_n \mu(K_n) \geq \mu(A) - \epsilon
\end{align*}
and as $\epsilon > 0$ was arbitrary inner regularity of $\mu$ on
$\sigma$-bounded Borel sets is proven.
\end{proof}

\begin{defn}Let $X$ be a topological space the $C_c(X)$ is the set of
  all continuous function $f : X \to \reals$ with compact support
  (i.e. $supp(f) = \overline{\{x \in X \mid f(x) \neq 0 \}}$ is
  compact).
\end{defn}

\begin{defn}Let $X$ be a topological space the $C_0(X)$ is the set of
  all continuous function $f : X \to \reals$ which vanish at infinity
  in the sense that for every $\lambda >0$ the set $\{ x \in X \mid
  \abs{f(x)} \geq \lambda \}$ is  compact.
\end{defn}

\begin{prop}\label{BanachSpaceOfFunctionsVanishingAtInfinity}If $X$ is a topological space, then  for each $f \in C_0(X)$
  define $\norm{f} = \sup_{x \in X} \abs{f(x)}$ then $\norm{f}$ is a
  norm on $C_0(X)$ and $C_0(X)$ is a Banach space.  Furthermore
  $C_c(X)$ is dense in $C_0(X)$.
\end{prop}
\begin{proof}
TODO:
\end{proof}

The difficult part of the Riesz-Markov Theorem is the construction of
a Radon measure that corresponds to a positive functional.  The
tradition is to break that construction into two pieces: first the
construction of a set function on a smaller class of sets than the
full $\sigma$-algebra  and secondly the extension of that set function
to a full blown Radon measure. In many developments the set function
is defined on the compact subsets of the  locally compact
Hausdorff space $X$ and are called \emph{contents}.  Following
Arveson, we choose a set function is one
that is defined on just the open subsets of $X$.

The description of the desireable properties of the set function and
the process of extending the set function to a Radon measure is dealt with in the following Lemma.
\begin{lem}\label{ExtensionToRadonMeasure}Let $X$ be a locally compact Hausdorff space and let $m$ be
  a function from the open set of $X$ to $[0,\infty]$ satisfying:
\begin{itemize}
\item[(i)]$m(U) < \infty$ if $\overline{U}$ is compact
\item[(ii)]if $U \subset V$ then $m(U) \leq m(V)$
\item[(iii)]$m(\cup_{i=1}^\infty U_i) \leq \sum_{i=1}^\infty m(U_i)$
  for all open sets $U_1, U_2, \dotsc$.
\item[(iv)]if $U \cap V = \emptyset$ then $m(U \cup V) = m(U) + m(V)$
\item[(v)]$m(U) = \sup \lbrace m(V) \mid V \text{ is open, } \overline{V} \subset U \text{ and }
  \overline{V} \text{ is compact} \rbrace$
\end{itemize}
then there is a unique Radon measure $\mu$ such that $\mu(U) = m(U)$
for all open sets $U$.  Moreover every Radon measure satisfies
properties (i) through (v) when restricted to the open subsets of $X$.
\end{lem}
\begin{proof}
First we show that a Radon measure satisfies properties (i) through
(v) on the open sets of $X$.  In fact, properties (ii), (iii) and (iv)
follow for all measures and (i) follows from the fact that $\mu$ is
finite on compact subsets and monotonicity of measure.  Property (v)
requires a bit more justification.  If we let $U$ is an open set and
$\epsilon > 0$ is given then by inner regularity of $\mu$ we may find
a compact set $K$ such that $K \subset U$ and $\mu(U) \geq \mu(K) > \mu(U) -
\epsilon$.  By Lemma \ref{BoundedNeighborhoodsOfCompactSets} we may
find a relatively compact open set $V$ such that $K \subset V \subset
\overline{V} \subset U$.  Then by monotonicity we have $\mu(U) \geq \mu(V) > \mu(U) -
\epsilon$ and since $\epsilon$ was arbitrary (v) follows.

Next we prove uniqueness of the extension of $m$ to a Radon measure
$\mu$.  Since a Radon measure is inner regular on all Borel sets Lemma
\ref{InnerOuterRegularityEquivalence} implies that any extension $\mu$
is outer regular on all $\sigma$-bounded Borel sets.  Since the values
of $\mu$ are determined on all open sets this implies that the values
of $\mu$ are determined on all $\sigma$-bounded Borel sets; in
particular the values of $\mu$ are determined on all compact
sets. Clearly a Radon measure is determined uniquely by its values on
compact sets.

Now we turn to proving existence of the extension $\mu$.  The proof
goes in a few steps.  First we define an outer measure from $m$ and
observe that Borel sets are measurable with respect to it; though the
Caratheordory restriction of the outer
measure is outer regular it is not necessarily inner regular.  The
second step is to 
modify the Caratheodory restriction to make it inner regular.  

We begin by defining the outer measure in a standard way.  Let $A$ be
an arbitrary subset of $X$ and define
\begin{align*}
\mu^*(A) &= \inf \lbrace m(U) \mid A \subset U \text{ and $U$
  is open} \rbrace
\end{align*}
Note that $\mu^*(U) = m(U)$ for all open sets.

Claim : $\mu^*$ is an outer measure

Note that because the emptyset is relatively compact we know from (i)
that $m(\emptyset) < \infty$ and thus from (iv) we see that
$m(\emptyset) = 2m(\emptyset)$.  Thus $m(\emptyset) = 0$ and it
follows that $\mu^*(\emptyset) = 0$.  If $A \subset B$ then it is
trival that 
\begin{align*}
\lbrace m(U) \mid A \subset U \text{ and $U$
  is open } \rbrace &\subset \lbrace m(U) \mid B \subset U \text{ and $U$
  is open } \rbrace
\end{align*}
which implies $\mu^*(A) \leq \mu^*(B)$.  If we let $A_1, A_2, \dotsc$
be given and define $A = \cup_{i=1}^\infty A_i$.  If any
$\mu^*(A_i) = \infty$ it follows that $\mu(A) \leq \sum_{i=1}^\infty
\mu^*(A_i) = \infty$.  If on the other hand every $\mu^*(A_i) <
\infty$ then let $\epsilon > 0$ be given and find an open set $U_i
\subset A_i$ such that $m(U_i) \leq \mu^*(A_i) + \epsilon / 2^i$.
Clearly $\cup_{i=1}^\infty U_i$ is an open subset of $A$ and it
follows from (iii) and the definition of $\mu^*$ that
\begin{align*}
\mu^*(A) &\leq m(\cup_{i=1}^\infty U_i) \leq \sum_{i=1}^\infty m(U_i)
\leq \sum_{i=1}^\infty m(A_i) + \epsilon
\end{align*}
Since $\epsilon > 0$ is arbitrary we see that $\mu^*$ is countably
subadditive and is therefore proven to be an outer measure.

Claim: Borel sets are $\mu^*$-measurable.

The $\mu^*$-measurable sets form a $\sigma$-algebra by Lemma
\ref{CaratheodoryRestriction} and therefore it suffices to show that
open sets are $\mu^*$-measurable.  Let $U$ be open subset and $A$ be an
arbitrary subset of $X$, by subadditivity of $\mu^*$ we only have to
show the inequality 
\begin{align*}
\mu^*(A) &\geq \mu^*(A \cap U) + \mu^*(A \cap U^c)
\end{align*}
Obviously we may assume that $\mu^*(A) < \infty$ since otherwise the
inequality is trivially satisfied.  
We first assume that $A$ is an open set.  Since $\mu^*$ and $m$ agree
on open sets we have to show
\begin{align*}
m(A) &\geq m(A \cap U) + \mu^*(A \cap U^c)
\end{align*}
Let $\epsilon > 0$ be given and use property (v) so we can find an relatively compact open set $V$ such
that $\overline{V} \subset A \cap U$ and $m(V) \geq m(A \cap U) -
\epsilon$.  Then $A \cap \overline{V}^c$ is an open set containing $A
\cap U^c$ disjoint from $V$ and it follows from (ii), (iv)  and the
definition of $\mu^*$ that
\begin{align*}
m(A) &\geq m(V \cup A \cap \overline{V}^c) = m(V) + m(A \cap
\overline{V}^c) \geq m(A \cap U) - \epsilon + \mu^*(A \cap U^c) 
\end{align*}
As $\epsilon > 0$ was arbitrary we are done with the case of open
sets $A$.  Now suppose that $A$ is an arbitrary set with $\mu^*(A) <
\infty$ and let $\epsilon
> 0$ be given.  We find an open set $V$ such that $A \subset V$ and
$m(V) \leq \mu^*(A) + \epsilon$.  From what we have just proven of
open sets and the monotonicity of $\mu^*$
\begin{align*}
\mu^*(A) + \epsilon &\geq \mu^*(V) \geq \mu^*(V \cap U) + \mu^*(V \cap
U^c) \geq \mu^*(A \cap U) + \mu^*(A \cap U^c) 
\end{align*}
The claim follows by observing that $\epsilon >0$ was arbitrary.

Now by Caratheodory Restriction (Lemma \ref{CaratheodoryRestriction}) we may restrict $\mu^*$ to a Borel measure
$\overline{\mu}$ that is outer regular by definition and that
satisfies $\overline{\mu}(U) = m(U)$ for all open sets $U$.  Moreover
$\overline{\mu}(K) < \infty$ for all compact sets since by Lemma
\ref{BoundedNeighborhoodsOfCompactSets} we may find a relatively
compact open neighborhood $U$ such that $K \subset U$; monotonicity
and (i) tell us that 
\begin{align*}
\overline{\mu}(K) \leq \overline{\mu}(U) = m(U) <
\infty
\end{align*}  
Since $\overline{\mu}$ is outer regular on all Borel sets \emph{a fortiori}
it is outer regular on all $\sigma$-bounded Borel sets.  By  Lemma
\ref{InnerOuterRegularityEquivalence} it follows that
$\overline{\mu}$ is inner regular on all $\sigma$-bounded Borel sets.
Note that if we assume that $X$ is $\sigma$-compact (i.e. all Borel
sets are $\sigma$-bounded) then we already know that $\overline{\mu}$
is a Radon measure.  In the general case it is not necessarily true
and we must make a further modification to $\overline{\mu}$ to make it
inner regular.

For an arbitrary Borel set $A$ we define
\begin{align*}
\mu(A) &= \sup \lbrace \overline{\mu}(B) \mid B \subset A \text{ and
  $B$ is a $\sigma$-bounded Borel set } \rbrace
\end{align*}
Clearly, $\mu(\emptyset) = \overline{\mu}(\emptyset) = 0$.
It is also immediate from the definition that $\mu(A) = \overline{\mu}(A)$
for all $\sigma$-bounded Borel sets $A$ and therefore that $\mu(U) =
m(U)$ for all $\sigma$-bounded open sets $U$.  In fact more is true.

Claim: $\mu(U) = m(U)$ for all open sets $U$.

Let $V$ be a relatively compact open set with $\overline{V} \subset U$.  We have
\begin{align*}
m(U) &= \overline{\mu}(U) \geq \mu(U) \geq \mu(V) = m(V)
\end{align*}
Now we take the supremum over all such $V$ and by property (v) 
\begin{align*}
m(U) &\geq \mu(U) \sup \lbrace m(V) \mid V \text{ is relatively
  compact and $\overline{V} \subset U$} \rbrace = m(U)
\end{align*}
and therefore $\mu(U) = m(U)$.

Claim: $\mu$ is a measure.

To see that $\mu$ is a measure it remains to show countable
additivity.  Let $A_1, A_2, \dotsc$ be disjoint Borel sets.  First we
show countable subadditivity.  Let $B$ be a $\sigma$-bounded Borel
subset of $\cup_{i=1}^\infty A_i$ and define $B_i = B \cap A_i$.
Clearly the $B_i$ are disjoint $\sigma$-bounded Borel measures, thus
using the countable additivity of $\overline{\mu}$ we get
\begin{align*}
\overline{\mu{B}} &= \sum_{i=1}^\infty \overline{\mu}(B_i) \leq \sum_{i=1}^\infty \mu(A_i)
\end{align*}
Taking the supremum over all such $B$ subadditivity follows.

We need to show the opposite inequality.  Suppose that some $\mu(A_j) = \infty$ for some $j$.  Then we may find
a sequence of $\sigma$-bounded Borel sets $B_n$ such that
$\overline{\mu}(B_n) \geq n$.  Since $B_n \subset \cup_{i=1}^\infty
A_i$ we also see that $\mu(\cup_{i=1}^\infty A_i) = \infty$.  Thus we
may now assume that $\mu(A_i) < \infty$ for all $i$.  Let $\epsilon >
0$ be given and for each $i$ find a $\sigma$-bounded Borel set $B_i$
such that $B_i \subset A_i$ and $\overline{\mu}(B_i) \geq \mu(A_i) -
\epsilon/2^i$.  For each $n$ define $C_n = \cup_{j=1}^n B_j$ and note
that $C_n$ is a $\sigma$-bounded Borel set such that $C_n \subset
\cup_{i=1}^\infty A_i$.  Also, for every $n$, 
\begin{align*}
\mu(\cup_{i=1}^\infty A_i) \geq \mu(C_n) = \overline{\mu}(C_n) =
\sum_{j=1}^n \overline{\mu}(B_j) \geq \sum_{j=1}^n \mu(A_j)  -
\epsilon/2^j \geq \sum_{j=1}^n \mu(A_j)  -\epsilon
\end{align*}
Now take the limit as $n \to \infty$ and using the fact that $\epsilon
> 0$ was arbitrary, we get $\sum_{j=1}^\infty \mu(A_j) \leq \mu(\cup_{j=1}^\infty A_j)$.

Claim: $\mu$ is a Radon measure.

The fact that $\mu(K) < \infty$ for all compact sets follows from the
fact that $\mu$ and $\overline{\mu}$ agree on $\sigma$-bounded sets
and the fact that $\overline{\mu}(K) < \infty$.  To see inner
regularity, let $A$ be a Borel set and let $\epsilon > 0$ be given.
By the definition of $\mu$ we find a $\sigma$-bounded Borel set $B
\subset A$ such that $\overline{\mu}(B) \geq \mu(A) - \epsilon/2$.  Then by
the fact that $\overline{\mu}$ is inner regular on $\sigma$-bounded
sets we find a compact set $K$ such that $\overline{\mu}(K) \geq
\overline{\mu}(B) - \epsilon/2$.  Combining the two inequalities and
using the fact that $\mu$ and $\overline{\mu}$ agree on compact sets
we get $\mu(K) \geq \mu(A) - \epsilon$.  Since $\epsilon > 0$ was
arbitrary we are done.
\end{proof}

Given a Radon measure on a locally compact Hausdorff space, all
compactly supported continuous functions are integrable: $\int \abs{f}
\, d\mu \leq \norm{f}_\infty \mu(supp(f)) < \infty$.  Thus such a
measure yields a linear functional on $C_c(X)$.  Such functionals
share another simple property.
\begin{defn}A linear functional $\Lambda$ on $C_c(X)$ is said to be
  \emph{positive} if $f \geq 0$ implies $\Lambda(f) \geq 0$.
\end{defn}

It is clear that the linear functional defined by integration with
respect to a Radon measure is positive.  The Riesz-Markov Theorem
tells us that the positive linear functionals are precisely those
generated by integration with respect to a Radon measure.  To prove
the result we will need to figure out how to define a measure from a
positive linear functional.  As a warm up let's first answer that
question in the case of integration with respect to a Radon measure.

\begin{lem}\label{RieszMarkovUniquenessOnOpen}Let $X$ be a locally compact Hausdorff space and let $\mu$
  be a Radon measure on $X$, then for every open set $U$ we have
\begin{align*}
\mu(U) &= \sup \lbrace \int f \, d\mu \mid 0 \leq f \leq 1, f \in
C_c(X), supp(f) \subset U \rbrace
\end{align*}
\end{lem}
\begin{proof}
For the inequality $\geq$, suppose that $f \in C_c(X)$ satisfies $0
\leq f \leq 1$ and $supp(f) \subset U$, then observe the hypotheses
imply that $f \leq \characteristic{U}$ so that
\begin{align*}
\int f(x) \, d\mu(x) &\leq \int \characteristic{U}(x) \, d\mu(x) = \mu(U)
\end{align*}
and the inequality follows by taking the supremum over all such $f$.

For the inequality $\leq$ we leverage the inner regularity of $\mu$.
Let $K \subset U$ be a compact set.  By Lemma
\ref{BoundedNeighborhoodsOfCompactSets} we find an relatively compact
open set $V$ with $K \subset V \subset \overline{V} \subset U$.  Since
$\overline{V}$ is a compact Hausdorff space, it is normal and we may
apply the Tietze Extension Theorem \ref{TietzeExtensionTheorem} to
find a continuous function $g : \overline{V} \to [0,1]$ such that $g
\equiv 1$ on $K$.  Applying Urysohn's Lemma \ref{UrysohnsLemma} we
construct a continuous function $h : X \to [0,1]$ such that $h = 1$ on
$K$ and $h=0$ on $V^c$.  We define
\begin{align*}
f(x) &= \begin{cases}
h(x) g(x) & \text{if $x \in \overline{V}$} \\
0 & \text{if $x \notin \overline{V}$}
\end{cases}
\end{align*}
By the corresponding properties of $g$ and $h$, it is clear that $0 \leq f \leq 1$ and that $f=1$ on $K$.  We claim that $f$ is continuous on all of $X$.  Since $h$ restricts to a continuous function
on $\overline{V}$ it is clear that the restriction of $f$ to
$\overline{V}$ is continuous.  Let $O \subset \reals$ be an open
set.  If $0 \notin O$ then it follows that $f^{-1}(O) \subset V$ and
is therefore open by the continuity of $f$ restricted to $V$.  If on
the other hand, $0 \in O$ then $f^{-1}(O) \cap \overline{V}$ is open
in $\overline{V}$ hence is of the form $Z \cap \overline{V}$ for some
open subset $Z \subset X$.  Because $0 \in O$ if follows that $Z
\subset f^{-1}(O)$ and therefore by the definition of $f$ we we may
write $f^{-1}(O) = Z \cup \overline{V}^c$ which is an open set.

TODO: This is a locally compact Hausdorff version of Tietze, factor it
out into a separate result.

With the extension $f$ in hand we see that 
\begin{align*}
\mu(K) &\leq \int f(x) \, d\mu(x) \leq \sup \lbrace \int f \, d\mu \mid 0 \leq f \leq 1, f \in
C_c(X), supp(f) \subset U \rbrace
\end{align*}
Now taking the supremum over all compact subsets $K \subset U$ and
using the inner regularity of $\mu$ the result follows.
\end{proof}


Before we state an prove the Riesz-Markov theorem we need the
existence of finite partitions of unity on compact sets in an LCH: a standard
bit of general topology.

\begin{lem}\label{PartitionOfUnity}Let $X$ be a locally compact Hausdorff space, $K$ be a
  compact subset of $X$ and $\lbrace U_\alpha \rbrace$ an open
  covering of $K$.  There exists a finite subset $\alpha_1, \dotsc,
  \alpha_n$ and continuous functions with compact support $f_{\alpha_1}, \dotsc,
  f_{\alpha_n}$ such that $supp(f_{\alpha_j}) \subset U_{\alpha_j}$
  and $f_{\alpha_1} + \dotsb + f_{\alpha_n} = 1$ on $K$.
\end{lem}
\begin{proof}
Pick an $x \in K$, pick an $U_{\alpha_x}$ such that $x \in U_{\alpha_x}$ and
using complete regularity of $X$, construct a continuous function
$g_x$ from $X$ to $[0,1]$ such that $g_x(x) = 1$ and
$g_x \equiv 0$ on $U_{\alpha_x}^c$.  Thus $g_x^{-1}(0,1] \subset
U_{\alpha_x}$ and the $g_x^{-1}(0,1]$ form an open cover of $K$.  By
compactness of $K$ we extract a finite subcover $g_{x_1}^{-1}(0,1],
\dotsc, g_{x_n}^{-1}(0,1]$.  If we clean up notation by denoting $U_{\alpha_{x_j}} =
U_{\alpha_j}$ and $g_{\alpha_j} = g_{\alpha_{x_j}}$, it follows that
$U_{\alpha_1}, \dotsc, U_{\alpha_n}$ is an open cover of $K$ and $g =
\sum_{j=1}^n g_{\alpha_j}$ is strictly positive on $K$.  Moreover by
compactness of $K$ we know that $g$ has a minimum value $C > 0$ on
$K$.  Define $h = g \vee C$ so that $h$ is continuous, $h = g$ on $K$ and $h
\geq C > 0$ everywhere on $X$.  By continuity and strict positivity of
$h$ we can define $f_{\alpha_j} = g_{\alpha_j}/h$ so that
$f_{\alpha_j}$ is continuous and moreover $f_{\alpha_1} + \dotsb +
f_{\alpha_n} = g/h = 1$ on $K$.
\end{proof}

\begin{thm}[Riesz-Markov Theorem]\label{RieszMarkov}Let $X$ be a
  locally compact Hausdorff space and let $\Lambda : C_c(X) \to
  \reals$ be a positive linear functional then there exists a unique
  Radon measure $\mu$ such that $\Lambda(f) = \int f \, d\mu$ for all
  $f \in C_c(X)$.
\end{thm}
\begin{proof}
The uniqueness part of the result is straightforward.  By Lemma
\ref{RieszMarkovUniquenessOnOpen} we know that the values of $\mu$ on open sets
are determined by $\Lambda$.  By Lemma
\ref{InnerOuterRegularityEquivalence} we conclude that the values of
$\mu$ on $\sigma$-bounded Borel sets are determined by $\Lambda$, in
particular the values on compact sets are determined by $\Lambda$.
The inner regularity of $\mu$ implies that the values on all Borel
sets are determined by $\Lambda$.

For existence we follow the lead of Lemma
\ref{RieszMarkovUniquenessOnOpen} and define the set function on the
open sets of $X$
\begin{align*}
m(U) &=  \sup \lbrace \Lambda( f ) \mid 0 \leq f \leq 1, f \in C_c(X), supp(f) \subset U \rbrace
\end{align*}
We proceed by showing that $m(U)$ satisfies properties (i) through (v)
from Lemma \ref{ExtensionToRadonMeasure} and that if $\mu$ is the
Radon measure constructed by that result that we indeed have
$\Lambda(f) = \int f \, d\mu$.

Claim: $m$ satisfies (i)

Let $U$ be a relatively compact open set.  By Lemma
\ref{BoundedNeighborhoodsOfCompactSets} we can find another relatively
compact open set $V$ such that $\overline{U} \subset V$.  By the
Tietze Extension Theorem argument of Lemma \ref{ExtensionToRadonMeasure} we can find a continuous function $g: X \to
[0,1]$ such that $g = 1$ on $\overline{U}$ and $g = 0$ on $V^c$.
Since $g \in C_c(X)$ we have $\Lambda(g) < \infty$.  Now suppose that
$f \in C_c(X)$ satisfies $0 \leq f \leq 1$ and  $f \in C_c(X), supp(f)
\subset U$.  It follows that $0 \leq f \leq g$ and linearity and
positivity of $\Lambda$ we know that $\Lambda(f) \leq \Lambda(g)$.
Taking the supremum over all such $f$ we get
\begin{align*}
m(U) &= \sup \lbrace \Lambda( f ) \mid 0 \leq f \leq 1, f \in C_c(X),
supp(f) \subset U \rbrace \leq \Lambda(g) < \infty
\end{align*}

Claim: $m$ satsifies (ii)

This is immediate since $U \subset V$ implies 
\begin{align*}
\lbrace \Lambda( f ) \mid 0 \leq f \leq 1, f \in C_c(X),
supp(f) \subset U \rbrace \subset \lbrace \Lambda( f ) \mid 0 \leq f \leq 1, f \in C_c(X),
supp(f) \subset V \rbrace
\end{align*}

Claim: $m$ satisfies (iii)

Let $U_1, U_2, \dotsc$ be open sets and let $f \in C_c(X)$ satisfy $0
\leq f \leq 1$ and $supp(f) \subset \cup_{n=1}^\infty U_n$.  By
compactness of $supp(f)$ and Lemma
\ref{PartitionOfUnity} we may find an $N$ and continuous functions
$g_i$ for $i=1, \dotsc, N$ such that $0 \leq g_i \leq 1$, $supp(g_i) \subset U_i$ and
$\sum_{i=1}^N g_i = 1$ on $supp(f)$ and therefore $f = f \cdot
\sum_{i=1}^N g_i$.  It also follows that $0 \leq f g_i
\leq 1$ and $supp(f g_i) \subset U_i$ for $i=1, \dotsc, N$ and thus
\begin{align*}
\Lambda(f) &= \sum_{i=1}^N \Lambda( f g_i) \leq \sum_{i=1}^N m(U_i)
\leq \sum_{i=1}^\infty m(U_i)
\end{align*}
Now we take the supremum over all such $f$ to conclude that
$m(\cup_{i=1}^\infty U_i) \leq \sum_{i=1}^\infty m(U_i)$.

Claim: $m$ satisfies (iv)

Suppose $U$ and $V$ are disjoint open sets.  We only need to show that
$m(U \cup V) \geq m(U) + m(V)$ since the opposite inequality follows
from (iii).  Let $f, g \in C_c(X)$ such that $0 \leq f,g \leq 1$,
$supp(f) \subset U$ and $supp(g) \subset V$.  By disjointness of $U$
and $V$ it follows that $f+g \in C_c(X)$, $0 \leq f+g \leq 1$ and
$supp(f+g) \subset supp(f) \cup supp(g) \subset U \cup V$.  Therefore
\begin{align*}
\Lambda(f) + \Lambda(g) &= \Lambda(f+g) \leq m(U \cup V)
\end{align*}
Now take the supremum over all $f$ and $g$ to get the result.

Claim: $m$ satisfies (v)

Let $U$ be an open set and let $f \in C_c(X)$ such that $0 \leq f \leq
1$ and $supp(f) \subset U$.  By compactness of $supp(f)$ and Lemma
\ref{BoundedNeighborhoodsOfCompactSets} we may find a relatively
compact open set $V$ such that 
$supp(f) \subset V \subset \overline{V} \subset U$.  
It follows that 
\begin{align*}
\Lambda(f) &\leq m(V) \leq \sup \lbrace m(V) \mid V \text{ is open, } \overline{V} \subset U \text{ and }
  \overline{V} \text{ is compact} \rbrace
\end{align*}
Now take the supremum over all such $f$.

We may now apply Lemma \ref{ExtensionToRadonMeasure} to construct a
Radon measure $\mu$ such that $\mu(U) = m(U)$.  We need to show that
for every $f \in C_c(X)$ we have $\Lambda(f) = \int f \, d\mu$. By
linearity we know that $\Lambda(0) = \int 0 \, d\mu = 0$ so we may
assume that $f \neq 0$.  We may write $f = f_+
- f_-$ with $f_+ = f \vee 0 \in C_c(X)$ and $f_- = (-f) \vee 0 \in
C_c(X)$.  Since both $\Lambda$ and the integral are linear it suffices
to show the result for $f \geq 0$.  Since $f$ is continuous with
compact support, it follows that $f$ is bounded and since $f \neq 0$
we have $0 < \norm{f}_\infty < \infty$.  Again, by linearity of
$\Lambda$ and integration it suffices to prove the result of
$f/\norm{f}_\infty$ and thus we may assume that $0 \leq f \leq 1$.

We proceed by constructing a generalized upper and lower sum
approximation to the integral of $f$.  Once again apply Lemma
\ref{BoundedNeighborhoodsOfCompactSets} to find a relatively compact
open neighborhood $U_0$ with $supp(f) \subset U_0$.  Let $\epsilon >
0$ be given and choose $n \in \naturals$ such that $\mu(U_0) <
\epsilon n$.  For $j=1, \dotsc, n$ define $U_j = f^{-1} (j/n,
\infty)$.  Because $f$ is continuous and of compact support, each
$U_j$ is a relatively compact open set and it is trivial from the
definitions that we have $\emptyset = U_n \subset U_{n-1} \subset \dotsb \subset
U_0$.  In fact by the continuity of $f$ it is also true that $\overline{U}_j \subset U_{j+1}$.
Define the lower and upper approximations to $f$
\begin{align*}
u(x) &= \begin{cases}
\frac{j}{n} & \text{if $x \in U_j \setminus U_{j+1}$ for some $j=1, \dotsc,  n-1$} \\
0 & \text{if $x \notin U_1$}
\end{cases}
\end{align*}
 and similarly 
\begin{align*}
v(x) &= \begin{cases}
\frac{j}{n} & \text{if $x \in U_{j-1} \setminus U_{j}$ for some
  $j=1,  \dotsc,  n$} \\
0 & \text{if $x \notin U_0$}
\end{cases}
\end{align*}
Note that we have the property that $u \leq f \leq v$ and moreover we
have the useful alternative defintion of $u$ and $v$
\begin{align*}
u(x) &= \frac{1}{n} \sum_{j=1}^n \characteristic{U_j}(x) \\
v(x) &= \frac{1}{n} \sum_{j=1}^{n} \characteristic{U_{j-1}}(x) \\
\end{align*}
which shows that $u,v \in C_c(X)$.

Claim: $\int (v -u) \, d\mu < \epsilon$

This follows by observing that $v - u = \frac{1}{n}
(\characteristic{U_0} - \characteristic{U_n}) = \frac{1}{n}
\characteristic{U_0}$ since $U_n = \emptyset$.

Claim: $\int u \, d\mu \leq \Lambda(f) \leq \int v \, d\mu + \epsilon$

To see this claim we decompose $f$ into a representation that is
adapted to the nested sequence $U_n \subset \dotsb \subset U_0$.  For
$j=1, \dotsc, n$ define 
\begin{align*}
\phi_j(x) &= \begin{cases}
1/n & \text{if $x \in U_j$} \\
f(x) - \frac{j-1}{n} & \text{if $x \in U_{j-1} \setminus U_{j}$} \\
0 & \text{if $x \notin U_{j-1}$}
\end{cases} \\
&=[(f(x) - \frac{j-1}{n}) \vee 0] \wedge \frac{1}{n}\\
\end{align*}
where the second representation shows that $\phi_j \in C_c(X)$ and $0 \leq \phi_j \leq \frac{1}{n}$.
Note also
that if we are given $x \in U_{j-1} \setminus U_j$ for some $j=1,
\dotsc, n$ then $\phi_i(x) = 0$ for $j < i \leq n$ and $\phi_i(x) =
\frac{1}{n}$ for $1 \leq i < j$.  Therefore we have 
\begin{align*}
\phi_1(x) + \dotsb + \phi_n(x) &= \phi_1(x) + \dotsb + \phi_j(x) \\
&= \frac{j-1}{n} + f(x) - \frac{j-1}{n} = f(x)
\end{align*}
It is clear that for $x \notin U_0$ we have $f(x) = 0$ and
$\phi_j(x) = 0$ for all $j=1, \dotsc, n$ so we have
 $f = \phi_1 + \dotsb + \phi_n$ on all of $X$.

We now need to bound $\Lambda(\phi_j)$ in terms of $\mu(U_k) = m(U_k)$ for
suitable $k=1, \dotsc, n$.  First we get a lower bound on
$\Lambda(\phi_j)$.  Let $1 \leq j \leq n$ be given.  Suppose that we have a $g \in C_c(X)$ with
$0 \leq g \leq 1$ and $supp(g) \subset U_j$.  Then by positivity of
$\phi_j$ and the fact that $\phi_j(x) = \frac{1}{n}$ on $U_j$ we see
that $g \leq \characteristic{U_j} \leq n \phi_j$ and therefore
$\Lambda(g) \leq n \Lambda(\phi_j)$.    Taking the supremum over all
such $g$ we see that $\frac{1}{n} \mu(U_j) \leq \Lambda(\phi_j)$.  Taking the
sum over all $j=1, \dotsc, n$ and using linearity of $\Lambda$ we get
\begin{align*}
\int u \, d\mu &= \frac{1}{n} \sum_{j=1}^n \mu(U_j) \leq \sum_{j=1}^n
\Lambda(\phi_j) = \Lambda(f)
\end{align*}

Now we get an upper bound on $\Lambda(\phi_j)$.   For $j=2, \dotsc, n$ we that
$n phi_j \in C_c(X)$, $0 \leq n \phi_j \leq 1$ and $supp(n \phi_j)
\subset \overline{U_{j-1}} \subset U_{j-2}$.  From the definition of
$\mu(U_{j-2}) =m(U_{j-2})$ it follows that $\Lambda(\phi_j) \leq
\frac{1}{n} \mu(U_{j-2})$.  As for $\phi_1$, we have
$n \phi_1 \in C_c(X)$ and $0 \leq n\phi_1 \leq 1$ by exactly the same
argument as for $j \geq 2$.  We also have $supp(n \phi_1) \subset
supp(f) \subset U_0$ so that $\Lambda(\phi_1) \leq \frac{1}{n}
\mu(U_0)$.  If we define $U_{-1} = U_0$ the we get
have $\Lambda(\phi_j) \leq \frac{1}{n} \Lambda(U_{j-2})$ for $j=1,
\dotsc, n$.  Again we sum and use linearity of $\Lambda$,
\begin{align*}
\Lambda(f) &= \sum_{j=1}^n \Lambda(\phi_j) \leq \frac{1}{n}
\sum_{j=1}^n \mu(U_{j-2}) = \frac{1}{n} \mu(U_{-1}) +  \frac{1}{n}
\sum_{j=1}^{n-1} \mu(U_{j-1}) \\
&\leq \frac{1}{n} \mu(U_{0}) +  \frac{1}{n}
\sum_{j=1}^{n} \mu(U_{j-1}) \leq \epsilon + \int v \, d\mu
\end{align*}

It remains to stitch together the previous claims to
show that $\Lambda(f) = \int f \, d\mu$.  Integrating the inequality
$u \leq f \leq v$ we get $\int u \, d\mu \leq f \leq \int v \, d\mu$.
Now using this fact and previous two claims we get
\begin{align*}
\Lambda(f) - \int f \, d\mu &\leq \Lambda(f) - \int v \, d\mu \leq
\int u \, d\mu  - \int u \, d\mu + \epsilon \leq 2 \epsilon
\end{align*}
and
\begin{align*}
\Lambda(f) - \int f \, d\mu &\geq \int u \, d\mu - \int f \, d\mu \geq
\int u \, d\mu - \int v \, d\mu \geq -\epsilon
\end{align*}
from which we conclude that $\abs{\Lambda(f) - \int f \, d\mu} \leq
2\epsilon$.  Since $\epsilon > 0$ was arbitrary we are done.
\end{proof}

\begin{defn}Let $\mu$ be a measure on the Borel $\sigma$-algebra of a
Hausdorff topological space $S$.  
\begin{itemize}
\item[(i)] A Borel set $B$ is \emph{inner regular} if for
 $\mu(B) = \sup_{K \subset B} \mu(K)$ where $K$
  is compact. $\mu$ is inner regular if every Borel set is inner regular.
\item[(ii)]A Borel set $B$ is \emph{outer regular} if $\mu(B) = \inf_{U \supset B} \mu(U)$ where $U$
  is open.  A measure $\mu$ is outer regular if every Borel set
  $B$ is outer regular.
\item[(iii)] $\mu$ is \emph{locally finite} if every $x \in S$ has an
  open neighborhood $x \in U$ such that $\mu(U) < \infty$.
\item[(iv)] $\mu$ is a \emph{Radon measure} it is inner regular and
  locally finite.
\item[(v)] $\mu$ is a \emph{Borel measure} when?????  In some cases
  I've seen it required that $\mu(B) < \infty$ for all Borel sets $B$
  (reference?) and in other cases just that the Borel sets are measurable.
\item[(vi)]A Borel set  $B$ is \emph{closed regular} if $\mu(B) = \inf_{F \subset B} \mu(F)$ where $F$
  is closed (e.g. Dudley pg. 224).  A measure $\mu$ is closed regular
  if every Borel set $B$ is closed regular.
\item[(vii)] If $\mu$ is finite, then we say \emph{tight} if and only if
  X is inner regular (e.g. Dudley pg. 224).
\end{itemize}
\end{defn}

\begin{prop}Let $\mu$ be a measure on the Borel $\sigma$-algebra of a
  locally compact Hausdorff space $S$.  Then $\mu$ is locally finite
  if and only if $\mu(K) < \infty$ for all compact sets $K \subset S$.
\end{prop}
\begin{proof}
If $\mu(K) < \infty$ for all compact sets $K$ we let $x \in S$ and
pick a relatively compact neighborhood $U$ of $x$.  Then $\mu(U) \leq
\mu(\overline{U}) < \infty$ which shows $\mu$ is locally finite.  On
the other hand, suppose $\mu$ is locally finite and let $K$ be a
compact set.  For each $x \in K$ we take an open neighborhood $U_x$
such that $\mu(U_x) < \infty$ and then extract a finite subcover $U_{x_1},
\dotsc,U_{x_n}$.  By subadditivity, we have $\mu(K) \leq \mu(U_{x_1}) + \dotsb
+ \mu(U_{x_n}) < \infty$.
\end{proof}

\begin{defn}Let $\mu$ be a Borel measure on a Hausdorff topological space. A set measurable set $A$ is called \emph{regular} if 
\begin{itemize}
\item[(i)]$\mu(A) = \inf_{U \supset A} \mu(A)$ where $U$ are open
\item[(ii)]$\mu(A) = \sup_{F \subset A} \mu(A)$ where $F$ are closed 
\end{itemize}
TODO: Alternative def assumes that $F$ are compact (see inner
regularity above).  If every measurable set is regular then $\mu$ is
said to be regular.  Note that if we assume the definition of
regularity uses compact inner approximations then regular measures are
inner and outer regular (although inner and outer regularity refer to
only Borel sets; is that a meaningful distinction?)  I think this use
of closed inner regularity is a bit non-standard should probably get
rid of it.
\end{defn}


TODO: Regularity of outer measures and the relationship to regularity
of measures as defined above (see Evans and Gariepy).  Note that
regularity of outer measure implies that if we take an outer measure $\mu$
and the measure on the $\mu$-measurable sets and then take the induced
outer measure we get $\mu$ back if and only $\mu$ is a regular outer
measure.  Evans and Gariepy show that Radon outer measures on
$\reals^n$ are inner
regular as measures on the $\mu$-measurable sets (I think we prove this more
generally above in the context of LCH spaces; note that every set in
$\reals^n$ is $\sigma$-bounded).  Note that inner
regular is part of the most common definition of Radon measure so
their result can be taken as showing a weaker definition of Radon
measure holds on $\reals^n$ (but also they phrase everything in terms
of outer measures...).

TODO: How much this stuff on regularity can be extended to outer
measures????  I want to understand the overlap with the results in
Evans and Gariepy.

\begin{lem}\label{InnerRegularSetsSigmaAlgebra}Let $X$ be a Hausdorff topological space, $\mathcal{A}$
  a $\sigma$-algebra on $X$ and $\mu$ a finite tight measure.  Then
\begin{align*}
\mathcal{R} &= \lbrace A \in \mathcal{A} \mid A \text { and } A^c
\text{ are $\mu$-inner regular} \rbrace
\end{align*}
is a $\sigma$-algebra.  The same is true if the condition is replaced
by sets that are $\mu$-closed inner regular (without the requirement
that $\mu$ is tight).
\end{lem}
\begin{proof}
By definition, $\mathcal{R}$ is closed under complement.  By
assumption that $\mu$ is tight we have $X \in \mathcal{R}$ so all that
needs to be shown is closure under countable union.

Assume $A_1, A_2, \dots \in \mathcal{R}$ and let $\epsilon>0$ be
given.  By finiteness of $\mu$, $\mu(\cup_{n=1}^\infty A_n) < \infty$ and
continuity of measure (Lemma \ref{ContinuityOfMeasure}) there exists $M>0$ such that $\mu(\cup_{n=1}^M
A_n) > \mu(\cup_{n=1}^\infty A_n) - \epsilon$.
 By assumption that $A_n \in \mathcal{R}$ and finiteness of $\mu$, for each
$A_n$ there exists a compact $K_n$ such that $\mu(A_n \setminus K_n) <
\frac{\epsilon}{2^n}$ and there exists compact $L_n$ such that $\mu(A_n^c \setminus L_n) <
\frac{\epsilon}{2^n}$. Let
\begin{align*}
K &= \cup_{n=1}^M K_n \\
L &= \cap_{n=1}^\infty L_n
\end{align*}
and note that both $K$ and $L$ are compact (in the latter case,
because X is Hausdorff we know that each $L$ is closed hence the
intersection is a closed subset of a compact set hence compact).
Furthermore we can compute
\begin{align*}
\mu(\cup_{n=1}^\infty A_n \setminus K) &= \mu(\cup_{n=1}^\infty A_n
\setminus \cup_{n=1}^M K_n)  \\
&= \mu(\cup_{n=1}^M A_n
\setminus \cup_{n=1}^M K_n)  + \mu(\cup_{n=1}^\infty A_n \setminus \cup_{n=1}^M A_n
\setminus \cup_{n=1}^M K_n)\\
&\leq \mu(\cup_{n=1}^M A_n \setminus K_n)  + \mu(\cup_{n=1}^\infty A_n
\setminus \cup_{n=1}^M A_n)\\
&\leq \sum_{n=1}^M(A_n \setminus K_n)  + \epsilon \\
&\leq 3 \epsilon
\end{align*}
and
\begin{align*}
\mu((\cup_{n=1}^\infty A_n)^c \setminus L) &=\mu(\cap_{n=1}^\infty
A_n^c \setminus \cap_{n=1}^\infty L_n) \\
 &=\mu(\cap_{n=1}^\infty
A_n^c \cap \cup_{n=1}^\infty L_n^c) \\
 &=\mu(\cup_{n=1}^\infty \cap_{m=1}^\infty
A_m^c \cap L_n^c) \\
 &\leq \mu(\cup_{n=1}^\infty 
A_n^c \cap L_n^c) \\
 &\leq \sum_{n=1}^\infty (
A_n^c \setminus L_n) \\
&\leq 2 \epsilon
\end{align*}

TODO: The closed inner regular case...
\end{proof}

TODO:  In metric space, tightness is equivalent to inner regularity.
Then Ulam's Theorem that finite measures on separable metric spaces
are automatically inner regular.  Also finite measures on arbitrary
metric spaces are closed inner regular as well as outer regular.

\begin{lem}\label{FiniteMeasuresOnMetricSpacesAreClosedInnerRegular}
Let $(S,d)$ be a metric space and $\mu$ be a Borel measure on $(S,
\mathcal{B}(S))$, then $\mu$ is closed inner regular.  If in addition
$\mu$ is a finite measure then it is outer regular.
\end{lem}
\begin{proof}
Let $U$ be an open set in $S$.  Then $U^c$ is closed and the
function $f(x) = d(x, U^c)$ is continuous.  If we define 
\begin{align*}
F_n &= f^{-1}([1/n, \infty))
\end{align*}
then each $F_n$ is closed, $F_1 \subset F_2 \subset \cdots$ and
$\cup_{n=1}^\infty F_n = U$.  By continuity of measure (Lemma
\ref{ContinuityOfMeasure}) we know that $\lim_{n \to \infty} \mu(F_n)
= \mu(U)$.  So this shows that every open set is inner closed
regular.  Furthermore it is trivial to note that $U^c$ is inner closed
regular because it is closed.  

By Lemma \ref{InnerRegularSetsSigmaAlgebra} we know know that 
\begin{align*}
\mathcal{B}(S) &\subset \mathcal{R} = \lbrace A \subset S \mid A
\text{ and } A^c
\text{ are inner closed regular}  \rbrace
\end{align*}

Outer regularity follows from taking complements and using the
finiteness of $\mu$.
\end{proof}

If we add the criterion that the metric space is separable, then we
can upgrade the closed inner regularity to inner regularity.
\begin{lem}\label{SeparableInnerRegularTight}Let $(S,d)$ be a
  separable metric space and $\mu$ be a finite Borel measure on $(S,
\mathcal{B}(S))$, then $\mu$ is inner regular if and only if it is tight.
\end{lem}
\begin{proof}
Clearly inner regularity implies tightness (which is just inner
regularity of the set $S$), so it suffices to show
that tightness implies inner regularity.

Suppose that $\mu$ is a tight measure.  By Lemma
\ref{InnerRegularSetsSigmaAlgebra} it suffices to show that both open
and closed sets are inner regular.

Pick $\epsilon >0$ and select $K \subset S$ a compact set such that $\mu(S \setminus K) < \frac{\epsilon}{2}$.
By Lemma \ref{FiniteMeasuresOnMetricSpacesAreClosedInnerRegular} we
know that for any Borel set $B$ there exists a closed set $F \subset
B$ such that $\mu(B \setminus F) < \frac{\epsilon}{2}$.  Note that $F
\cap K$ is compact.   We have
\begin{align*}
\mu(B \setminus (F \cap K)) &\leq \mu(B \cap F^c) + \mu(B \cap K^c) \leq \mu(B \cap F^c) + \mu(S \cap K^c) < \epsilon
\end{align*}
\end{proof}
\begin{thm}[Ulam's Theorem]\label{UlamsTheorem}Let $(S,d)$ be a
  complete separable metric space and $\mu$ be a finite Borel measure on $(S,
\mathcal{B}(S))$, then $\mu$ is inner regular.
\end{thm}
\begin{proof}
By Lemma \ref{SeparableInnerRegularTight} it suffices to show that $\mu$ is tight.  Pick
$\epsilon > 0$ and we construct a compact set $K \subset S$ such that
$\mu(S \setminus K) < \epsilon$.  Let
$\overline{B}(x,r)$ denote the closed ball of radius $r$ around $x \in
S$.  Pick
a countable dense subset $x_1, x_2, \dotsc \in S$.  For each $m \in
\naturals$, by density of $\lbrace x_n \rbrace$, we know $\cap_{n=1}^\infty \left ( S
\setminus \cup_{j=1}^n \overline{B}(x_j, \frac{1}{m}) \right ) =
\emptyset$, thus by
continuity of measure (Lemma \ref{ContinuityOfMeasure}) there exists
$N_m > 0$ such that $\mu(S
\setminus \cup_{j=1}^n \overline{B}(x_j, \frac{1}{m}) < \frac{\epsilon}{2^m}$ for
all $n \geq N_m$.
If we define
\begin{align*}
K &= \cap_{m=1}^\infty \cup_{j=1}^{N_m} \overline{B}(x_j, \frac{1}{m})
\end{align*}
we claim that $K$ is compact.  Note that $K$ is easily seen to be
closed as it is an intersection of a finite union of closed balls.
Since $S$ is complete this implies that $K$ is also complete.  Also it
is easy to see that $K$ is totally bounded since by construction we
have demonstrated a cover by a finite number of balls of radius
$\frac{1}{m}$ for each $m \in \naturals$.  So by Theorem
\ref{CompactnessInMetricSpaces} we know $K$ is compact.

To finish the result we claim $\mu(S \setminus K) < \epsilon$:
\begin{align*}
\mu(S \setminus K) 
&= \mu(S \cap \left(\cap_{m=1}^\infty
  \cup_{j=1}^{N_m} \overline{B}(x_j, \frac{1}{m})\right)^c) \\
&= \mu(S \cap \cup_{m=1}^\infty \left(
  \cup_{j=1}^{N_m} \overline{B}(x_j, \frac{1}{m})\right)^c) \\
&= \mu(\cup_{m=1}^\infty S \setminus 
  \cup_{j=1}^{N_m} \overline{B}(x_j, \frac{1}{m})) \\
&\leq \sum_{m=1}^\infty \mu( S \setminus 
  \cup_{j=1}^{N_m} \overline{B}(x_j, \frac{1}{m})) \\
&< \epsilon
\end{align*}
\end{proof}

\begin{thm}Let $\mu$ be a finite Borel measure on a metric space $S$,
  then $\mu$ is closed regular.  If $\mu$ is tight then $\mu$ is regular.
\end{thm}
TODO: Specialize the definition of Radon measure in the presence of
more assumptions on $X$ (in particular local compactness,
$\sigma$-compactness, second countability).

TODO: Are Radon measures automatically outer regular?

Tao proves Riesz representation under assumption of local compactness
and $\sigma$-compactness.

Kallenberg proves Riesz representation under assumption of LCH and second countability (this is more general than the Tao
result as $\sigma$-compactness implies second countability (I think))
and targets Radon measures.  Our results taken from Arveson are more
general as the remove the second countability assumption.

Evans and Gareipy prove Riesz representation only on $\reals^n$ using
Radon outer measures.  This is probably subsumed by our results taken
from Arveson but I need to understand whether the use of outer
measures adds anything to the picture.

Arveson has some well known lecture notes that prove Riesz on general
LCH spaces
and emphasizes Radon measures (it also explores how Baire measures figure in the
picture).  I have chosen to follow these notes.

Fremlin probably has some very general account of Reisz representation
(of course).

Dudley proves Riesz representation of compact Hausdorff spaces and
phrases things in terms of Baire measures.  Dudley does not really
discuss Radon measures.  Arveson discusses the relationship between
the use of Baire and Radon measures.

\section{Covering Theorems in $\reals^n$}

Since our purposes have been to understand probability theory we have
hitherto avoided making assumptions that we are dealing with
$\reals^n$.  While this decision has benefits, it has drawbacks as
well.  Among those drawbacks are that we lose sight of some history and also some very
beautiful and deep understanding of the measure theory of the reals.
TODO: Vitali and Besicovich.

\section{Hausdorff Measure}

\subsection{Introduction}

In this section we discuss the construction of a family of outer
measures on $\reals^n$ called \emph{Hausdorff measures}.  Note the
construction can be generalized to metric spaces.  The following is
motivation why a tool like Hausdorff measure may be useful.  Suppose
very specifically that we are
in $\reals^3$, then the Lebesgue product measure essentially
corresponds to a notion of volume.  What about the surface area of a
$2$-dimensional object or the length of a $1$-dimensional object?  As
you may have learned in advanced calculus these ideas can indeed be
describe in great generality by the notion of differential forms.
However, the formalism of forms usually has some notion of smoothness
associated with it (hence the adjective differential); a natural question to ask is whether one can fine
a purely measure theoretic approach to the problem.  Hausdorff measures
provide one answer to this question.   The broad form of the theory
is perhaps a bit more general than one might expect; for any space
there is a Hausdorff outer measure for every real number $s$.  The
case of integers
$s=1$ corresponds to arclength, $s=2$ surface area, $s=3$ volume and so
on.  Measures with $s$ non-integral are
\emph{fractal}.  On $\reals^n$, the Hausdorff measure with $s=n$ is equal to
Lebesgue measure and any Hausdorff measure with $s > n$ is trivial
(gives $0$ measure to all sets).  We'll prove all of this and more in
what follows.

\subsection{Construction of Hausdorff Measure}

The following technical Lemma is useful (we'll use it when
discussing Hausdorff outer measures).  If the reader is in a hurry,
no harm will come from skipping over this result and returning to it
when the need arises.  Note that if the user is only interested in
probability theory this result may never come up.
\begin{lem}[Caratheodory Criterion]\label{CaratheodoryCriterion}Let $(S,d)$ be a metric space with an outer measure $\mu^*$.
  Then $\mu^*$ is a Borel outer measure (i.e. all Borel sets are
  $\mu^*$-measurable) if and only if $\mu^*(A \cup B) = \mu^*(A) +
  \mu^*(B)$ for all $A,B$ such that $d(A, B) > 0$.
\end{lem}
\begin{proof}
We begin with the only if direction.  Let $A$ be a closed set in $S$
and let $B \subset S$.  To show $A$ is $\mu^*$-measurable it suffices
to show $\mu^*(B) \geq \mu^*(A \cap B) + \mu^*(A^c \cap B)$.  Since
the inequality is trivially satisfied when $\mu^*(B) = \infty$ we
assume that $\mu^*(B) < \infty$.  For
every $n \in \naturals$, let $A_n =
\lbrace x \in S \mid d(x, A) \leq \frac{1}{n} \rbrace$.  By definition
of $A_n$, we have $d(A,
A_n^c) > \frac{1}{n} > 0$ and therefore $d(A \cap B, A_n^c \cap B)
> \frac{1}{n} > 0$.  Now by our assumption, we can conclude $\mu^*((A
\cap B) \cup (A_n^c \cap B)) = \mu^*(A \cap B) +
\mu^*(A_n^c \cap B)$.

We claim that $\lim_{n \to \infty} \mu^*(A_n^c \cap B) = \mu^*(A^c
\cap B)$.  Note that if we prove the claim the Lemma is proven because then we have
\begin{align*}
\mu^*(B) &\geq \mu^*((A
\cap B) \cup (A_n^c \cap B)) & & \text{by monotonicity}\\
&= \mu^*(A \cap B) +
\mu^*(A_n^c \cap B)
\end{align*}
and taking limits we have 
\begin{align*}
\mu^*(B) \geq \lim_{n\to \infty} \mu^*(A \cap B) +
\mu^*(A_n^c \cap B) &= \mu^*(A \cap B) +
\mu^*(A^c \cap B)
\end{align*}
To prove the claim we observe that monotonicity of outer measure
implies that $\lim_{n \to \infty} \mu^*(A_n^c \cap B) \leq \mu^*(A^c
\cap B)$ so we just need to
work on the opposite inequality.  To see it first define the rings
around $A$
\begin{align*}
R_n &= \lbrace x \mid \frac{1}{n+1} < d(x, A) \leq \frac{1}{n} \rbrace
\end{align*}
and note that because $A$ is closed, for each $n$,
\begin{align*}
A^c &= \lbrace x \in S \mid d(x, A) > 0 \rbrace \\
&=\lbrace x \in S \mid d(x, A) > n \rbrace \cup \bigcup_{m=n}^\infty \lbrace
x \in S \mid \frac{1}{m+1} < d(x, A) \leq \frac{1}{m} \rbrace \\
&=A_n^c \cup \bigcup_{m=n}^\infty R_m
\end{align*}
It follows that
$A^c \cap B = A_n^c \cap B \cup \cup_{m=n}^\infty
R_m \cap B$ and therefore by subadditivity of outer measure 
\begin{align*}
\mu^*(A^c \cap B) \leq \mu^*(A_n^c \cap B) + \sum_{m=n}^\infty
\mu^*(R_m \cap B)
\end{align*}
The claim will follow if we can show $\lim_{n \to \infty} \sum_{m=n}^\infty
\mu^*(R_m \cap B)=0$ which in turn will follow if we can show that $\sum_{m=1}^\infty
\mu^*(R_m \cap B)$ converges.  By construction, $d(R_{2m}, R_{2n})
> 0$ and therefore $d(R_{2m} \cap B, R_{2n} \cap B)
> 0$ for any $m \neq n$.  So if we consider only the even terms of the
series we can use our hypothesis to show that for any $n$
\begin{align*}
\sum_{m=1}^n \mu^*(R_{2m} \cap B) &= \mu^*(\cup_{m=1}^n
R_{2m} \cap B) \leq \mu^*(B) < \infty
\end{align*}
and by taking limits $\sum_{m=1}^\infty \mu^*(R_{2m} \cap B) \leq \mu^*(B)$
The same argument applies to the odd indexed terms and we get
\begin{align*}
\sum_{m=1}^\infty \mu^*(R_{m} \cap B) &\leq 2\mu^*(B) < \infty
\end{align*}
The claim and the Lemma follow.
\end{proof}


TODO:  Here I am taking the path of Evans and Gariepy and normalizing
Hausdorff measure so that $\mathcal{H}^n = \lambda_n$.  I am not sure
if this winds up being inconvenient when one considers Hausdorff
measure in arbitrary metric spaces (nor do I know whether we'll bother
considering Hausdorff measures in metric spaces).

\begin{lem}Let $\lambda_n$ be Lebesgue measure on $\reals^n$, then
  $\lambda_n(B(0, 1)) = \frac{\pi^{n/2}}{\Gamma(\frac{n}{2} + 1)}$.
\end{lem}
\begin{proof}
TODO
\end{proof}

\begin{defn}Let $(S,d)$ be a metric space and $A \subset S$, the
  \emph{diameter} of $A$ is 
\begin{align*}
\diam(A) &= \sup \lbrace d(x,y) \mid x,y \in A \rbrace
\end{align*}
\end{defn}

\begin{defn}Let $(S,d)$ be a metric space, $0 \leq s < \infty$ and $0
  < \delta$.  Then for $A \subset S$,
\begin{align*}
\mathcal{H}^s_\delta(A) &= \inf \lbrace \sum_{n=1}^\infty \alpha(s)
\left ( \frac{\diam(C_n)}{2}\right )^s \mid A \subset
\cup_{n=1}^\infty C_n \text{ where } \diam(C_n) \leq \delta \text{ for
  all } n\rbrace
\end{align*}
where 
\begin{align*}
\alpha(s) &= \frac{\pi^{n/2}}{\Gamma(\frac{n}{2} + 1)}
\end{align*}
For $A$ and $s$ as above define
\begin{align*}
\mathcal{H}^s(A) &= \lim_{\delta \to 0} \mathcal{H}_\delta^s(A) = \sup_{\delta>0} \mathcal{H}_\delta^s(A)
\end{align*}
\end{defn}