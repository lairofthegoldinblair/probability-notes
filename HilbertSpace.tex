\chapter{Hilbert Spaces}

\section{Basics}

\begin{defn}Let $V$ be a vector space of a field $\field$ ($\field = \reals$ or $\field = \complexes$) then an
  \emph{inner product} is a map $\langle \cdot , \cdot \rangle : V \times V \to \field$ 
satisfying the following properties
\begin{itemize}
\item[(i)]  For all $v,w \in V$, $\langle v, w \rangle = \overline{\langle w, v \rangle}$
\item[(ii)] For all $v \in V$, $\langle v,v \rangle \in \reals$, $\langle v,v \rangle \geq 0$ and $\langle v,v \rangle = 0$ if and only if $v=0$.
\item[(iii)] For all $v,w \in V$ and $c \in \field$, $\langle cv, w \rangle = \overline{c} \langle v,w \rangle$ and $ \langle v,cw \rangle = c \langle v,w \rangle$.
\item[(iv)] For all $v,w,u \in V$ $\langle v + u, w \rangle = \langle v,w \rangle + \langle u, w \rangle$ and $\langle v, w+u \rangle = \langle v,w \rangle + \langle v, u \rangle$
\end{itemize}
\end{defn}

\begin{prop}[Cauchy Schwartz Inequality]\label{hilbert:CauchySchwartz}Let $V$ be an inner product space then for every $v, w \in V$ we have
\begin{align*}
\abs{\langle v, w \rangle}^2 &\leq \langle v,v \rangle \langle w,w \rangle
\end{align*}
Moreover we have inequality if and only if there exists a constant $c \in \field$ such that $v = c w$.
\end{prop}
\begin{proof}
For the case of $\field = \reals$ just use the proof of Lemma \ref{CauchySchwartz}.  For the case of $\field = \complexes$ let $v, w \in V$.  Note that the result clearly holds when $w=0$ (both sides are $0$) so assume that $w \neq 0$ and define $c = \frac{\overline{\langle v, w \rangle}}{\langle w, w \rangle}$ and note that
\begin{align*}
0 &\leq \langle v - c w , v - c w \rangle = \langle v, v \rangle - \overline{c} \overline{\langle v, w \rangle} - c \langle v, w \rangle + \abs{c}^2 \langle w, w \rangle \\
&= \langle v, v \rangle - \frac{\abs{\langle v, w \rangle}^2}{\langle w, w \rangle} - \frac{\abs{\langle v, w \rangle}^2}{\langle w, w \rangle} + \frac{\abs{\langle v, w \rangle}^2}{\langle w, w \rangle}  \\
&=\langle v, v \rangle - \frac{\abs{\langle v, w \rangle}^2}{\langle w, w \rangle}
\end{align*}
and this shows $\abs{\langle v, w \rangle}^2 \leq \langle v,v \rangle \langle w,w \rangle$.

Now suppose that we have equality.  By the above computation this implies $\langle v - c w , v - c w \rangle$ and therefore $v - cw =0$.  On the other hand if we have $v = cw$ then
\begin{align*}
\abs{\langle v, w \rangle}^2 &=  \langle v, c v \rangle \overline{\langle  v, c v \rangle} = c \overline{c} \langle v, v \rangle^2 = \langle v, v \rangle \langle cv, cv \rangle 
= \langle v, v \rangle \langle w, w \rangle
\end{align*}
so equality holds.
\end{proof}

\begin{prop}\label{hilbert:ContinuityOfInnerProduct}Let $H$ be an inner product space and then for every $v \in H$ the map $\langle v, \cdot \rangle$ is bounded linear and the map $\langle \cdot, v \rangle$ is bounded sesquilinear, hence uniformly continuous.  In particular, if $\sum_{i=1}^\infty v_i$ converges in $H$ and $w \in H$ then $\langle \sum_{i=1}^\infty v_i, w \rangle=\sum_{i=1}^\infty \langle v_i, w \rangle$.
\end{prop}
\begin{proof}
The Cauchy-Schwartz inequality \ref{hilbert:CauchySchwartz} shows that $\langle v, \cdot \rangle$ and $\langle \cdot, v \rangle$ are bounded; (sesqui)linearity follow from the corresponding properties of the inner product.  Uniform continuity of a bounded sesquilinear map follows by the same proof as the one for linear maps.
\end{proof}

TODO: Stuff about orthogonal projections.
\begin{prop}Let $H$ be a Hilbert space and let $V \subset H$ be a closed subspace then there exists another closed subspace $W$ such that $H = V \oplus W$ and for every $v \in V$ and $w \in W$ we have $\langle v, w \rangle = 0$.  
\end{prop}
\begin{proof}
Let $W = \lbrace w \in H \mid \langle v, w \rangle = 0 \text{ for all $v \in V$}  \rangle$.  

\begin{clm} $W$ is a closed subspace.  
\end{clm}
Let $u,w \in W$ and $a \in \field$ then for any $v \in V$ we have $\langle v, au + w \rangle = a \langle v, u \rangle + \langle v, w \rangle = 0$.  Suppose $w_1, w_2, \dotsc \in W$ and $w \in H$ such that $w_n \to w$.  By Proposition \ref{hilbert:ContinuityOfInnerProduct} we have $\langle v, w \rangle = \lim_{n \to \infty} \langle v, w_n \rangle = 0$ which implies $w \in W$.

\begin{clm} $H = V \oplus W$.
\end{clm}
Let $v \in H$.  
TODO: Finish
\end{proof}

\section{Quadratic Forms}


\begin{defn}Let $V$ be a vector space of a field $\field$ ($\field = \reals$ or $\field = \complexes$) then a
  \emph{sesquilinear form} is a map $L : V \times V \to \field$ 
satisfying the following properties
\begin{itemize}
\item[(i)] For all $v,w \in V$ and $c \in \field$, $L(cv, w)= \overline{c} L(v,w)$ and $L(v,cw)= c L(v,w)$.
\item[(ii)] For all $v,w,u \in V$ $L(v + u, w) = L(v,w)+ L(u, w)$ and $L(v, w+u) = L(v,w) + L(v, u)$
\end{itemize}
A sesquilinear form is \emph{conjugate symmetric} if $L(v,w) = \overline{L(w,v)}$ for all $v, w \in V$.
A sesquilinear form on a normed vector space $V$ is said to be \emph{bounded} if there exists a constant $C$ such that $\abs{L(v,w)} \leq C \norm{v} \norm{w}$ for all $v, w \in V$.   We define the norm 
\begin{align*}
\norm{L} = \sup \lbrace \abs{L(v,w)} \mid \norm{v} \leq 1, \norm{w} \leq 1 \rbrace
\end{align*}
\end{defn}

\begin{defn}Let $V$ be a vector space of a field $\reals$ then an
  \emph{bilinear form} is a map $L : V \times V \to \reals$ 
satisfying the following properties
\begin{itemize}
\item[(i)] For all $v,w \in V$ and $c \in \field$, $L(cv, w)= c L(v,w)$ and $L(v,cw)= c L(v,w)$.
\item[(ii)] For all $v,w,u \in V$ $L(v + u, w) = L(v,w)+ L(u, w)$ and $L(v, w+u) = L(v,w) + L(v, u)$
\end{itemize}
A bilinear form is \emph{symmetric} if $L(v,w) = L(w,v)$ for all $v,w \in V$.
A bilinear form on a normed vector space $V$ is said to be \emph{bounded} if there exists a constant $C$ such that $\abs{L(v,w)} \leq C \norm{v} \norm{w}$ for all $v, w \in V$.
\end{defn}

\begin{prop}\label{hilbert:LinearCombinationSesquilinear}Let $V$ be a vector space of a field $\field$ ($\field = \reals$ or $\field = \complexes$) and $L,M$ be sesquilinear forms then for every $a \in \field$, $cL$ is a sesquilinear form and $L+M$ is a sesquilinear form.  If $V$ is a normed vector space then $\norm{L}$ defines a norm on the space of sesquilinear forms.  If $V$ is a Banach space then the space of sesquilinear forms is a Banach space.
\end{prop}
\begin{proof}
To see that $aL$ is sesquilinear, let $v,w \in V$ and $c \in \field$ then 
\begin{align*}
(aL)(cv, w)= a \overline{c} L(v,w) = \overline{c} (aL)(v,w)
\end{align*}
and similarly $aL(v, cw) = c (aL)(v,w)$.  For $u,v,w \in V$, 
\begin{align*}
(aL)(u+v, w) &=a(L(u,w) + L(v,w)) =(aL)(u,w) + (aL)(v,w)
\end{align*}
and similarly $(aL)(u,v+w) = (aL)(u,v)+(aL)(u,w)$.  

Let $v,w \in V$ and $c \in \field$ then 
\begin{align*}
(L+M)(cv, w)&= L(cv,w) = M(cv,w) = \overline{c} L(v,w)+\overline{c} M(v,w) = \overline{c} (L+M)(v,w)
\end{align*}
and similarly $(L+M)(v, cw) = c (L+M)(v,w)$.  For $u,v,w \in V$, 
\begin{align*}
(L+M)(u+v, w) &= L(u+v,w) + M(u+v,w) = L(u,w) + L(v,w) + M(u,w) + M(v,w) \\
&=(L+M)(u,w) + (L+M)(v,w)
\end{align*}
and similarly $(L+M)(u,v+w) = (L+M)(u,v)+(L+M)(u,w)$.

Let $V$ be a normed vector space then clearly $\norm{L} \geq 0$ and furthermore if $\norm{L} = 0$ then $L(v,w) = 0$ for all $v,w \in V$ with $\norm{v} \leq 1$ and $\norm{w} \leq 1$.  For arbitrary $v,w \in V$ there exist constants $a,b$ and vectors $\tilde{v}, \tilde{w}$ with $\norm{\tilde{v}} \leq 1$, $\norm{\tilde{w}} \leq 1$, $v = a \tilde{v}$ and $w= b\tilde{w}$.  Thus 
\begin{align*}
L(v,w) &= L(a\tilde{v}, b \tilde{w}) = \overline{a} b L(\tilde{v}, \tilde{w}) = 0
\end{align*}
To see homogeneity, for all $v, w \in V$ then
\begin{align*}
\abs{aL(v,w)} &= \abs{a} \abs{L(v,w)}\leq \abs{a} \norm{L} \norm{v} \norm{w}
\end{align*}
which shows that $\norm{aL} \leq \abs{a} \norm{L}$.  In the other direction, let $\epsilon > 0$ and pick $v,w$ with $\norm{v} \leq 1$ and $\norm{w} \leq 1$ such that $\abs{L(v,w)} \geq \norm{L} - \epsilon$ then 
\begin{align*}
\norm{aL} &\geq \abs{aL(v,w)} = \abs{a} \abs{L(v,w)} \geq \abs{a} (\norm{L} - \epsilon)
\end{align*}
and let $\epsilon \to 0$ to see that $\norm{aL} \geq \abs{a} \norm{L}$.

To see the triangle inequality for $\norm{L}$,  by the triangle inequality in $\field$,
\begin{align*}
\abs{(L+M)(v,w)} &\leq \abs{L(v,w)} + \abs{M(v,w)} \leq (\norm{L}+\norm{M}) \norm{v} \norm{w}
\end{align*}
which shows $\norm{L+M} \leq \norm{L}+\norm{M}$.

TODO: Do the Banach space part.
\end{proof}

\begin{prop}[Polarization Identity]\label{hilbert:PolarizationIdentity}Let $V$ be a vector space over $\complexes$ and $L$ a sesquilinear form then for all $v,w \in V$,
\begin{align*}
L(v,w) &= \frac{1}{2} \left ( L(v+w, v+w) - L(v,v) - L(w,w) \right) - \frac{i}{2} \left ( L(v+iw, v+iw) - L(v,v) - L(iw,iw) \right) 
\end{align*}
Let $V$ be a vector space over $\reals$ and let $L$ be a symmetric bilinear form then for all $v,w \in V$
\begin{align*}
L(x,y) &= \frac{1}{4} \left( L(v+w, v+w) - L(v-w, v-w) \right)
\end{align*}
\end{prop}
\begin{proof}
\begin{align*}
&\frac{1}{2} \left ( L(v+w, v+w) - L(v,v) - L(w,w) \right) - \frac{i}{2} \left ( L(v+iw, v+iw) - L(v,v) - L(iw,iw) \right) \\
&=\frac{1}{2} \left ( L(v,w) + L(w,v) \right) - \frac{i}{2} \left ( i L(v, w) - i L(w,v) \right) \\
&=\frac{1}{2}  L(v,w) + \frac{1}{2}  L(w,v)  + \frac{1}{2}  L(v, w) - \frac{1}{2}  L(w,v) = L(v,w) \\
\end{align*}

The proof for the symmetric bilinear case is similar.
\end{proof}

A non-symmetric bilinear form is not uniquely determined by its diagonal elements.
\begin{examp}In $\reals^2$ consider the matrix for counterclockwise rotation by $90{\degree}$
\begin{align*}
A &= \begin{bmatrix} 
0 & -1 \\ 
1 & 0 \\
\end{bmatrix}
\end{align*}
and define $L(v,w) = v^T A w$.  Then $L(v,v) = (v_1,v_2) \cdot (-v_2, v_1) = 0$ but 
\begin{align*}
L \left( \begin{bmatrix} 
1 \\ 
0 \\
\end{bmatrix},
\begin{bmatrix} 
0 \\ 
1 \\
\end{bmatrix}
\right) &= 1
\end{align*}
so $L$ is not equal to $0$ (which is also a bilinear form that has $0$ diagonal elements).
\end{examp}

Since a sesquilinear form is determined by its values on the diagonal we choose to study that restriction.  First we need to characterize such restrictions and give them a name.
\begin{defn}Let $H$ be a complex Hilbert space then a \emph{quadratic form} is a function $Q : H \to \complexes$ such that 
\begin{itemize}
\item[(i)] $Q(c v) = \abs{c}^2 Q(v)$ for all $v \in H$ and $c \in \field$
\item[(ii)] The expression
\begin{align*}
L(v,w) &= \frac{1}{2} \left ( Q(v+w) - Q(v) - Q(w) \right) - \frac{i}{2} \left (Q(v+iw) - Q(v) - Q(iw) \right) 
\end{align*}
defines a sesquilinear form.
\end{itemize}
We say that $Q$ is bounded if there exists a constant $C$ such that $\abs{Q(v)} \leq C \norm{v}^2$ for all $v \in H$.  If $Q$ is bounded then the infimum of all such $C$ is the \emph{norm} of $Q$.  In that case we can define 
\begin{align*}
\norm{Q} = \sup \lbrace \abs{Q(v)} \mid \norm{v} \leq 1 \rbrace
\end{align*}
\end{defn}

\begin{prop}\label{hilbert:QuadraticPropertiesToSesquilinearProperties}Let $H$ be a complex Hilbert space, $Q$ a quadratic form and $L$ be the associated sesquilinear form.  Then
\begin{itemize}
\item[(i)] $Q(v) = L(v,v)$ for all $v \in H$
\item[(ii)] If $Q$ is bounded then $L$ is bounded
\item[(iii)] If $Q$ is real valued then $L$ is conjugate symmetric.
\end{itemize}
\end{prop}
\begin{proof}
To see (i) we compute using the property $Q(c v) = \abs{c}^2 Q(v)$,
\begin{align*}
L(v,v) &= \frac{1}{2} \left ( Q(v+v) - Q(v) - Q(v) \right) - \frac{i}{2} \left (Q(v+iv) - Q(v) - Q(iv) \right)  \\
&= \frac{1}{2} \left ( 4 - 1 -1 \right)  Q(v) -  \frac{i}{2} \left ( \abs{1+i}^2 - 1 - 1 \right)  Q(v)  = Q(v)
\end{align*}

To see (ii), suppose $\abs{Q(v)} \leq C \norm{v}^2$ for all $v \in H$.  Let $v, w \in H$ be unit vectors and so that by the triangle inequality in both $\complexes$ and $H$.
\begin{align*}
\abs{L(v,w)} &\leq \frac{1}{2} \left(\abs{Q(v+w)} + \abs{Q(v)} + \abs{Q(w)} + \abs{Q(v+iw)} + \abs{Q(v)} + \abs{Q(iw)} \right) \\
&\leq \frac{C}{2} \left( \norm{v+w}^2 + \norm{v}^2 + \norm{w}^2 + \norm{v+iw}^2 + \norm{v}^2 + \norm{iw}^2 \right ) \\
&\leq \frac{C}{2} \left( 4 + 1 + 1 + 4 + 1 + 1 \right ) = 6 C
\end{align*}
For arbitrary $v,w \in H$ we pick unit vectors $\tilde{v}$ and $\tilde{w}$ such that  $v = \norm{v} \tilde{v}$ and $w = \norm{w} \tilde{w}$ and compute
\begin{align*}
\abs{L(v,w)} &= \norm{v} \norm{w} \abs{L(\tilde{v}, \tilde{w})} \leq 6C \norm{v} \norm{w} 
\end{align*}

To see (iii) suppose that $Q$ is real valued then define
\begin{align*}
M(v,w) &= \RePart (L(v,w))  = \frac{1}{2} \left( Q(v+w) - Q(v) - Q(w) \right)
\end{align*}
Note that since $L$ is sesquilinear, for $c \in \reals$ and $v,w \in H$,
\begin{align*}
M(cv, w) &= \RePart (c L(v,w)) =c \RePart ( L(v,w)) = cM(v,w)
\end{align*}
and for $u,v,w \in H$
\begin{align*}
M(u+v, w) &= \RePart (L(u+v,w)) =\RePart ( L(u,w) + \RePart ( L(v,w)) = M(u,w) + M(v,w)
\end{align*}
Also for $v,w \in H$
\begin{align*}
M(v,w) &= \frac{1}{2} \left( Q(v+w) - Q(v) - Q(w) \right) = \frac{1}{2} \left( Q(w+v) - Q(w) - Q(v) \right) = M(w,v)
\end{align*}
so $M$ is a symmetric real binear form on $H$.  Lastly sesquilinearity implies $M(iv,iw) = \RePart ( L(iv,iw)) = \RePart (-i^2 L(v,w)) = M(v,w)$ hence 
\begin{align*}
M(v,iw) &= M(iw, v) = M(i^2w, iv) = M(-w, iv) = -M(w,iv)
\end{align*}
Finally,
\begin{align*}
L(v,w) &= M(v,w) - i M(v,iw) = M(w,v) + i M(w, iv) = \overline{L(w, v)}
\end{align*}
\end{proof}

We have seen the notion of a bounded sesquilinear form and a bounded quadratic form are equivalent.  If it also the case that in a Hilbert space, bounded quadratic forms are equivalent to bounded linear operators.

\begin{prop}\label{hilbert:QuadraticFormFromOperator}Let $H$ be a complex Hilbert space and $A : H \to H$ a bounded linear operator then $Q(v) = \langle v, A v \rangle$ is a bounded quadratic form with norm bounded above by $\norm{A}$.  The sesquilinear form defined by $Q$ is $L(v,w) = \langle v, Aw \rangle$.
\end{prop}
\begin{proof}
Straightforward computation using linearity and the fact that the inner product is sesquilinear shows that for $v,w \in H$,
\begin{align*}
L(v, w) &= \frac{1}{2} \left ( Q(v+w) - Q(v) - Q(w) \right) - \frac{i}{2} \left (Q(v+iw) - Q(v) - Q(iw) \right) \\
&= \frac{1}{2} \left ( \langle v+w, A(v+w) \rangle - \langle v, A(v) \rangle - \langle w, Aw \rangle \right) \\
&- \frac{i}{2} \left ( \langle v+iw, A(v + iw) \rangle - \langle v, A(cv) \rangle - \rangle iw, A(iw) \rangle \right) \\
&= \frac{1}{2} \left ( \langle v, Aw \rangle + \langle w, A(v) \rangle \right) - \frac{i}{2} \left ( \langle v, A(iw) \rangle + \langle iw, A(v) \rangle \right) \\
&= \frac{1}{2} \left ( \langle v, Aw \rangle +  \langle w, Av \rangle \right) - \frac{i}{2} \left ( i \langle v, Aw \rangle - i\langle w, Av \rangle \right) \\
&= \langle v, Aw \rangle 
\end{align*}
and
\begin{align*}
Q(cv) &= \langle cv, A (cv) \rangle = \langle cv, c A v \rangle = \abs{c}^2 \langle v, A v \rangle = \abs{c}^2Q(v)
\end{align*}

The fact that $L$ is sequilinear follows from the fact that the inner product is sequilinear and linearity of $A$,
as well as 
\begin{align*}
L(cv, w) &= \langle cv, Aw \rangle = \overline{c} \langle v, Aw \rangle = \overline{c} L(v,w)
\end{align*}
and
\begin{align*}
L(v, cw) &= \langle v, A(cw) \rangle = c \langle v, Aw \rangle = c L(v,w)
\end{align*}
\begin{align*}
L(u+v, w) &=\langle u+v, Aw \rangle = \langle u, Aw \rangle + \langle v, Aw \rangle = L(u,w) + L(v,w)
\end{align*}
\begin{align*}
L(u, v+w) &= \langle u, A(v+w) \rangle = \langle u, Av \rangle + \langle u, Aw \rangle = L(u,v) + L(u,w)
\end{align*}
which show that $Q$ is a quadratic form.  To see that $Q$ is bounded note that by the Cauchy-Schwartz inequality \ref{hilbert:CauchySchwartz}
\begin{align*}
\abs{\langle v, Av \rangle}^2 &\leq \norm{v} \norm{Av} \leq \norm{A} \norm{v}^2
\end{align*}
\end{proof}

\begin{prop}\label{hilbert:LinearCombinationOfQuadraticForms}Let $H$ be a complex Hilbert space and $Q$ and $R$ be quadratic forms then for every $c \in \complexes$, $cQ$ is a quadratic form and $Q + R$ is a quadratic form.  If $Q$ is bounded with norm $\norm{Q}$ then $cQ$ is bounded with norm $\abs{c}^2\norm{Q}$.  If $Q$ and $R$ are bounded then $Q+R$ is bounded and $\norm{Q+R} \leq \norm{Q} + \norm{R}$. 
\end{prop}
\begin{proof}
For any constants $c, d \in \complexes$ and $v \in H$, we have $(cQ)(dv) = c \abs{d}^2 Q(v) = \abs{d}^2 (cQ)(v)$ and 
\begin{align*}
(Q+R) (dv) = Q(dv) + R(dv) = \abs{d}^2 Q(v) + \abs{d}^2 R(v) = \abs{d}^2 (Q+R)(v)
\end{align*}
The rest of the proof that $cQ$ and $Q+R$ are quadratic forms follows from Proposition \ref{hilbert:LinearCombinationSesquilinear}.   Assuming $Q$ and $R$ are bounded we have
\begin{align*}
\abs{cQ(v)} &\leq \abs{c}\abs{Q(v)} \leq \abs{c} \norm{Q} \norm{v}^2
\end{align*}
and 
\begin{align*}
\abs{(Q+R)(v)} &\leq \abs{Q(v)} + \abs{R(v)} \leq \norm{Q} \norm{v}^2 +  \norm{R} \norm{v}^2
\end{align*}
\end{proof}

\begin{prop}\label{hilbert:OperatorFromQuadraticForm}Let $H$ be a complex Hilbert space and $Q$ a bounded quadratic form then there exists a unique bounded linear operator $A : H \to H$ such that $Q(v) = \langle v, A v \rangle$.  In this case the associated sesquilinear form $L$ has the formula $L(v,w) = \langle v, A w \rangle$.  If $Q$ is real valued then the operator $A$ is self adjoint.
\end{prop}
\begin{proof}
From Proposition \ref{hilbert:QuadraticPropertiesToSesquilinearProperties} we know that sesquilinear form $L$ is bounded hence there exists a constant $C$ such that $L(v,w) \leq C \norm{v}\norm{w}$ for all $v,w \in H$.  Let $v \in H$ be fixed so that $w \mapsto L(v,w)$ is a bounded linear functional on $H$ with norm bounded above by $C \norm{v}$.  By the Riesz Theorem TODO there exists a unique $B(v) \in H$ with $\norm{B(v)} \leq C \norm{v}$ such that $L(v,w) = \langle B(v), w \rangle$ for all $w \in H$.  Let $c \in \complexes$ and observe that 
\begin{align*}
\langle c B(v), w \rangle &= \overline{c} \langle B(v), w \rangle = \overline{c} L(v,w) = L(cv, w)
\end{align*}
and uniqueness in the Riesz Theorem implies $B(cv) = cB(v)$.  Furthermore for $u,v, w \in H$ we have 
\begin{align*}
\langle  B(u) + B(v), w \rangle &= \langle  B(u), w \rangle  + \langle B(v), w \rangle = L(u,w) + L(v,w) = L(u+v, w)
\end{align*}
hence $B(u+v) = B(u) + B(v)$ and $B$ is a linear map.  The fact that $\norm{B(v)} \leq C \norm{v}$ implies that $B$ is bounded linear and therefore we can define the adjoint $A = B^*$.  It follows from the definition of $B$ that $L(v,w) = \langle B(v) , w \rangle = \langle v, A w \rangle$ for all $v,w \in H$ and therefore $Q(v) = L(v,v) = \langle v, A v \rangle$.  

To see that for any $Q(v) = \langle v, A v \rangle$ it is necessary that $L(v,w) = \langle v, Aw \rangle$ just use the Polarization identity to compute
\begin{align*}
L(v,w) &= \frac{1}{2} \left ( Q(v+w) - Q(v) - Q(w) \right) - \frac{i}{2} \left (Q(v+iw) - Q(v) - Q(iw) \right) \\
&=\frac{1}{2} \left ( \langle v+w, Av + Aw \rangle - \langle v, Av \rangle - \langle w, A w \rangle \right) - \frac{i}{2} \left ( \langle v+iw, Av + i Aw \rangle - \langle v, A v \rangle - \langle iw, i A w \rangle \right)  \\
&=\frac{1}{2} \left ( \langle w, Av \rangle + \langle v, Aw \rangle \right) - \frac{i}{2} \left ( i \langle v, Aw \rangle -  i \langle w, A v \rangle \right) \\
&= \langle v, Aw \rangle
\end{align*}

To see that $A$ is unique suppose that there exist bounded linear operators $A_1$ and $A_2$ with $Q(v) = \langle v, A_1 v \rangle = \langle v, A_2 v \rangle$ for all $v \in H$ then by the polarization formula above it follows that $\langle v, A_1 w \rangle = \langle v, A_2 w \rangle$ for all $v, w \in H$ so in particular $\norm{(A_1-A_2) v} = \langle (A_1 - A_2) v, (A_1 - A_2) v \rangle = 0$ for all $v \in H$.

Suppose that $Q(v)$ is real valued for all $v \in H$, then by Proposition \ref{hilbert:QuadraticPropertiesToSesquilinearProperties} we know that $L$ is conjugate symmetric and therefore 
\begin{align*}
\langle v, A w \rangle &= L(v,w) = \overline{L(w,v)} = \overline{\langle w, A v \rangle} = \langle A v, w \rangle
\end{align*}
which implies $A = A^*$.
\end{proof}

\section{Spectrum of Bounded Linear Operators}

\begin{defn}Let $A : V \to V$ be a bounded linear operator on a Banach
  space $V$ over the normed field $\field$ ($\field= \reals$ or $\complexes$) then the \emph{resolvent set} $\resolventset{A}$ is the set of $\lambda \in \field$ such that operator $(A - \lambda)$ has a bounded inverse.  For $\lambda \in \resolventset{A}$ the operator $(A - \lambda)^{-1}$ is called the \emph{resolvent} of $A$ at $\lambda$ and is maybe written $R_\lambda$.  The set $\spectrum{A} = \field \setminus \resolventset{A}$ is called the \emph{spectrum} of $A$.
\end{defn}

Note that by the Open Mapping Theorem the boundedness of the inverse of $A - \lambda$ is is a consequence of the boundedness of $A$ and bijectiveness of $A - \lambda$.  

\begin{prop}\label{BoundedLinearResolventSetOpen}Let $A : V \to V$ be a bounded linear operator on a Banach  space $V$ over the normed field $\field$.  
\begin{itemize}
\item[(i)] If $\abs{\lambda} > \norm{A}$ then $\lambda \in \resolventset{A}$.
\item[(ii)] $\spectrum{A}$ is a closed bounded set of $\field$
\item[(iii)] $R_\lambda$ is analytic on $\resolventset{A}$
\item[(iv)] If $\field = \complexes$ then $\spectrum{A} \neq \emptyset$
\end{itemize}
\end{prop}
\begin{proof}
To see (i), let $\abs{\lambda} > \norm{A}$ and consider the operator $A - \lambda = -\lambda (\IdentityMatrix - \frac{A}{\lambda})$.  We see that $\norm{\frac{A}{\lambda}} < 1$ and therefore by Proposition \ref{banach:InvertibleMapsOpen} we know that $A - \lambda$ has a bounded inverse given by the formula
\begin{align*}
(A - \lambda)^{-1} &= -\frac{1}{\lambda} \sum_{n=0}^\infty \left( \frac{A}{\lambda} \right)^n
\end{align*}
thus $\lambda \in \resolventset{A}$.  In particular, $\spectrum{A}$ is bounded.

Now let $\lambda_0 \in \resolventset{A}$ so $A -\lambda_0$ has a bounded inverse.  Now suppose 
\begin{align*}
\abs{\lambda - \lambda_0}  &< \frac{1}{\norm{(A-\lambda_0)^{-1}}}
\end{align*}
then 
\begin{align*}
\norm{(A - \lambda) - (A - \lambda_0)} &= \abs{\lambda - \lambda_0} < \frac{1}{\norm{(A-\lambda_0)^{-1}}}
\end{align*}
and Proposition \ref{banach:InvertibleMapsOpen} shows that $A- \lambda$ has a bounded inverse.  Thus $ \resolventset{A}$ is open, hence $\spectrum{A}$ is closed.

Let $\lambda_0 \in \resolventset{A}$ and note that again applying Proposition \ref{banach:InvertibleMapsOpen} we see that for 
\begin{align*}
\abs{\lambda - \lambda_0}  &< \frac{1}{\norm{(A-\lambda_0)^{-1}}}
\end{align*}
we have the formula ($B = A - \lambda$ and $A = A - \lambda_0$)
\begin{align*}
R_\lambda &= (A - \lambda)^{-1} = \sum_{n=0}^\infty (A- \lambda_0)^{-n-1} (\lambda - \lambda_0)^n
\end{align*}
so $R_\lambda$ is analytic on $\resolventset{A}$.  

Now let $\field = \complexes$ and assume that $\spectrum{A} = \emptyset$ then by (iii) we see that $R_\lambda$ is entire.  From the proof of (i) we have for $\abs{\lambda} > \norm{A}$,
\begin{align*}
\norm{R_\lambda} &\leq \frac{1}{\abs{\lambda}} \sum_{n=0}^\infty \left( \frac{\norm{A}}{\abs{\lambda}} \right)^n = \frac{1}{\abs{\lambda}} \frac{1}{1 - \norm{A}/\abs{\lambda}} < \frac{1}{\abs{\lambda}} 
\end{align*}
so $R_\lambda$ is bounded and therefore by Liouville's Theorem \ref{banach:LiouvillesTheorem} we know that $R_\lambda$ is constant.  Since the above norm estimate shows $R_\lambda \to 0$ as $\lambda \to \infty$ it follows that $R_\lambda \equiv 0$ which contradicts the identity $(A - \lambda) R_\lambda = \IdentityMatrix$.
\end{proof}

\section{Functional Calculus}

\subsection{Holomorphic Functional Calculus}

TODO: For bounded linear operators is trivial to define a functional calculus for entire functions (just expand $f(z) = \sum_{n=0}^\infty a_n z^n$ as a power series then define $f(A) = \sum_{n=0}^\infty a_n A^n$), the holomorphic functional calculus extends this to analytic functions $f : U \subset \complexes \to \complexes$ such that $\sigma(A) \subset U$ and $U$ open.  The idea is to use the Cauchy integral formula to show that $f(A) = \oint_{\Gamma} \frac{f(z)}{(z - A)^{-1}} \, dz$; the main issues to get started are that to make sense of the definition one must find curves $\Gamma$ such $\Gamma \cap \sigma(A) = \emptyset$ and then to verify that the integral doesn't depend on the choice of $\Gamma$.

\subsection{Continuous Functional Calculus}

\begin{defn}Let $A : V \to V$ be a bounded linear operator on a Banach space $V$ then the \emph{spectral radius} is defined to be 
\begin{align*}
\spectralradius{A} &= \sup \lbrace \abs{\lambda} \mid \lambda \in \sigma{A} \rbrace
\end{align*}
\end{defn}

\begin{prop}\label{hilbert:OperatorNormAlternative}Let $V$ and $W$ be Hilbert space over $\field$.   For every $v \in V$ we have $\norm{v} = \sup_{\norm{w}=1} \abs{\langle v, w \rangle}$.  If $A : V \to W$ be a linear operator then $\norm{A} = \sup_{\norm{v} = \norm{w} = 1} \abs{\langle w, A v \rangle}$.
\end{prop}
\begin{proof}
Note that by Cauchy-Schwartz we have for every $\norm{w} = 1$,$\abs{\langle v, w \rangle} \leq \norm{v}\norm{w} = \norm{v}$.  On the other hand if $v \neq 0$ then 
\begin{align*}
\abs{\langle v, v/\norm{v} \rangle} &= \langle v, v \rangle/\norm{v} = \norm{v} 
\end{align*}
and if $v = 0$ then for every $\norm{w} = 1$ we have $0 = \langle v, w \rangle = \norm{v}$.

By Proposition \label{banach:OperatorNormAlternative}, the first part of this result and Proposition \ref{real:SupremumOfBivariate} we have 
\begin{align*}
\norm{A} &= \sup_{\norm{v}=1} \norm{Av}  = \sup_{\norm{v}=1} \sup_{\norm{w}=1} \abs{\langle w, A v \rangle} = \sup_{\norm{v}=\norm{w}=1} \abs{\langle w, A v \rangle} 
\end{align*}
\end{proof}

\begin{prop}\label{hilbert:NormOfAdjoint}Let $V$ be a Hilbert space over $\field$ and $A : V \to V$ be a bounded linear operator then
\begin{itemize}
\item[(i)] $\norm{A} = \norm{\adjoint{A}}$
\item[(ii)] $\norm{\adjoint{A} A} = \norm{A}^2$
\end{itemize}
\end{prop}
\begin{proof}
By Proposition \ref{hilbert:OperatorNormAlternative} and the definition of the adjoint we have
\begin{align*}
\norm{\adjoint{A}} &= \sup_{\norm{v}=1} \sup_{\norm{w}=1} \abs{\langle w, \adjoint{A} v \rangle} = \sup_{\norm{v}=1} \sup_{\norm{w}=1} \abs{\langle Aw,  v \rangle} = \norm{A}
\end{align*}

To see (ii), by Proposition \ref{banach:OperatorNormInequality} and (i), we know that $\norm{\adjoint{A} A} \leq \norm{\adjoint{A}} \norm{A} = \norm{A}^2$.  On the other hand,
\begin{align*}
\norm{\adjoint{A} A}  &= \sup_{\norm{v}=1} \sup_{\norm{w}=1} \abs{\langle w, \adjoint{A} A v \rangle} = \sup_{\norm{v}=1} \sup_{\norm{w}=1} \abs{\langle A w, A v \rangle} \\
&\geq \sup_{\norm{v} = 1} \abs{\langle A v, A v \rangle} = \sup_{\norm{v} = 1} \norm{Av}^2 = \norm{A}^2
\end{align*}
\end{proof}

\begin{prop}\label{hilbert:SpectralRadiusBoundedSelfAdjoint}Let $A : H \to H$ be a self adjoint bounded linear operator on the separable Hilbert space $H$ then $\spectralradius{A} = \norm{A}$.
\end{prop}
\begin{proof}
From Proposition \ref {BoundedLinearResolventSetOpen} we have seen that for $\abs{\lambda} > \norm{A}$ we have the absolutely convergent Neumann series expansion
\begin{align*}
(A - \lambda)^{-1} &= -\frac{1}{\lambda} \sum_{n=0}^\infty \frac{A^n}{\lambda^n}
\end{align*}
Consider what happens when $\abs{\lambda} \leq \norm{A}$.  Since $A$ is self-adjoint, by Proposition \ref{hilbert:NormOfAdjoint} we have $\norm{A^2} = \norm{\adjoint{A}A} = \norm{A}^2$ and by an induction argument $\norm{A^{2^n}} = \norm{A}^{2^n}$ for all $n \in \naturals$ which shows that $\sum_{n=0}^\infty \frac{A^n}{\lambda^n}$  does not converge absolutely for $\abs{\lambda} \leq \norm{A}$.  

By Proposition \ref {BoundedLinearResolventSetOpen} we know that $\spectralradius{A} \leq \norm{A}$ and moreover we showed that for $\lambda_0 \in \resolventset{A}$ and 
\begin{align*}
\abs{\lambda - \lambda_0}  &< \frac{1}{\norm{(A-\lambda_0)^{-1}}}
\end{align*}
we have 
\begin{align*}
(A - \lambda)^{-1} &= \sum_{n=0}^\infty (A- \lambda_0)^{-n-1} (\lambda - \lambda_0)^n
\end{align*}
from which we concluded that $(A - \lambda)^{-1}$ was an analytic function on $\resolventset{A}$.  As an analytic function, $(A - \lambda)^{-1}$ has Laurent series about $0$ which (by uniqueness) is given by $-\frac{1}{\lambda} \sum_{n=0}^\infty \frac{A^n}{\lambda^n}$ and converges on the largest open annulus contained in $\resolventset{A}$ which is $\abs{\lambda} > \spectralradius{A}$ (suppose $\abs{\lambda} >  \spectralradius{A}$ then by definition  $\lambda \in \resolventset{A}$ and for any $r < \spectralradius{A}$ there exists a $\lambda \in \spectrum{A}$ with $\abs{\lambda} > r$).  We have already shown that the series diverges for $\abs{\lambda} < \norm{A}$ so it follows that $\spectralradius{A} \geq \norm{A}$.   

TODO:  Get these facts about Laurent series proven for the Banach space case.  Alternatively argue using ordinary complex valued functions...
\end{proof}

\begin{lem}[Spectral Mapping Theorem]\label{hilbert:SpectralMappingPolynomialBoundedSelfAdjoint}Let $H$ be a separable complex Hilbert space and let $A :H \to H$ be a bounded self adjoint operator then for every polynomial $p$ we have $\spectrum{p(A)} = p(\spectrum{A})$.
\end{lem}
\begin{proof}
If $p$ is a constant $0 \neq c \in \complexes$ then since $(c A - c \lambda)^{-1}  = \frac{1}{c} (A - \lambda)^{-1}$ it follows that $\resolventset{cA} = c \resolventset{A}$ hence $\spectrum{cA} c\spectrum{A}$.  Now let $p$ have non-zero degree and write 
\begin{align*}
p(z) &= a_n z^n + a_{n-1} z^{n-1} + \dotsb + a_0
\end{align*}
with $a_n \neq 0$.  

We will need the following simple fact.
\begin{clm}Suppose $A$ and $B$ are commuting bounded linear operators such that $AB$ is invertible, then $A$ is invertible.
\end{clm}
Note that $A$ and $B$ commute with $(AB)^{-1} = (BA)^{-1}$.  E.g. for $B$ we see
\begin{align*}
(AB)^{-1} B  &= (AB)^{-1} B (AB) (AB) ^{-1}  =  (AB)^{-1} (AB) B  (AB) ^{-1} = A  (AB) ^{-1}
\end{align*}
We define $C = (AB)^{-1}B = B(AB)^{-1}$.  Then $C A = (AB)^{-1} (AB) = \IdentityMatrix$ and $A C = (A B) (AB)^{-1} = \IdentityMatrix$.

\begin{clm} $p(\spectrum{A}) \subset \spectrum{p(A)}$.
\end{clm}
For any $k \in \naturals$ and $\lambda \in \complexes$ we can write
\begin{align*}
A^k - \lambda^k &= (A - \lambda) (A^{k-1} + \lambda A^{k-2} + \dotsb + \lambda^{k-1} = (A - \lambda) \sum_{j=0}^{k-1} \lambda^{j} A^{k-1-j}
\end{align*}
we have
\begin{align*}
p(A) - p(\lambda) &=  a_n (A^n - \lambda^n) + a_{n-1} (A^{n-1} - \lambda^{n-1})  + \dotsb + a_1 (A - \lambda) \\
&= (A - \lambda) \left ( a_n \sum_{j=0}^{n-1} \lambda^{j} A^{n-1-j} + a_{n-1} \sum_{j=0}^{n-2} \lambda^{j} A^{n-2-j} + a_1 \right )
\end{align*}
Now suppose that $p(\lambda) \in \resolventset{p(A)}$ then by the previous claim it follows that $\lambda \in \resolventset{A}$.  Taking set complements shows the claim.

\begin{clm} $\spectrum{p(A)}\subset p(\spectrum{A})$.
\end{clm}
Let $\lambda \in \spectrum{p(A)}$.  Since $\complexes$ is algebraically closed we may completely factor the polynomial $p(z) - \lambda$:
\begin{align*}
p(z) - \lambda &= c(z - b_1) \dotsb (z -b_n)
\end{align*}
and therefore
\begin{align*}
p(A) - \lambda &= c(A - b_1) \dotsb (A -b_n)
\end{align*}
with $c \neq 0$.  If $b_j \in \resolventset{A}$ for every $j=1, \dotsc, n$ then $\frac{1}{c} (A - b_1)^{-1} \dotsb (A -b_n)^{-1}$ would be an bounded inverse of $p(A) - \lambda$ (it is simple to see that the $(A-b_j)^{-1}$ commute) which would contradict $\lambda \in \spectrum{p(A)}$.  Thus for some $j=1, \dotsc, n$ we have $b_j \in \spectrum{A}$.  Since $p(b_j) - \lambda = 0$ we see that $\lambda \in p(\spectrum{A})$.
\end{proof}

\begin{prop}\label{hilbert:BoundedSelfAdjointProperties}The space of bounded self adjoint operators is a closed real linear subspace of $L(H,H)$.
\end{prop}
\begin{proof}
Let $A$ and $B$ be bounded self adjoint operators and let $a, b \in \reals$, then for all $v,w \in H$,
\begin{align*}
\langle v, (aA + bB) w \rangle &= a \langle v, Aw \rangle + b \langle v, B w \rangle =  a \langle A v, w \rangle + b \langle B v, w \rangle = \langle (aA+bB) v, w \rangle
\end{align*}
Let $A_n$ be bounded self adjoint operators and suppose that $\lim_{n \to \infty} A_n = A$.  Then for all $v, w \in H$, by Proposition \ref{banach:OperatorNormConvergenceImpliesPointwise} and 
Proposition \ref{hilbert:ContinuityOfInnerProduct}
\begin{align*}
\langle v, A w \rangle &= \lim_{n\to \infty} \langle v, A_n w \rangle = \lim_{n\to \infty} \langle A_n v, w \rangle = \langle A v, w \rangle
\end{align*}
\end{proof}

\begin{thm}[Continuous Functional Calculus]\label{hilbert:ContinuousFunctionalCalculusBoundedSelfAdjoint}Let $H$ be a complex Hilbert space and let $A$ be a bounded self adjoint operator then there exists a unique bounded linear map from $\Psi : C(\spectrum{A}; \reals) \to L(H;H)$ such that $\Psi(z^n) = A^n$ for every $n \in naturals$.  For $f \in  C(\spectrum{A}; \reals)$ we will denote $\Psi(f)$ by $f(A)$.  The map $\Psi$ has the following properties for $f,g  \in C(\spectrum{A}; \reals)$ 
\begin{itemize}
\item[(i)] $(fg)(A) = f(A) g(A)$.
\item[(ii)] $f(A)$ is self-adjoint
\item[(iii)] If $f \geq 0$ then $f(A)$ is a non-negative operator (i.e. $\langle v, Av \rangle \geq 0$ for all $v \in H$)
\item[(iv)] $\norm{f(A)} = \norm{f}_\infty = \sup_{\lambda \in \spectrum{A}} \abs{\lambda}$
\item[(v)] $\spectrum{f(A)} = f(\spectrum{A})$
\end{itemize}
\end{thm}
\begin{proof}
We define $\Psi$ on polynomials by taking $\Psi \left(\sum_{i=0}^n a_i z^i \right) = \sum_{i=0}^n a_i A^i$.  Using Proposition \ref{hilbert:SpectralRadiusBoundedSelfAdjoint} and the Spectral Mapping Theorem \ref{hilbert:SpectralMappingPolynomialBoundedSelfAdjoint} we get
\begin{align*}
\norm{p(A)} &= \spectralradius{p(A)} = \sup_{\lambda \in \spectrum{p(A)}} \abs{\lambda} = \sup_{\lambda \in \spectrum{A}} \abs{p(\lambda)} = \norm{p(z)}_\infty
\end{align*}
which shows that $\Psi$ is a linear isometry.  In particular it is uniformly continuous and therefore by the Stone Weirstrass Theorem \ref{StoneWeierstrassApproximation} and Proposition \ref{ExtensionOfUniformlyContinuousMapCompleteRange} there is a unique linear extension of $\Psi$ to all of $C(\spectrum{A}; \reals)$.

To see (i), by direct computation we see that (i) holds for polynomials $p$ and $q$.  For general $f$ and $g$ simply choose approximating polynomials and use the continuity of $\Psi$.

To see (ii) use Proposition \ref{hilbert:BoundedSelfAdjointProperties} to observe that $p(A)$ is bounded self adjoint for every polynomial with real coefficients and for arbitrary $f$ approximate by polynomials and use the continuity of $\Psi$.

To see (iii), let $f \in C(\spectrum{A}; \reals)$ satisfy $f \geq 0$.  Then  writing $g = \sqrt{f}$ we have $g \in C(\spectrum{A}; \reals)$ and $f = g^2$.  By (ii), $g(A)$ is self adjoint and therefore by (i) we get for all $v \in H$,
\begin{align*}
\langle v, f(A) v \rangle &= \langle v, g(A) g(A) v \rangle = \langle g(A) v, g(A) v \rangle = \norm{g(A)v}^2 \geq 0
\end{align*}

To see (iv), observe that by construction $\Psi$ was an isometry on polynomials.  Since the operator norm is continuous this extends to all of $C(\spectrum{A}; \reals)$.

To see (v), we first show that $\spectrum{f(A)} \subset f(\spectrum{A})$.  Suppose that $\lambda_0 \in \reals \setminus f(\spectrum{A})$.  Let $g(\lambda) = 1/(f(\lambda - \lambda_0)$ and note that $g \in C(\spectrum{A}; \reals)$.  By (i) we have $g(A)(f(A) - \lambda_0) = (f(A) - \lambda_0) g(A) = \IdentityMatrix$ so $\lambda_0 \in \resolventset{f(A)}$.  To see the opposite inclusion, let $\lambda \in \spectrum{A}$.  Let $p_1, p_2, \dotsc$ be polynomials with $\lim_{n \to \infty} p_n = f$ in $(\spectrum{A}; \reals)$.  By continuity of $\Psi$ we have $\lim_{n \to \infty} p_n(A) - f(\lambda) = f(A) - f(\lambda)$ in the operator norm.  Moreover since $\norm{p_n - f}_\infty \to 0$ we have $\lim_{n \to \infty} p_n(A) - p_n(\lambda) = f(A) - f(\lambda)$ in operator norm.  Suppose that $f(\lambda) \in \resolventset{f(A)}$, then by Proposition \ref{banach:InvertibleMapsOpen} we conclude that $p_n(A) - p_n(\lambda)$ is invertible for $n$ sufficiently large which contradicts the Spectral Mapping Theorem \ref{hilbert:SpectralMappingPolynomialBoundedSelfAdjoint}.
\end{proof}

\subsection{Measurable Functional Calculus}

We now use the Riesz-Markov Theorem \ref{RieszMarkov} to extend the continuous functional calculus for self adjoint operators to bounded measurable functions on $\spectrum{A}$.

The following application of the standard machinery will be useful.

\begin{lem}\label{hilbert:ContinuousToMeasurable}Let $S$ be a compact metric space and let $C(S; \reals)$ be the space of real valued continuous functions on $S$ and let $\sboundedmeasurable{S}{\complexes}$ be the space of bounded complex valued Borel measurable functions on $S$.  Let $\mathcal{F} \subset \sboundedmeasurable{S}{\complexes}$ such that 
\begin{itemize}
\item[(i)] $\mathcal{F}$ is a complex vector space
\item[(ii)] $C(S; \reals) \subset \mathcal{F}$ 
\item[(iii)] If $f_1, f_2, \dotsc \in \mathcal{F}$ and there exists $M>0$ such that $\norm{f_n}_\infty \leq M$ for all $n \in \naturals$ and $\lim_n f_n = f$ pointwise then $f \in \mathcal{F}$.
\end{itemize}
It follows that $\mathcal{F} = \sboundedmeasurable{S}{\complexes}$.
\end{lem}
\begin{proof}
First we use a monotone class argument to show that every indicator function is in $\mathcal{F}$.  Let $\mathcal{D}$ be the set of Borel subsets in $A \subset S$ such that $\characteristic{A} \in \mathcal{F}$.  Suppose $A, B \in \mathcal{D}$ and $A \subset B$ then $\characteristic{B \setminus A} = \characteristic{B} - \characteristic{A} \in \mathcal{F}$ by (i); thus $B \setminus A \in \mathcal{D}$.  If $A_1, A_2, \dotsc \in \mathcal{D}$ with $A_1 \subset A_2 \subset \dotsc$ and $A = \cup_n A_n$ then $\characteristic{A} = \lim_n \characteristic{A_n}$ and $\characteristic{A_n}$ is uniformly bounded so $\characteristic{A} \in \mathcal{F}$ by (iii) and thus $A \in \mathcal{D}$.  Lastly $\characteristic{S} \equiv 1 \in C(S; \reals)$ hence $S \in \setminus{D}$ by (ii).  It follows that $\characteristic{D}$ is a $\lambda$-system.  Let $F \subset S$ be a closed set then using the standard approximation $f_n(x)  =  nd(x,F)  \wedge 1$ we have $\characteristic{F}$ is the pointwise limit of the uniformly bounded sequence $f_n$.  Since $f_n \in C(S; \reals)$ (in fact $f_n$ is Lipschitz by Lemma \ref{DistanceToSetLipschitz}) we see that $\characteristic{F} \in \mathcal{F}$ by (ii) and (iii); hence all closed sets are in $\mathcal{D}$.  The set of closed sets is a $\pi$-system that generates $\mathcal{B}(S)$ it follows from the $\pi$-$\lambda$ Theorem \ref{MonotoneClassTheorem} that $\mathcal{B}(S) \subset \mathcal{D}$.  

By (i) it follows that $\mathcal{F}$ contains all real valued simple
functions.  For any $0 \leq f \in \sboundedmeasurable{S}{\reals}$ we
take simple functions $f_n \uparrow f$ to conclude that $f \in
\mathcal{F}$ (the $f_n$ are uniformly bounded by $\norm{f}_\infty$).
We may write any $\sboundedmeasurable{S}{\complexes}$ as a complex
linear combination of non-negative $f \in
\sboundedmeasurable{S}{\reals}$ ($f = \RePart(f)_+ - \RePart(f)_- + i \ImPart(f)_+ - i \ImPart(f)_-$) so by (i) we are done.
\end{proof}

\begin{prop}\label{hilbert:BoundedMeasurableFunctionalCalculusBoundedSelfAdjoint}Let $H$ be a complex Hilbert space and let $A$ be a bounded self adjoint operator then for every $v \in H$ there exists a unique Radon measure $\mu_v$ on $\spectrum{A}$ such that 
\begin{align*}
\langle v, f(A) v \rangle &= \int f \, d\mu_v \text{ for all $f \in C(\spectrum{A}; \reals)$}
\end{align*}
For every bounded measurable $f : \spectrum{A} \to \complexes$, the map 
\begin{align*}
Q_f(v) &= \int f \, d\mu_v
\end{align*}
defines a bounded quadratic form.  If we let $f(A) : H \to H$ be the linear operator uniquely associated with $Q_f$ then  
\begin{itemize}
\item[(i)] $(af + g)(A) = af(A) + g(A)$ for all $f,g \in \sboundedmeasurable{\spectrum{A}}{\complexes}$ and $a \in \complexes$
\item[(ii)] $(fg)(A) = f(A) g(A)$ for all $f,g \in \sboundedmeasurable{\spectrum{A}}{\complexes}$
\item[(iii)] If $f$ is real valued then $f(A)$ is self adjoint
\end{itemize}
\end{prop}
\begin{proof}
Given $v \in H$, we let $\Lambda_v : C(\spectrum{A}; \reals) \to \reals$ be defined by $\Lambda_v(f) = \langle v, f(A) v \rangle$.  By linearity of the continuous functional calculus, we see that $\Lambda_v$ is linear and since $f(A)$ is a bounded operator we have 
\begin{align*}
\abs{\Lambda_v(f)} &=\abs{\langle v, f(A) v \rangle} \leq \norm{v} \norm{f(A) v} \leq \norm{f(A)} \norm{v}^2 = \norm{f}_\infty \norm{v}^2
\end{align*}
so $\Lambda_v$ is bounded with $\norm{\Lambda_v} = \norm{v}^2$.  Moreover from Theorem \ref{hilbert:ContinuousFunctionalCalculusBoundedSelfAdjoint} it follows that $\Lambda_v$ is positive hence by the Riesz-Markov Theorem\ref{RieszMarkov} there exists a unique Radon measure $\mu_v$ such that 
\begin{align*}
\langle v, f(A) v \rangle &= \Lambda_v(f) = \int f \, d\mu_v
\end{align*}
and
\begin{align*}
\norm{v}^2 &= \Lambda_v(1) 
\end{align*}
For any $f \in \sboundedmeasurable{\spectrum{A}}{\complexes}$ we now define
\begin{align*}
Q_f(v) &= \int_{\spectrum{A}} f \, d\mu_v
\end{align*}

\begin{clm}For any $f \in \sboundedmeasurable{\spectrum{A}}{\complexes}$ define
\begin{align*}
Q_f(v) &= \int_{\spectrum{A}} f \, d\mu_v
\end{align*}
then $Q_f$ is a bounded quadratic form
\end{clm}
For any $f \in C(\spectrum{A}; \reals)$ we have already shown $Q_f(v) = \Lambda_v(f) = \langle v, f(A) v \rangle$ which is a bounded quadratic form by Proposition \ref{hilbert:QuadraticFormFromOperator}.  Let $\mathcal{F} \subset \sboundedmeasurable{\spectrum{A}}{\complexes}$ be the set of functions such that $Q_f$ a quadratic form.  Since
\begin{align*}
Q_{af +b}(v) &= \int (a f +g ) \, d\mu_v = a Q_f(v) + Q_g(v)
\end{align*}
the fact that $\mathcal{F}$ is a complex vector space follows from the fact that quadratic forms are a complex vector space (TODO: Where do we show this).  We have ready shown that $C(\spectrum{A}; \reals) \subset \mathcal{F}$.  Lastly suppose that $f_1, f_2, \dotsc \in \mathcal{F}$ is a uniformly bounded sequence and $f_n \to f$.  Then by Dominated Convergence we have
\begin{align*}
Q_f(v) &= \int f \, d\mu_v = \lim_{n \to \infty} \int f_n \, d\mu_v = \lim_{n \to \infty} Q_{f_n}(v) 
\end{align*}
which shows $Q_f$ is a quadratic form (TODO: Where do we show that quadratic forms are closed under pointwise limits).  Now by Lemma \ref{hilbert:ContinuousToMeasurable} it follows that $Q_f$ is a quadratic form for all $f \in \sboundedmeasurable{\spectrum{A}}{\complexes}$.  The fact that $Q_f$ is bounded (and in fact $\norm{Q_f} \leq \norm{f}_\infty$) follows from
\begin{align*}
\abs{Q_f(v)} &\leq \int \abs{f} \, d\mu_v \leq \norm{f}_\infty \int \, d\mu_v = \norm{f}_\infty \norm{v}^2
\end{align*}

By the previous claim and Proposition \ref{hilbert:OperatorFromQuadraticForm} for any $f \in \sboundedmeasurable{\spectrum{A}}{\complexes}$ we can let $f(A)$ be the unique bounded linear operator such that $\langle v , f(A) v \rangle = Q_f(v)$ for all $v \in H$.
To see that $(af + b)(A) = af(A) + g(A)$ let $v \in H$,
\begin{align*}
\langle v, (af(A) + g(A))(v) \rangle &= a \langle v, f(A) v \rangle + \langle v, g(A) v \rangle = a Q_f(v) + Q_g(v) \\
&= a \int f \, d\mu_v + \int g \, d\mu_v = \int (af + g) \, d\mu_v = Q_{af +g}(v)
\end{align*}
so by uniqueness in Proposition \ref{hilbert:OperatorFromQuadraticForm} we have $(af+g)(A) = af(A) + g(A)$.

To see that $(fg)(A) = f(A) g(A)$ we use another monotone class argument.  Let $\mathcal{F}_1 \subset \sboundedmeasurable{\spectrum{A}}{\complexes}$ be the set of $f$ such that $(fg)(A) = f(A) g(A)$ for all $g \in C(\spectrum{A}; \reals)$.  If $f,g \in \mathcal{F}_1$, $a \in \complexes$, $h \in C(\spectrum{A}; \reals)$ and $v \in H$ then
\begin{align*}
((af + g) h)Q_{(af +g)h} = a Q_{fh} + Q_{gh} = a Q_f Q_h = Q_g Q_h = Q_{af+g} Q_h 
\end{align*}
so $\mathcal{F}_1$.  By the Continuous Functional Calculus Theorem \ref{hilbert:ContinuousFunctionalCalculusBoundedSelfAdjoint} we know that $C(\spectrum{A}; \reals) \subset \mathcal{F}_1$.  Let $f_1, f_2, \dotsc \in \mathcal{F}_1$ be a uniformly bounded sequence with $f_n \to f$.  By Dominated Convergence we know that $Q_{f_n}(v) \to Q_f(v)$ for every $v \in H$.  If we let $L_{f_n}$ and $L_f$ be the sesquilinear forms associated with $Q_{f_n}$ and $Q_f$ then it follows from the polarization identity that $L_{f_n}(v,w)  \to L_f(v,w)$ for all $v,w \in H$.  In particular, for all $v \in H$ and $g \in C(\spectrum{A}; \reals)$, we have 
\begin{align*}
\langle v, f(A)g(A) v \rangle &= L_f(v, g(A)v) = \lim_{n \to \infty} L_{f_n}(v, g(A)) = \lim_{n \to \infty} Q_{f_ng}(v) = Q_{fg}(v) = \langle v, (fg)(A) v \rangle
\end{align*}
(note that $f_n g$ is also a uniformly bounded sequence and $f_n g \to fg$ pointwise so $Q_{f_ng} = Q_{fg}$ pointwise).  Thus by uniqueness in Proposition \ref{hilbert:OperatorFromQuadraticForm} we have $(fg)(A) = f(A) g(A)$. By Lemma \ref{hilbert:ContinuousToMeasurable} we conclude that $\mathcal{F}_1 = \sboundedmeasurable{\spectrum{A}}{\complexes}$.

Now let $\mathcal{F}_2 \subset \sboundedmeasurable{\spectrum{A}}{\complexes}$ be the set of $f$ such that $(fg)(A) = f(A) g(A)$ for all $g \in \sboundedmeasurable{\spectrum{A}}{\complexes}$.  By the same argument as for $\mathcal{F}_1$ we see that $\mathcal{F}_2$ is a complex vector space that is closed under uniformly bounded pointwise limits.  The argument for $\mathcal{F}_1$ shows that $C(\spectrum{A}; \complexes) \subset \mathcal{F}_2$ so again applying Lemma \ref{hilbert:ContinuousToMeasurable}  we get $\mathcal{F}_2 = \sboundedmeasurable{\spectrum{A}}{\complexes}$.

If $f$ is real valued then by definition $Q_f(v) = \int_{\spectrum{A}} f \, d\mu_v$ is real valued and therefore it follows from Proposition \ref{hilbert:OperatorFromQuadraticForm} that $f(A)$ is self adjoint.
\end{proof}

TODO: The bounded measurable functional calculus can be extended to unbounded measurable functions but the resulting operators are unbounded when $f$ isn't bounded.   If I continue to follow Hall then we won't develop the unbounded Borel functional calculus directly but will bootstrap from the bounded spectral theorem (self adjoint then normal) to the spectral theorem for unbounded self adjoint and from there we could develop the functional calculus.  

\section{Spectral Theory}

\subsection{Projection Valued Measures}

\begin{defn}Let $H$ be a Hilbert space, $(\Omega, \mathcal{A})$ be a measurable space then a map $\mu : \mathcal{A} \to L(H)$ is a 
\emph{projection valued measure} if and only if 
\begin{itemize}
\item[(i)] For every $A \in \mathcal{A}$ the operator $\mu(A)$ is an orthogonal projection
\item[(ii)] $\mu(\emptyset) = 0$ and $\mu(H) = \IdentityMatrix$
\item[(iii)] For $A_1, A_2, \dots \in \mathcal{A}$ disjoint and $v \in H$, the infinite series $\sum_{i=1}^\infty \mu(A_i)v$ converges in $H$ and 
\begin{align*}
\mu(\bigcup_{i=1}^\infty A_i)  v &= \sum_{i=1}^\infty \mu(A_i)v
\end{align*}
\item[(iv)]For all $A,B \in \mathcal{A}$, $\mu(A \cap B) = \mu(A) \mu(B)$.
\end{itemize}
\end{defn}


\begin{prop}\label{hilbert:PointwiseEvaluationOfProjectionMeasure}Let $H$ be a Hilbert space and $(\Omega, \mathcal{A})$ be a measurable space and $\mu : \mathcal{A} \to L(H)$ a projection valued measure, then
for every $v \in H$ the map $\mu_v(A) = \langle v, \mu(A) v \rangle$ is a measure.
\end{prop}
\begin{proof}
Let $v \in H$ then $\mu_v(\emptyset) = \langle v , \mu(\emptyset) v \rangle = \langle v, 0 \rangle = 0$.  If $A_1, A_2, \dots \in \mathcal{A}$ are disjoint
then using Proposition \ref{hilbert:ContinuityOfInnerProduct} we get
\begin{align*}
\mu_v(\bigcup_{i=1}^\infty A_i) &= \langle v , \sum_{i=1}^\infty \mu(A_i)v \rangle = \sum_{i=1}^\infty \langle v , \mu(A_i)v \rangle = \sum_{i=1}^\infty \mu_v (A_i)
\end{align*}
\end{proof}

With the previous proposition in hand we can build an integration theory for projection valued measures (TODO: Is this a Bochner integral?)
\begin{prop}\label{hilbert:OperatorValuedIntegration}Let $H$ be a Hilbert space and $(\Omega, \mathcal{A})$ be a measurable space and $\mu : \mathcal{A} \to L(H)$ a projection valued measure then there exists a unique linear map $\int \cdot \, d\mu : \sboundedmeasurable{\Omega}{\complexes} \to L(H,H)$ (recall $\sboundedmeasurable{\Omega}{\complexes}$ denotes the space of bounded measurable complex valued functions on $\Omega$) satisfying
\begin{align}\label{hilbert:DefiningPropertyOfOperatorIntegral}
\left \langle v, \left(\int f \, d\mu \right) v \right \rangle &= \int f \, d\mu_v \text{, for all $v \in H$ and $f \in \sboundedmeasurable{\Omega}{\complexes}$}
\end{align}
The map satisfies
\begin{itemize}
\item[(i)] For every $A \in \mathcal{A}$ 
\begin{align*}
\int \characteristic{A} \, d\mu = \mu(A)
\end{align*}
\item[(ii)] For every $f \in \sboundedmeasurable{\Omega}{\complexes}$, 
\begin{align*}
\norm {\int f \, d\mu} &\leq \sup_{v \in H} \abs{f(v)} = \norm{f}_\infty
\end{align*}
\item[(iii)] For every $f,g  \in \sboundedmeasurable{\Omega}{\complexes}$, 
\begin{align*}
\int f g \, d\mu &= \left ( \int f \, d\mu \right ) \left ( \int g \, d\mu \right )
\end{align*}
\item[(iv)] For every $f \in \sboundedmeasurable{\Omega}{\complexes}$, 
\begin{align*}
\left( \int f \, d\mu \right)^*  &= \int \overline{f} \, d\mu 
\end{align*}
for if $f$ is real valued then $\int f \, d\mu$ is self-adjoint.
\end{itemize}
\end{prop}
\begin{proof}

\begin{clm}For every bounded measurable $f : H \to \complexes$ the map $Q_f(v) = \int f \, d\mu_v$ defines a bounded quadratic form with 
\begin{align*}
\norm{Q_f} &\leq \norm{f}_\infty
\end{align*}
\end{clm}
Let $A \in \mathcal{A}$ and define $Q_A : H \to \complexes$ by $Q_A(v) = \mu_v(A) = \langle v , \mu(A) v \rangle$ and it follows from Propositoin \ref{hilbert:QuadraticFormFromOperator} that $Q_A$ is a bounded quadratic form.

Let $f = c_1 \characteristic{A_1} + \dotsb + c_n \characteristic{A_n}$ be a simple function then we see that 
\begin{align*}
Q_f(v) = \int f \, d\mu_v &= c_1 \mu_v(A_1) +  \dotsb + c_n \mu_v(A_n) =  c_1 Q_{A_1}(v) +  \dotsb + c_n Q_{A_n}(v) 
\end{align*}
and thus by Proposition \ref{hilbert:LinearCombinationOfQuadraticForms} we see that $Q_f$ is a bounded quadratic form.  TODO: Finish claim by limiting argument

From the claim and Proposition  \ref{hilbert:OperatorFromQuadraticForm} for each bounded measurable $f : H \to \complexes$ we construct a unique bounded linear operator $A_f : H \to H$ such that
$\langle v, A_f v \rangle = \int f \, d \mu_v$.  We know that $\norm{A_f} \leq \norm{Q_f} \leq \norm{f}_\infty$.  We define $\int f \, d\mu$ to be $A_f$ so $\left \langle v, \left(\int f \, d\mu \right) v \right \rangle = \int f \, d\mu_v$ for all $v \in H$.  The fact that the map $f \mapsto \int f \, d\mu$ is uniquely defined by property \eqref{hilbert:DefiningPropertyOfOperatorIntegral} follows from the uniqueness property of Proposition  \ref{hilbert:OperatorFromQuadraticForm}.  We have already observed that properties (i) and (ii) hold.  

To see (iii)

TODO: Finish
\end{proof}

\begin{lem}Let $V_1, V_2, \dotsc$ be closed pairwise orthogonal subspaces in the Hilbert space $H$, $V$ be the smallest closed subspace containing $V_1, V_2, \dotsc$ then $P_V v = \sum_{i=1}^\infty P_{V_i} v$.  
\end{lem}
\begin{proof}
\begin{clm}Let $v \in V$ and $P_{V_i} v = 0$ for all $i \in \naturals$ then $v=0$.
\end{clm}
We argue by contradiction.  Suppose $0 \neq w \in V$ and $P_{V_i} w = 0$ for all $i \in \naturals$.  Let $W$ be the orthogonal complement of $w$ in $V$ (i.e. $W = \lbrace v \in V \mid \langle v,w \rangle=0 \rbrace$.  Observe that $W$ is closed since if $v_1, v_2, \dotsc \in W$ and $v \in H$ with $v_n \to v$ then since $W \subset V$ and $V$ is closed we know that $v \in V$ but by continuity of the inner product $\langle v,w \rangle = \lim_{n \to \infty} \langle v_n, w \rangle = 0$ so $v \in W$.  Also for every $i \in \naturals$ and $v \in V_i$ we have by the self adjointness of orthogonal projections 
\begin{align*}
\langle w, v \rangle &= \langle w, P_{V_i} v \rangle = \langle P_{V_i} w, v \rangle = 0
\end{align*}
Thus $W$ is a strictly smaller closed subspace that containers all of the $V_i$.

\begin{clm}\label{hilbert:SumOfOrthogonalSubspaces} Let $v_i \in V_i$ for every $i \in \naturals$ then for every $n \in \naturals$, $\norm{\sum_{i=1}^n v_i}^2 =\sum_{i=1}^n \norm{ v_i}^2$ and $\sum_{i=1}^\infty v_i$ converges if and only if $\sum_{i=1}^\infty \norm{v_i}^2 < \infty$.
\end{clm}
By orthogonality of the $V_i$ it follows that 
\begin{align*}
\norm{\sum_{i=1}^n v_i}^2 &= \langle \sum_{i=1}^n v_i, \sum_{i=1}^n v_i \rangle = \sum_{i=1}^n \langle v_i , v_i \rangle = \sum_{i=1}^n \norm{ v_i}^2
\end{align*}
Now suppose $\sum_{i=1}^\infty v_i \in H$ then $\norm{\sum_{i=1}^n v_i} \to \norm{\sum_{i=1}^\infty v_i}$  (generally if $w_n \to w$ in a normed vector space then by the triangle inequality $-\norm{w - w_n} \leq \norm{w} - \norm{w_n} \leq \norm{w - w_n}$ hence $\norm{w_n} \to \norm{w}$).  Thus $\norm{\sum_{i=1}^n v_i}^2 = \sum_{i=1}^n\norm{ v_i}^2$ converges (to $\norm{\sum_{i=1}^\infty v_i}^2 < \infty$).  

On the other hand, suppose $\sum_{i=1}^\infty \norm{v_i}^2 < \infty$.  Then the sequence $\sum_{i=1}^n \norm{v_i}^2$ is Cauchy.  Let $\epsilon > 0$ and pick $n$ such that $\sum_{i=n}^m \norm{v_i}^2 < \epsilon$ for all $m \geq n$.  Then 
\begin{align*}
\norm{\sum_{i=1}^n v_i - \sum_{i=1}^m v_i}^2 &= \norm{\sum_{i=n}^m v_i}^2 = \sum_{i=n}^m \norm{ v_i}^2 < \epsilon
\end{align*}
and therefore the sequence $\sum_{i=1}^n v_i$ is Cauchy.  By completeness of $H$ the series $\sum_{i=1}^\infty v_i$ converges.

\begin{clm}For $i \neq j$, $P_{V_i} + P_{V_j} = P_{V_i \oplus V_j}$.
\end{clm}
As an aside note that $V_i \oplus V_j$ is a closed subspace.  Let $v_n \in V_i \oplus V_j$ converge to $v \in H$.  Then by continuity $P_{V_i} v_n \to P_{V_i} v$ and $P_{V_j} v_n \to P_{V_j} v$.  On the other hand since $V_i$ and $V_j$ are orthogonal, $v_n = P_{V_i} v_n + P_{V_j} v_n$ (write $v_n = x + y$ with $x \in V_i$ and $y \in V_j$ then by orthogonality $P_{V_i} v_n = P_{V_i} x + P_{V_i} y = x$).  Thus, it follows that $v_n \to P_{V_i} v+P_{V_j} v \in V_i \oplus V_j$.  By a similar argument, for $v \in H$ we may write $P_V v = P_{V_i} P_V v + P_{V_j} P_V v = P_{V_i} v + P_{V_j} v$ (generally if $W \subset V$ then $P_W = P_W \circ P_V$).

Now let $v \in H$ and observe that by the previous claim $\sum_{i=1}^n P_{V_i} v = P_{\oplus_{i=1}^n V_i} v$  thus 
\begin{align*}
\sum_{i=1}^n \norm{P_{V_i} v}^2 &= \norm{\sum_{i=1}^n  P_{V_i} v}^2 = \norm{P_{\oplus_{i=1}^n V_i} v}^2 \leq \norm{v}^2
\end{align*}
which shows us that $\sum_{i=1}^\infty \norm{P_{V_i} v}^2 \leq \norm{v}^2 < \infty$ and therefore the series $\sum_{i=1}^\infty P_{V_i} v$ converges.  Since $V$ is closed it follows that the sum is an element of $V$.  By continuity, for every $i \in \naturals$, 
\begin{align*}
P_{V_i} \sum_{i=1}^\infty P_{V_i} v &= \lim_{n \to \infty} P_{V_i} \sum_{i=1}^n P_{V_i} v =P_{V_i} v = P_{V_i} P_V v
\end{align*}
and therefore by the first claim, $P_V v = \sum_{i=1}^\infty P_{V_i} v$.
\end{proof}

\begin{thm}\label{hilbert:SpectralTheoremBoundSelfAdjointProjectionValuedMeasure}Let $H$ be a complex Hilbert space and $A : H \to H$ be a bounded self-adjoint operator then there exists a unique projection valued measure $\mu_A$ on the Borel $\sigma$-algebra on $\sigma(A)$ that satisfies
\begin{align*}
A &= \int_{\sigma(A)} \lambda  \, \mu_A(d\lambda)
\end{align*}
\end{thm}
\begin{proof}
For the existence proof, we define the projection valued measure $\mu_A$ using the bounded Borel functional calculus.  For any Borel measurable $E \in \mathcal{B}(\spectrum{A})$ let
\begin{align*}
\mu_A(E) &= \characteristic{E}(A)
\end{align*}
Since $\characteristic{E}$ is real valued and satisfies
$\characteristic{E}^2  = \characteristic{E}$, it follows from Theorem
\ref{hilbert:BoundedMeasurableFunctionalCalculusBoundedSelfAdjoint}
that $\mu_A(E) = \characteristic{E}(A)$ is self adjoint and 
\begin{align*}
\mu_A(E)^2 &= \characteristic{E}(A)^2 = (\characteristic{E}^2)(A) = \characteristic{E}(A) = \mu_A(E)
\end{align*}  
It follows (TODO: Where) that $\mu_A(E)$ is an orthogonal projection.

Let $E$ and $F$ be Borel measurable subsets of $\spectrum{A}$ then since $\characteristic{E} \cdot \characteristic{F} = \characteristic{E \cap F}$ it follows from Theorem \ref{hilbert:BoundedMeasurableFunctionalCalculusBoundedSelfAdjoint} that $\mu_A(E) \mu_A(F) = \mu_A(E \cap F)$.  Suppose that $E_1, E_2, \dotsc$ are disjoint Borel measurable subsets of $\spectrum{A}$.  Then we have shown for every $i \neq j$ that 
\begin{align*}
\mu_A(E_i) \mu_A(E_j) = \mu_A(E_i \cap E_j) = \mu_A(\emptyset) = 0
\end{align*}
(note that by linearity of the bounded Borel functional calculus and the fact that $\characteristic{\emptyset} \equiv 0$ that $\characteristic{\emptyset}(A) = 0$).  It follows that the range of $\mu_A(E_i)$ and $\mu_A(E_j)$ are orthogonal (for any $v,w \in H$, $\langle \mu_A(E_i) v, \mu_A(E_j) w \rangle = \langle v, \mu_A(E_i) \mu_A(E_j) v \rangle = 0$).  Let $V$ be the smallest closed subspace containing the range of $\mu_A(E_1), \mu_A(E_2), \dotsc$ and let $P_V$ be the orthogonal projection onto this subspace.  By Lemma \ref{hilbert:SumOfOrthogonalSubspaces}, for every $v \in H$, $\sum_{i=1}^\infty \mu_A(E_i)v = P_V v$ where the convergence is in the norm topology.

\begin{clm} $P_V = \mu_A(\cup_{i=1}^\infty E_i)$
\end{clm}
If we let $E = \cup_{i=1}^\infty E_i$ then $\lim_{n \to \infty} \sum_{i=1}^n \characteristic{E_i} = \characteristic{E}$ and by disjointness of the $E_i$ the series is bounded by the constant function $1$ (i.e. $\sum_{i=1}^n \characteristic{E_i}  = \characteristic{\cup_{i=1}^n E_i}$) therefore by continuity of inner product Proposition \ref{hilbert:ContinuityOfInnerProduct} and Dominated Convergence, for every $v \in H$,
\begin{align*}
\langle v, P_V v \rangle &= \lim_{n \to \infty} \langle v, \sum_{i=1}^n \characteristic{E_i}(A) v \rangle = \lim_{n \to \infty} \int \sum_{i=1}^n \characteristic{E_i} \, d\mu_v = \int \characteristic{E} \, d\mu_v \\
&= \langle v, \characteristic{E}(A) v \rangle = \langle v, \mu_A(E) v \rangle 
\end{align*}
Thus $P_V = \mu_A(E)$.

Therefore $\mu_A$ is countably additive.  

\begin{clm} For all bounded measurable $f$ we have $f(A) = \int_{\spectrum{A}} f(\lambda)  \, \mu_A(d\lambda)$
\end{clm}
Let $f = \characteristic{E}$ for some Borel set $E \subset \spectrum{A}$.  Then by the of $\mu_A$ and the properties of
integration with respect to a projection valued measure,
\begin{align*}
\characteristic{E}(A) &= \mu_A(E) = \int_{\spectrum{A}} \characteristic{E} \, d\mu_A
\end{align*}
Thus if  $f = a_1 \characteristic{E_1} + \dotsc +  a_n \characteristic{E_n}$ is simple, by linearity of the bounded measurable 
functional calculus and linear of projection valued integrals,
\begin{align*}
f(A) &= a_1 \characteristic{E_1}(A) + \dotsc +  a_n \characteristic{E_n}(A) \\
= a_1 \int_{\spectrum{A}} \characteristic{E_1} \, d\mu_A + \dotsc + a_1 \int_{\spectrum{A}} \characteristic{E_1} \, d\mu_A = \int_{\spectrum{A}} f \, d\mu_A
\end{align*}

TODO: Finish
\end{proof}

\begin{defn}Let $\Omega$ be a set and for every $\omega \in \Omega$ suppose that $H_\omega$ is a separable complex Hilbert space with inner product $\langle \cdot, \cdot \rangle_\omega$.  A function $s$ from $\Omega$ to the disjoint union of $H_\omega$ is said to be a \emph{section} if $s(\omega) \in H_\omega$ for every $\omega \in \Omega$.  A set of sections $e_1, e_2, \dotsc$ is said to be a \emph{simultaneous orthonormal basis} of the family $\lbrace H_\omega \rbrace$ if for every $\omega \in \Omega$ the set $\lbrace e_j(\omega) \mid e_j(\omega) \neq 0 \rbrace$ is an orthonormal basis of $H_\omega$.  If $(\Omega, \mathcal{A})$ is a measurable space then we say that a simultaenous orthonormal basis is a \emph{measurability structure} if for every $i,j \in \naturals$ the function $\omega \mapsto \langle e_i(\omega), e_j(\omega) \rangle_\omega$ is Borel measurable.   An arbitrary section $s$ is said to be measurable if the function 
$\omega \mapsto \langle e_i(\omega), s(\omega) \rangle_\omega$ is Borel measurable for every $i \in \naturals$.
\end{defn}

\begin{prop}\label{hilbert:InnerProductOfMeasurableSections}Let $(\Omega, \mathcal{A})$ be a measurable space, $\lbrace H_\omega \rbrace$ be a family of separable complex Hilbert spaces and $e_1, e_2,\dotsc$ be a measurability structure.  Let $s$ and $t$ be measurable sections then the function $\omega \mapsto \langle s(\omega), t(\omega) \rangle_\omega$ is Borel measurable.
\end{prop}
\begin{proof}
Since $e_1, e_2, \dotsc$ is a simultaenous orthonormal basis, for every $\omega \in \Omega$  we have $s(\omega) = \sum_{i=1}^\infty \langle e_i(\omega), s(\omega) \rangle_\omega e_i(\omega)$ and $t(\omega) = \sum_{j=1}^\infty \langle e_j(\omega), t(\omega) \rangle_\omega e_j(\omega)$.  By continuity of the inner product and orthogonality of the $e_i$,
\begin{align*}
\langle s(\omega), t(\omega) \rangle_\omega 
&= \sum_{i=1}^\infty \sum_{j=1}^\infty \langle  s(\omega)  , e_i(\omega)\rangle_\omega \langle e_j(\omega), t(\omega) \rangle_\omega \langle e_i(\omega), e_j(\omega) \rangle_\omega \\
&=\sum_{i=1}^\infty  \langle s(\omega)  ,e_i(\omega)\rangle_\omega \langle e_i(\omega), t(\omega) \rangle_\omega 
\end{align*}
which is measurable since each of $s$ and $t$ is measurable and Lemma \ref{LimitsOfMeasurable}
\end{proof}

By the previous proposition, if a measurable space $(\Omega, \mathcal{A})$ has measure $\mu$, then we can consider integrals $\int \langle s(\omega), t(\omega) \rangle_\omega \, \mu(d\omega)$.  In particular we can consider square integrable sections for which $\int \langle s(\omega), s(\omega) \rangle_\omega \, \mu(d\omega)$ is finite.

\begin{defn}Let $(\Omega, \mathcal{A}, \mu)$ be a $\sigma$-finite measure space, $\lbrace H_\omega \rbrace$ be a family of separable complex Hilbert spaces such that the dimension function $\omega \to \dim(H_\omega)$ is measurable and $e_1, e_2,\dotsc$ be a measurability structure. The \emph{direct integral}, denoted
\begin{align*}
\int^\oplus H_\omega \, \mu(d\omega)
\end{align*}
is the set of almost everywhere equal measurable sections $s$ for which
\begin{align*}
\norm{s}^2 &= \int \langle s(\omega), s(\omega) \rangle_\omega \, \mu(d\omega) = \int \norm{ s(\omega)}^2_\omega \, \mu(d\omega) < \infty
\end{align*}
Given two square integrable sections $s$ and $t$ we define 
\begin{align*}
\langle s, t \rangle &= \int \langle s(\omega), t(\omega) \rangle_\omega \, \mu(d\omega)
\end{align*}
\end{defn}

Note that the definition of a square integrable equivlence class of sections is well defined since any two representatives of the equivalence class have the same integral by Proposition \ref{AlmostEverywhereEqualIntegralEqual}.  

\begin{prop}\label{hilbert:DirectIntegralIsHilbertSpace} $\left (\int^\oplus H_\omega \, \mu(d\omega), \langle \cdot, \cdot \rangle \right )$ is a Hilbert space.
\end{prop}
\begin{proof}
First we show that $\langle s, t \rangle$ is well defined and finite.  Pick two representative of the equivalence class of $s$ and $t$ (by abuse of notation calling them $s$ and $t$ respectively).  By Proposition \ref{PropertiesOfComplexIntegrals}, the Cauchy Schwartz inequality in Hilbert space \ref{hilbert:CauchySchwartz} and the Cauchy Schwartz inequality in $L^2$ spaces (Lemma \ref{CauchySchwartz} TODO: this is only stated/proved for probability measures) we know that 
\begin{align*}
\abs{\langle s, t \rangle} &\leq \int \abs{\langle s(\omega), t(\omega) \rangle_\omega} \, \mu(d\omega) \\
&\leq \int \norm{s(\omega)}_\omega \norm{t(\omega)}_\omega\, \mu(d\omega) \\
&\leq \left( \int \norm{s(\omega)}^2_\omega \, \mu(d\omega) \right)^{1/2} \left(\int \norm{t(\omega)}^2_\omega \, \mu(d\omega) \right)^{1/2} < \infty\\
\end{align*}
So $\langle s, t \rangle$ is integrable.  The fact that the inner product doesn't depend on the choice of representatives of the equivalence class follows from Proposition \ref{IntegrableAlmostEverywhereEqualIntegralEqual}.  TODO: Do we need to state a complex analogue of this?

We now show that $\langle s,t \rangle$ is an inner product.  Non-negativity of $\langle s, s \rangle$ follows from the non-negativity of $\langle s(\omega), s(\omega) \rangle_\omega$ for every $\omega \in \Omega$ and monotonicity of integral.  if $\langle s, s \rangle = 0$ then by Lemma \ref{ZeroIntegralImpliesZeroFunction} we know that $\langle s(\omega), s(\omega) \rangle_\omega = 0$ for almost every $\omega \in \Omega$.  To see conjugate symmetry simply use Proposition \ref{PropertiesOfComplexIntegrals} to see
\begin{align*}
\langle s, t \rangle &= \int \langle s(\omega), t(\omega) \rangle_\omega \, \mu(d\omega) = \int \overline{\langle t(\omega), s(\omega) \rangle_\omega} \, \mu(d\omega) \\
&= \overline{\int \langle t(\omega), s(\omega) \rangle_\omega\, \mu(d\omega)} = \overline{\langle t, s \rangle}
\end{align*}
Similarly we see sesquilinearity using sesquilinearity of each $\langle \cdot, \cdot \rangle_\omega$ and the linearity of complex integral.

Lastly we need to show completeness.  Let $s_1, s_2, \dotsc$ be a Cauchy sequence of square integrable sections.  TODO: Finish
\end{proof}

TODO: Show that direct integrals generalize the construction of $L^2(\Omega, \mathcal{A}, \mu)$ (let each $H_\omega = \complexes$) and Hilbert space direct sums (choose $\Omega$ to be countable with counting measure).

\begin{prop}\label{hilbert:DirectIntegralSubspaces} Let $\int^\oplus H_\omega \, \mu(d\omega)$ be a direct integral and suppose $\omega_0 \in \Omega$ with $\lbrace \omega_0 \rbrace$ measurable and $\mu( \lbrace \omega_0 \rbrace) > 0$ then for each $v \in H_{\omega_0}$ define the section $s_v$ by
\begin{align*}
s_v(\omega) = 
\begin{cases}
\frac{1}{\sqrt{\mu(\lbrace \omega_0 \rbrace)}} v & \text{if $\omega = \omega_0$} \\
0 & \text{if $\omega \neq \omega_0$} 
\end{cases}
\end{align*}
The the map $v \mapsto s_v$ is an isometry of $H_{\omega_0}$ into $\int^\oplus H_\omega \, \mu(d\omega)$.
\end{prop}
\begin{proof}
It is clear that $v \mapsto s_v$ is linear and to see the isometry property
 we compute for $v,w \in H_{\omega_0}$
\begin{align*}
\langle s_v, s_w \rangle &= \int \langle s_v(\omega), s_w(\omega) \rangle_\omega \, \mu(d\omega) = \langle s_v(\omega_0), s_w(\omega_0) \rangle_{\omega_0} \mu(\lbrace \omega_0 \rbrace) \\
&=\frac{1}{\mu(\lbrace \omega_0 \rbrace)} \langle v,w \rangle_{\omega_0} \mu(\lbrace \omega_0 \rbrace) = \langle v,w \rangle_{\omega_0}
\end{align*}
\end{proof}

\begin{thm}\label{hilbert:SpectralTheoremBoundedSelfAdjointDirectIntegral}Let $H$ be a separable complex Hilbert space and $A : H \to H$ be a bounded self-adjoint linear operator, then there exists a $\sigma$-finite Borel measure on $\spectrum{A}$, a direct integral 
\begin{align*}
\int^\oplus H_\lambda \, \mu(d\lambda)
\end{align*}
and a unitary map $U: H \to \int^\oplus H_\lambda \, \mu(d\lambda)$ such that 
\begin{align*}
[UAU^{-1}(s)] (\lambda) = \lambda s(\lambda) 
\end{align*}
\end{thm}

