\section{Markov Processes}

\begin{defn}Let $X$ be a process in $(S, \mathcal{S})$ with time scale
  $T$ which is adapted to a filtration $\mathcal{F}_t$.  We say that
  $X$ has the \emph{Markov property} if 
$\cindependent{\mathcal{F}_s}{X_t}{X_s}$ for all $s \leq t \in T$.
\end{defn}
Given any process that satisfies the Markov property it is not hard to
show using properties of conditional independence that it
automatically satisfies a seemingly stronger condition
\begin{lem}[Extended Markov Property]\label{Extended Markov
    Property}Let $X$ be a process that satsifies the Markov property
  then $\cindependent{\mathcal{F}_t}{\sigma(\bigvee_{u \geq t}
    X_u)}{X_t}$ for all $t \in T$.
\end{lem}
\begin{proof}
Let $t_0 \leq t_1 \leq \cdots $ with $t_i \in T$.  By the
Markov property we know for each $0 \leq n$ that
$\cindependent{\mathcal{F}_{t_n}}{X_{t_{n+1}}}{X_{t_n}}$.  Because $X$ is
adapted to $\mathcal{F}$, we know that $X_{t_m}$ is
$\mathcal{F}_{t_n}$-measurable for $m \leq n$ and therefore
$\cindependent{\sigma(X_{t_0}, \dots
  ,X_{t_{n-1}},\mathcal{F}_{t_n})}{X_{t_{n+1}}}{X_{t_n}}$.
By Lemma \ref{ConditionalIndependenceChainRule} we conclude that $\cindependent{\mathcal{F}_{t_n}}{X_{t_{n+1}}}{X_{t_0}, \dots
  ,X_{t_n}}$ for all $n \geq 0$; because $\mathcal{F}_{t_0} \subset
\mathcal{F}_{t_n}$ we get $\cindependent{\mathcal{F}_{t_0}}{X_{t_{n+1}}}{X_{t_0}, \dots
  ,X_{t_n}}$ for all $n \geq 0$.  Another application of Lemma
\ref{ConditionalIndependenceChainRule} shows that
$\cindependent{\mathcal{F}_{t_0}}{\sigma(X_{t_1}, X_{t_2},
  \dots)}{X_{t_0}}$.

Since the union of the $\sigma$-algebras $\sigma(X_{t_1}, X_{t_2},
  \dots )$ for all $t_0 \leq t_1 \leq \cdots $ is
  clearly a $\pi$-system that generates $\sigma(\bigvee_{u \geq t_0}X_u)$, the result follows by montone classes (specifically Lemma \ref{ConditionalIndependencePiSystem}).
\end{proof}

TODO: Introduce the example of Markov Chains here as it is quite a bit
simpler and helps the
understanding of the abstract case quite a bit.

We know make a regularity assumption that for each pair $s,t \in T$
with $s \leq t$, we
have a probability kernel $\mu_{s,t} : S \times \mathcal{S} \to
\reals$ such that for every $A \in \mathcal{S}$
\begin{align*}
\mu_{s,t}(X_s, A) &= \cprobability{X_s}{X_t \in A} =
\cprobability{\mathcal{F}_s}{X_t \in A} \text{ a.s.}
\end{align*}
(e.g. if $S$ is a Borel space then this is true by Theorem
\ref{ExistenceConditionalDistribution}).
We let $\nu_t$ denote the distribution of $X_t$.
These conditional distributions characterize the distribution of the
process $X$ itself.  In particular we have the following nice formula
for finite dimensional distributions of the process.
\begin{lem}\label{MarkovDistributions}Let $X$ be a Markov process with
  one dimensional distributions $\nu_t$ and transition kernels
  $\mu_{s,t}$, then for all $t_0 \leq \cdots \leq t_n$ and $A \in
  \mathcal{S}^{\otimes n}$ we have
\begin{align*}
\probability{(X_{t_1}, \dots, X_{t_n}) \in A} &= \nu_{t_1} \otimes
\mu_{t_1, t_2} \otimes \cdots \mu_{t_{n-1},t_n}(A) \\
\cprobability{\mathcal{F}_{t_0}}{(X_{t_1}, \dots, X_{t_n}) \in A}(\omega) &= \mu_{t_0, t_1} \otimes \cdots \mu_{t_{n-1},t_n}(\omega,A) \\
\end{align*}
\end{lem}
\begin{proof}
TODO
\end{proof}
A special case of the relations above should be called out as it
motivates a property that will assume as part of the definition of a
Markov process.
\begin{cor}[Chapman-Kolmogorov
  Relations]\label{ChapmanKolmogorovWeak}Let $X$ be a stochastic
  process on a time scale $T \subset \reals$ with values in Borel
  space $(S, \mathcal{S})$ and suppose that $X$ has the Markov
  property.  Then for every $s, t, u \in T$ with $s \leq t \leq u$ we
  have
\begin{align*}
\mu_{s,t} \mu_{t,u} &= \mu_{s,u} \text{ a.s. $\nu_s$}
\end{align*}
\end{cor}
\begin{defn}Suppose that a family of transition kernels $\mu_{s,t}$ is
  given.  For a distribution $\nu$ on $(S, \mathcal{S})$, let
  $\sprobabilityop{\nu}$ denote the distribution on $S^T$ of the
  Markov process with initial distribution $\nu$.  If $\nu=\delta_x$
  for some $x \in S$ then it is customary to write
  $\sprobabilityop{x}$ instead of $\sprobabilityop{\delta_x}$.
\end{defn}
\begin{lem}The family $\sprobabilityop{x}$ is a kernel from $S$ to
  $S$.  Futhermore, given an initial distribution $\nu$
\begin{align*}
\sprobability{A}{\nu} = \int \sprobability{A}{x} \, d\nu(x)
\end{align*}
\end{lem}
\begin{proof}
First assume that $A = (\pi_{t_1}, \dots, \pi_{t_n})^{-1}(B)$ for some
$B \in \mathcal{S}^{\otimes n}$.  We can use Lemma \ref{MarkovDistributions} to compute for
any $\nu$,
\begin{align*}
\sprobability{A}{\nu} &= \sprobability{(\pi_0, \pi_{t_1}, \dots,
  \pi_{t_n})^{-1}(S \times B)}{x} \\
&=\nu \otimes \mu_{0, t_1} \otimes \cdots \mu_{t_{n-1}, t_n}(S \times
B) \\
&= \int \mu_{0, t_1} \otimes \cdots \mu_{t_{n-1}, t_n}(x,B) \, d\nu(x)
\end{align*}
In particular, for $\nu = \delta_x$ we get
\begin{align*}
\sprobability{A}{x} &=\mu_{0, t_1} \otimes \cdots \mu_{t_{n-1},
  t_n}(x,B)
\end{align*}
which shows both that $\sprobability{A}{x}$ is measurable and that
$\sprobability{A}{\nu} = \int \sprobability{A}{x} \, d\nu(x)$.

To extend to general measurable sets, we note that the set of $A$ of
the form given above is a $\pi$-system therefore we can apply Lemma
\ref{KernelMeasurability} to conclude $\sprobabilityop{x}$ is a
kernel.  Similarly we may conclude that $\sprobability{A}{\nu} = \int
\sprobability{A}{x} \, d\nu(x)$ for arbitrary measurable $A$ by the fact that probability measures
are uniquely determined by their values on a generating $\pi$-system
(Lemma \ref{UniquenessOfMeasure}).
\end{proof}

\begin{lem}Let $X$ be a Markov process and let $\tau$ be an optional
  time with at most countably many values.  Then for every measurable
  $A \subset S^T$,
\begin{align*}
\cexpectationlong{\mathcal{F}_\tau}{\theta_\tau X \in A} &=
\sprobability{A}{X_\tau} & & \text{on $\lbrace \tau < \infty \rbrace$}
\end{align*}
\end{lem}
